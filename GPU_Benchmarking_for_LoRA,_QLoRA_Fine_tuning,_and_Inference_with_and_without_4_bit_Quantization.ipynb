{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tuhinmallick/AI-for-Fashion/blob/main/GPU_Benchmarking_for_LoRA%2C_QLoRA_Fine_tuning%2C_and_Inference_with_and_without_4_bit_Quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*More details in this article: [GPU Benchmarking: What Is the Best GPU for LoRA, QLoRA, and Inference?](https://newsletter.kaitchup.com/p/gpu-benchmarking-what-is-the-best)*\n",
        "\n",
        "This notebook benchmarks your hardware configuration for LoRA, QLoRA fine-tuning, and inference with and without 4-bit Quantization.\n",
        "\n",
        "It uses Hugging Face Transformers, TRL, and PEFT for the fine-tuning part. For the inference part, the benchmarking is done through optimum-benchmark.\n",
        "\n",
        "For fine-tuning, I use the training time returned by the logs as the benchmarking metric.\n",
        "\n",
        "For inference, optimum benchmark produces a CSV file containing a lot of information that you can use as benchmarking metrics (memory consumption, latency, etc.)\n",
        "\n",
        "*Note: This notebook only works with Ampere and more recent NVIDIA GPUs*"
      ],
      "metadata": {
        "id": "4ge2XsidhlRH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WsleTqfUH-QB",
        "outputId": "ff3cda80-40cc-4dcb-cc03-f23f36d4f1dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optimum-benchmark in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.11.1)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.9.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from optimum-benchmark) (4.42.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from optimum-benchmark) (0.32.1)\n",
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.10/dist-packages (from optimum-benchmark) (1.3.2)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (from optimum-benchmark) (2.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from optimum-benchmark) (5.9.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from optimum-benchmark) (4.12.2)\n",
            "Requirement already satisfied: flatten-dict in /usr/local/lib/python3.10/dist-packages (from optimum-benchmark) (0.4.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optimum-benchmark) (6.8.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from optimum-benchmark) (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.3)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl) (0.8.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2022.12.7)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->optimum-benchmark) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->optimum-benchmark) (0.19.1)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
            "Requirement already satisfied: six<2.0,>=1.12 in /usr/lib/python3/dist-packages (from flatten-dict->optimum-benchmark) (1.16.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core->optimum-benchmark) (4.9.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->optimum-benchmark) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->optimum-benchmark) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->optimum-benchmark) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.10/dist-packages (12.555.43)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install optimum-benchmark bitsandbytes datasets peft trl\n",
        "!pip install nvidia-ml-py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method for LoRA and QLoRA fine-tuning:"
      ],
      "metadata": {
        "id": "iGRCggG9meoZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtXNXUf8wc5T",
        "outputId": "91b8fa7c-7671-4b10-ff0f-a44650fd8708"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flash_attn\n",
            "  Downloading flash_attn-2.5.9.post1.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash_attn) (2.1.0+cu118)\n",
            "Collecting einops (from flash_attn)\n",
            "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (2024.5.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash_attn) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash_attn) (1.3.0)\n",
            "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: flash_attn\n",
            "  Building wheel for flash_attn (setup.py): started\n",
            "  Building wheel for flash_attn (setup.py): finished with status 'done'\n",
            "  Created wheel for flash_attn: filename=flash_attn-2.5.9.post1-cp310-cp310-linux_x86_64.whl size=121711011 sha256=c55cb075a15591ebea0e8df05daea937ae206afd67ad1c50524a36f37cbd8d1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/ad/f6/7ccf0238790d6346e9fe622923a76ec218e890d356b9a2754a\n",
            "Successfully built flash_attn\n",
            "Installing collected packages: einops, flash_attn\n",
            "Successfully installed einops-0.8.0 flash_attn-2.5.9.post1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch, os, multiprocessing\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "\n",
        "#use bf16 and FlashAttention if supported\n",
        "if torch.cuda.is_bf16_supported():\n",
        "  os.system('pip install flash_attn')\n",
        "  compute_dtype = torch.bfloat16\n",
        "  attn_implementation = 'flash_attention_2'\n",
        "else:\n",
        "  compute_dtype = torch.float16\n",
        "  attn_implementation = 'sdpa'\n",
        "\n",
        "\n",
        "def LoRA(model_id, q=False):\n",
        "  model_name =  model_id.split('/')[1]\n",
        "  #Tokenizer\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
        "  tokenizer.pad_token = tokenizer.eos_token\n",
        "  tokenizer.padding_side = 'left'\n",
        "\n",
        "  ds = load_dataset(\"timdettmers/openassistant-guanaco\")\n",
        "  #Add the EOS token\n",
        "  def process(row):\n",
        "      row[\"text\"] = row[\"text\"]+\"<|end_of_text|>\"\n",
        "      return row\n",
        "\n",
        "  ds = ds.map(\n",
        "      process,\n",
        "      num_proc= multiprocessing.cpu_count(),\n",
        "      load_from_cache_file=False,\n",
        "  )\n",
        "  if q:\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=compute_dtype,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "    )\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "              model_id, quantization_config=bnb_config, device_map={\"\": 0}, attn_implementation=attn_implementation\n",
        "    )\n",
        "    model = prepare_model_for_kbit_training(model, gradient_checkpointing_kwargs={'use_reentrant':True})\n",
        "    output_dir = model_name+\"_QLoRA\"\n",
        "  else:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id, device_map={\"\": 0}, attn_implementation=attn_implementation, torch_dtype=compute_dtype\n",
        "    )\n",
        "    model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={'use_reentrant':True})\n",
        "    output_dir = model_name+\"_LoRA\"\n",
        "\n",
        "  peft_config = LoraConfig(\n",
        "          lora_alpha=16,\n",
        "          lora_dropout=0.05,\n",
        "          r=16,\n",
        "          bias=\"none\",\n",
        "          task_type=\"CAUSAL_LM\",\n",
        "          target_modules= ['k_proj', 'q_proj', 'v_proj', 'o_proj', \"gate_proj\", \"down_proj\", \"up_proj\"]\n",
        "  )\n",
        "\n",
        "\n",
        "  training_arguments = SFTConfig(\n",
        "          output_dir=\"./\"+output_dir,\n",
        "          optim=\"adamw_8bit\",\n",
        "          per_device_train_batch_size=2,\n",
        "          gradient_accumulation_steps=8,\n",
        "          log_level=\"debug\",\n",
        "          save_strategy=\"epoch\",\n",
        "          logging_steps=10,\n",
        "          learning_rate=1e-4,\n",
        "          fp16 = not torch.cuda.is_bf16_supported(),\n",
        "          bf16 = torch.cuda.is_bf16_supported(),\n",
        "          num_train_epochs=1,\n",
        "          warmup_ratio=0.1,\n",
        "          lr_scheduler_type=\"linear\",\n",
        "          dataset_text_field=\"text\",\n",
        "          max_seq_length=512,\n",
        "  )\n",
        "\n",
        "  trainer = SFTTrainer(\n",
        "          model=model,\n",
        "          train_dataset=ds['train'],\n",
        "          peft_config=peft_config,\n",
        "          tokenizer=tokenizer,\n",
        "          args=training_arguments,\n",
        "  )\n",
        "\n",
        "  trainer.train()\n",
        "  del model\n",
        "  del trainer\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmMD3HpvwSfZ"
      },
      "source": [
        "Method for benchmarking the inference:\n",
        "\n",
        "Note:\n",
        "- Change the input shape for different batch size and sequence length\n",
        "- Change \"model_names\" to add the models you wish to benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5811626d8b1e4dc8b87c0af505375741",
            "d93e0d36c93f4e6f8e2b31819791349d",
            "601cea16930b4c1cb304dbeaf8ff1426",
            "5b32f16115be45eaa4f653d275c06d9c",
            "7fb8809d05e24d29aea92eacca0f5068",
            "ac84116afb0440a68edd1879e8991743",
            "6ff660ccd8404a95ae1f5aaa6764beab",
            "73e80bdf50564c8fae9c4e37875a94ab",
            "f4e793be316d43be8e80d767514de4bb",
            "c95cb7b121fb48d1bad811e81561660a",
            "4052dc6505b94068a1d9a619ed5e2b2b",
            "96d7127d58b54ad98a859fe76c152fe1",
            "39379a89ce2146aeba8d30ff936ed2e7",
            "f86caa4407c84530bd7a14c0e4293383",
            "10290c4735c8478991e5cf62dce99d32",
            "72e1ae246bf44130bcde89e60e8645b5",
            "685a57a3a9e2415eb7e7803514095c65",
            "47892706e07044fdbf3b5175cdbd0edb",
            "6a47508c08844a139502172b60bcf8bc",
            "597d520b85a243eaa7b0dee6b339978a",
            "f477d087260146deb216d1b4d57fa528",
            "376cabaacb8d4119876f5fb7611ddace",
            "20d9ac3b059e433fa3f5d510102e2db3",
            "ef05b9250f8e4be0a3ecbc67fb8ab00e",
            "ee60529639724fc2929756fc679b59a7",
            "11eb26573e424f4f89850d09f091b022",
            "4df8b62bd5c74626b4da1149d9c33bd7",
            "c6259128930c48a5953b069eeb01af9d",
            "78e83aef087b46c2b23655ea0675ca4e",
            "e4014a0107e64efa8d4dddbaf2c0cee9",
            "4b8bd73dfb4b4a6fa752e74f54f52e49",
            "30dd3974f9e84f0c888bbf56c2af13b4",
            "492a7a5d98fa4e3bb2a0bd25cc8c2d28",
            "c09805b8560c49adb91745418b5345e2",
            "80d1fb7464d44a83885f758b571cc5f3",
            "e9ec4ac30e864404b2e846bd374bfe65",
            "5c43528c71344e00ae2086982c71cf59",
            "2f0cc0636c584c3e95aaa7bf6864286f",
            "0ca6bb5d9c0945a3b6c14ac735680e95",
            "659e331f0566400bb6d1e13a268c23c6",
            "f346ca9d5b2d4dc194730c9198a9141b",
            "42dd7b2edc5f43a7a25d803049016a61",
            "4f6922996ab34cd0a261a438a3101be4",
            "8626597972454679a3f3486b4e6a23bd",
            "98e69412b20b47dc89233bb68f4100b8",
            "564e88aab96c4fbead4b5821a292d617",
            "ad00e0a87b6141e6bfc02d48066a6003",
            "dfad0154611445078492c05e8e983d66",
            "21be7bb3ac9141d28c00151b2e1075bf",
            "c4ade128bb244c56ba9cf39893101ae4",
            "bde5680cd79c46e0b637c8f556cd7e94",
            "898b4d7387c641fbb7bdbb8fb2986d1c",
            "f5064212fd9b496baa3b837f216cc309",
            "69375bfe83cd496f9b411de40c1aa517",
            "559f424e9fce4413aec67b0d58149542",
            "977e34f4c4c944feb33efe167452956c",
            "fb4b388360bd4b8a8495565e284fb002",
            "948481067e2541728cf2b8e4024a4a5f",
            "6b74c454d50a42c08c2eec01e8b14721",
            "99e2156a858b479ea39e6ad519bce447",
            "f57ff4608390461b9640003e0971e311",
            "ca3c3e6ccf2344c29687c78252b1c37e",
            "2eedd7afac584dc4bf05e6abbf8469e1",
            "7975344ad8b0442d85b2bd4cc1181336",
            "a9ca546c378041f88358ee4d18bdcccf",
            "5aca3509a1fe4b2d9dc1cf21192ed901",
            "03722fa0dd504417ba9629eaf477dcb6",
            "31a9a2a00a924ba38f1b83387fd19469",
            "faa4a353198f4a9e9dde1a838dbb9161",
            "afbd7388c92444c2a8831b844ba1e3e9",
            "a3aa13c8ae364d48a6afa5ae3a0f604e",
            "de86d710c27b49548183435ddac772ff",
            "3c2254340275414ca981ff0130670447",
            "fb79cf94f8be491a84bb24af51cc6a9f",
            "e9e1adaa0a084c4885ea26c3a3cc12f7",
            "6a83c87b03a94e14a574674b39f7943b",
            "c3fb7e7c5fdc44b88fa57a7c2a164385",
            "9f5cfc62fdf0468bb3f8ef00096eda2b",
            "42e454bbf6d74498b4ddbcee69f8fec1",
            "de42fbadcf0f4f0ba2bdf353411060b1",
            "b319e775aa864d129d5dcae0abab4db5",
            "2a1d9e3c8ffa4f2ba7f286e582bff627",
            "6caed408bf2d42ca9b0c9c1edf5234b7",
            "a26bf05256714275bd0e08e9a2d99219",
            "75cd86ad91fc451db45e1920f9a15079",
            "505187039bf646358c1d7560a3663cbb",
            "3b214e7879214cd0879d03477d200ec4",
            "69c1da244ddf473dba7fc2971b566379",
            "fcba92a81f0543ab8b9be2d7e55d9384"
          ]
        },
        "id": "NcbRzggCGtTZ",
        "outputId": "3d31260f-b99a-44fd-b230-90ea59ab5bef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03722fa0dd504417ba9629eaf477dcb6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31a9a2a00a924ba38f1b83387fd19469",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "faa4a353198f4a9e9dde1a838dbb9161",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afbd7388c92444c2a8831b844ba1e3e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/395 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3aa13c8ae364d48a6afa5ae3a0f604e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/20.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de86d710c27b49548183435ddac772ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.11M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c2254340275414ca981ff0130670447",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/9846 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb79cf94f8be491a84bb24af51cc6a9f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/518 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9e1adaa0a084c4885ea26c3a3cc12f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=48):   0%|          | 0/9846 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a83c87b03a94e14a574674b39f7943b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=48):   0%|          | 0/518 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3fb7e7c5fdc44b88fa57a7c2a164385",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f5cfc62fdf0468bb3f8ef00096eda2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42e454bbf6d74498b4ddbcee69f8fec1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de42fbadcf0f4f0ba2bdf353411060b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b319e775aa864d129d5dcae0abab4db5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a1d9e3c8ffa4f2ba7f286e582bff627",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6caed408bf2d42ca9b0c9c1edf5234b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a26bf05256714275bd0e08e9a2d99219",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75cd86ad91fc451db45e1920f9a15079",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "505187039bf646358c1d7560a3663cbb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/9846 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:397: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n",
            "Using auto half precision backend\n",
            "Currently training with a batch size of: 2\n",
            "***** Running training *****\n",
            "  Num examples = 9,846\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 615\n",
            "  Number of trainable parameters = 41,943,040\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='615' max='615' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [615/615 2:35:11, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.669400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.595200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.448200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.357500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.345700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.348200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.313800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.388200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.308100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.265500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.327200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.318400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.331500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.310100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.320400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.354100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>1.315800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.299800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>1.345700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.280600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>1.251800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>1.361700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>1.318900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.261200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.343100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>1.285800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>1.304600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>1.240000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>1.278500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.343600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>1.304700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>1.271000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>1.320100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>1.279700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.291500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>1.286700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>1.260200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>1.281000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>1.273500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.371000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>1.291700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>1.345200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>1.262100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>1.340900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>1.302100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>1.347700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>1.324600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>1.308900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>1.278600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.310800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>1.315300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>1.190100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>1.272400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>1.256700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>1.320400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>1.226500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>1.221000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>1.223600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>1.350800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.329900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>1.266800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./Meta-Llama-3-8B_QLoRA/checkpoint-615\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B/snapshots/62bd457b6fe961a42a631306577e622c83876cb6/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.42.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in ./Meta-Llama-3-8B_QLoRA/checkpoint-615/tokenizer_config.json\n",
            "Special tokens file saved in ./Meta-Llama-3-8B_QLoRA/checkpoint-615/special_tokens_map.json\n",
            "Saving model checkpoint to ./Meta-Llama-3-8B_QLoRA/checkpoint-615\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B/snapshots/62bd457b6fe961a42a631306577e622c83876cb6/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.42.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in ./Meta-Llama-3-8B_QLoRA/checkpoint-615/tokenizer_config.json\n",
            "Special tokens file saved in ./Meta-Llama-3-8B_QLoRA/checkpoint-615/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B/snapshots/62bd457b6fe961a42a631306577e622c83876cb6/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B/snapshots/62bd457b6fe961a42a631306577e622c83876cb6/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B/snapshots/62bd457b6fe961a42a631306577e622c83876cb6/tokenizer_config.json\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b214e7879214cd0879d03477d200ec4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=48):   0%|          | 0/9846 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69c1da244ddf473dba7fc2971b566379",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=48):   0%|          | 0/518 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B/snapshots/62bd457b6fe961a42a631306577e622c83876cb6/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"_name_or_path\": \"meta-llama/Meta-Llama-3-8B\",\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.42.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B/snapshots/62bd457b6fe961a42a631306577e622c83876cb6/model.safetensors.index.json\n",
            "Instantiating LlamaForCausalLM model under default dtype torch.bfloat16.\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001\n",
            "}\n",
            "\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n",
            "Detected flash_attn version: 2.5.9.post1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcba92a81f0543ab8b9be2d7e55d9384",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
            "\n",
            "All the weights of LlamaForCausalLM were initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
            "loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B/snapshots/62bd457b6fe961a42a631306577e622c83876cb6/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"max_length\": 4096,\n",
            "  \"temperature\": 0.6,\n",
            "  \"top_p\": 0.9\n",
            "}\n",
            "\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:397: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n",
            "Using auto half precision backend\n",
            "Currently training with a batch size of: 2\n",
            "***** Running training *****\n",
            "  Num examples = 9,846\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 615\n",
            "  Number of trainable parameters = 41,943,040\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='615' max='615' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [615/615 1:05:52, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.628300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.587900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.440400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.317900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.301900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.306300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.283900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.352300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.277900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.234300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.296600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.289100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.301400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.281900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.287500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.323200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>1.287100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.270400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>1.318900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.250100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>1.224200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>1.334300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>1.291100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.231000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.314200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>1.256300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>1.279100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>1.216200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>1.251600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.317200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>1.279400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>1.246400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>1.292600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>1.252600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.262600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>1.262400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>1.233300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>1.252500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>1.250200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.343300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>1.265700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>1.320200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>1.233900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>1.318000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>1.274800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>1.321600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>1.301000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>1.283500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>1.256700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.286800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>1.290500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>1.163900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>1.248000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>1.233100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>1.296500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>1.202300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>1.196000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>1.200700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>1.327600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.305600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>1.245000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./Meta-Llama-3-8B_LoRA/checkpoint-615\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B/snapshots/62bd457b6fe961a42a631306577e622c83876cb6/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.42.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in ./Meta-Llama-3-8B_LoRA/checkpoint-615/tokenizer_config.json\n",
            "Special tokens file saved in ./Meta-Llama-3-8B_LoRA/checkpoint-615/special_tokens_map.json\n",
            "Saving model checkpoint to ./Meta-Llama-3-8B_LoRA/checkpoint-615\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B/snapshots/62bd457b6fe961a42a631306577e622c83876cb6/config.json\n",
            "Model config LlamaConfig {\n",
            "  \"architectures\": [\n",
            "    \"LlamaForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 128000,\n",
            "  \"eos_token_id\": 128001,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 14336,\n",
            "  \"max_position_embeddings\": 8192,\n",
            "  \"mlp_bias\": false,\n",
            "  \"model_type\": \"llama\",\n",
            "  \"num_attention_heads\": 32,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"pretraining_tp\": 1,\n",
            "  \"rms_norm_eps\": 1e-05,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 500000.0,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.42.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 128256\n",
            "}\n",
            "\n",
            "tokenizer config file saved in ./Meta-Llama-3-8B_LoRA/checkpoint-615/tokenizer_config.json\n",
            "Special tokens file saved in ./Meta-Llama-3-8B_LoRA/checkpoint-615/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ISOLATED-PROCESS][\u001b[36m2024-07-05 11:42:07,633\u001b[0m][\u001b[34mtorchrun\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Starting benchmark in isolated process\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:10,826\u001b[0m][\u001b[34mtorchrun\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Setting torch.distributed cuda device to 0\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:10,841\u001b[0m][\u001b[34mtorchrun\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Initializing torch.distributed process group\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:10,884\u001b[0m][\u001b[34mdatasets\u001b[0m][\u001b[32mINFO\u001b[0m] - PyTorch version 2.1.0+cu118 available.\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:12,280\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - Allocating pytorch backend\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:12,281\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Seeding backend with 42\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:12,284\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Benchmarking a Transformers model\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:13,918\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Using automodel class AutoModelForCausalLM\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:13,919\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Using AutoModel AutoModelForCausalLM\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:13,919\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Creating backend temporary directory\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:13,920\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Loading model with pretrained weights\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:13,921\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Loading Transformers model\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:17,820\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Moving Transformers model to device: cuda\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:19,809\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Turning on model's eval mode\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:19,813\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - Allocating inference scenario\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:19,814\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Creating input generator\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:19,814\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Generating Text Generation inputs\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:19,815\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Updating Text Generation kwargs with default values\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:19,816\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Initializing Text Generation report\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:19,817\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Preparing inputs for Inference\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:19,855\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Preparing backend for Inference\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:19,856\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Warming up backend for Text Generation\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:26,370\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Running Text Generation memory tracking\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:26,371\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Tracking RAM memory of process [6131]\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:26,372\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Tracking VRAM memory of CUDA devices [0]\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:26,372\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Tracking Allocated/Reserved memory of 1 Pytorch CUDA devices\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:43,185\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t+ prefill memory:\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:43,186\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max RAM: 1326.043136 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:43,187\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max global VRAM: 17474.781184 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:43,187\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max process VRAM: 0.000000 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:43,188\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max reserved memory: 16443.768832 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:43,188\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max allocated memory: 16251.908096 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:43,189\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t+ decode memory:\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:43,189\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max RAM: 1326.043136 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:43,190\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max global VRAM: 17474.781184 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:43,191\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max process VRAM: 0.000000 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:43,191\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max reserved memory: 16443.768832 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:43,192\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max allocated memory: 16251.910144 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:43,192\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Running Per-Token Text Generation latency tracking\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:42:43,193\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Tracking latency using Pytorch CUDA events\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,502\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t+ prefill latency:\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,507\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ count: 10\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,507\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ total: 0.723004 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,508\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ mean: 0.072300 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,508\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ stdev: 0.000199 s (0.28%)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,509\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p50: 0.072344 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,510\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p90: 0.072534 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,510\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p95: 0.072545 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,511\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p99: 0.072554 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,511\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t+ decode latency:\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,512\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ count: 10\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,512\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ total: 50.575350 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,513\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ mean: 5.057535 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,513\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ stdev: 0.000695 s (0.01%)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,514\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p50: 5.057387 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,514\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p90: 5.058040 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,515\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p95: 5.058702 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,516\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p99: 5.059231 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,516\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t+ per_token latency:\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,517\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ count: 990\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,517\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ total: 50.573363 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,518\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ mean: 0.051084 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,518\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ stdev: 0.000150 s (0.29%)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,519\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p50: 0.051085 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,519\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p90: 0.051274 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,520\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p95: 0.051303 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,520\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p99: 0.051539 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,522\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t+ prefill throughput: 2766.237922 tokens/s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,523\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t+ decode throughput: 19.574753 tokens/s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,523\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t+ per_token throughput: 19.575523 tokens/s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,550\u001b[0m][\u001b[34mtorchrun\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Benchmark completed successfully\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,552\u001b[0m][\u001b[34mtorchrun\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Destroying torch.distributed process group\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:34,565\u001b[0m][\u001b[34mtorchrun\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Exiting rank process\u001b[0m\n",
            "[ISOLATED-PROCESS][\u001b[36m2024-07-05 11:43:38,849\u001b[0m][\u001b[34mtorchrun\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Sending outputs to main process\u001b[0m\n",
            "[ISOLATED-PROCESS][\u001b[36m2024-07-05 11:43:38,850\u001b[0m][\u001b[34mtorchrun\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Exiting isolated process\u001b[0m\n",
            "[ISOLATED-PROCESS][\u001b[36m2024-07-05 11:43:42,792\u001b[0m][\u001b[34mtorchrun\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Starting benchmark in isolated process\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:46,022\u001b[0m][\u001b[34mtorchrun\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Setting torch.distributed cuda device to 0\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:46,036\u001b[0m][\u001b[34mtorchrun\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Initializing torch.distributed process group\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:46,227\u001b[0m][\u001b[34mdatasets\u001b[0m][\u001b[32mINFO\u001b[0m] - PyTorch version 2.1.0+cu118 available.\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:47,556\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - Allocating pytorch backend\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:47,557\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Seeding backend with 42\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:47,560\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Benchmarking a Transformers model\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:49,973\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Using automodel class AutoModelForCausalLM\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:49,974\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Using AutoModel AutoModelForCausalLM\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:49,974\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Processing quantization config\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:49,975\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Processing BitsAndBytes config\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:49,976\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Creating backend temporary directory\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:49,977\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Loading model with pretrained weights\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:49,978\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Loading bitsandbytes-quantized model\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:54,951\u001b[0m][\u001b[34mpytorch\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Turning on model's eval mode\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:54,955\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - Allocating inference scenario\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:54,956\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Creating input generator\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:54,956\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Generating Text Generation inputs\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:54,957\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Updating Text Generation kwargs with default values\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:54,957\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Initializing Text Generation report\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:54,958\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Preparing inputs for Inference\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:54,997\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Preparing backend for Inference\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:43:54,998\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Warming up backend for Text Generation\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:44:03,154\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Running Text Generation memory tracking\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:44:03,155\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Tracking RAM memory of process [6510]\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:44:03,156\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Tracking VRAM memory of CUDA devices [0]\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:44:03,156\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Tracking Allocated/Reserved memory of 1 Pytorch CUDA devices\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:44:21,035\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t+ prefill memory:\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:44:21,036\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max RAM: 1057.619968 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:44:21,037\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max global VRAM: 7100.170240 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:44:21,038\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max process VRAM: 0.000000 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:44:21,038\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max reserved memory: 6069.157888 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:44:21,039\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max allocated memory: 5893.362688 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:44:21,040\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t+ decode memory:\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:44:21,040\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max RAM: 1057.619968 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:44:21,041\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max global VRAM: 7100.170240 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:44:21,041\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max process VRAM: 0.000000 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:44:21,042\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max reserved memory: 6069.157888 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:44:21,043\u001b[0m][\u001b[34mmemory\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t- max allocated memory: 5893.364736 (MB)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:44:21,043\u001b[0m][\u001b[34minference\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Running Per-Token Text Generation latency tracking\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:44:21,043\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Tracking latency using Pytorch CUDA events\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,617\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t+ prefill latency:\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,618\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ count: 10\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,619\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ total: 1.299769 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,619\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ mean: 0.129977 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,620\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ stdev: 0.000275 s (0.21%)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,621\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p50: 0.129903 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,621\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p90: 0.130190 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,622\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p95: 0.130449 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,622\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p99: 0.130655 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,623\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t+ decode latency:\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,624\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ count: 10\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,624\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ total: 60.263642 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,625\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ mean: 6.026364 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,625\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ stdev: 0.044436 s (0.74%)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,626\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p50: 6.018043 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,626\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p90: 6.091693 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,627\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p95: 6.098301 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,628\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p99: 6.103587 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,629\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t+ per_token latency:\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,629\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ count: 990\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,630\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ total: 60.261609 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,631\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ mean: 0.060870 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,631\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ stdev: 0.001513 s (2.48%)\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,632\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p50: 0.060314 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,632\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p90: 0.062780 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,633\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p95: 0.063130 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,634\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t\t+ p99: 0.063712 s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,636\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t+ prefill throughput: 1538.735342 tokens/s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,636\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t+ decode throughput: 16.427816 tokens/s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,637\u001b[0m][\u001b[34mlatency\u001b[0m][\u001b[32mINFO\u001b[0m] - \t\t+ per_token throughput: 16.428370 tokens/s\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,664\u001b[0m][\u001b[34mtorchrun\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Benchmark completed successfully\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,667\u001b[0m][\u001b[34mtorchrun\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Destroying torch.distributed process group\u001b[0m\n",
            "[RANK-PROCESS-0][\u001b[36m2024-07-05 11:45:22,683\u001b[0m][\u001b[34mtorchrun\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Exiting rank process\u001b[0m\n",
            "[ISOLATED-PROCESS][\u001b[36m2024-07-05 11:45:43,894\u001b[0m][\u001b[34mtorchrun\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Sending outputs to main process\u001b[0m\n",
            "[ISOLATED-PROCESS][\u001b[36m2024-07-05 11:45:43,895\u001b[0m][\u001b[34mtorchrun\u001b[0m][\u001b[32mINFO\u001b[0m] - \t+ Exiting isolated process\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from optimum_benchmark import Benchmark, BenchmarkConfig, TorchrunConfig, InferenceConfig, TrainingConfig, PyTorchConfig\n",
        "from optimum_benchmark.logging_utils import setup_logging\n",
        "from transformers import set_seed\n",
        "import gc\n",
        "set_seed(1234)\n",
        "\n",
        "model_names = [\"meta-llama/Meta-Llama-3-8B\"]\n",
        "\n",
        "def inference_bench(model_id, quant=False):\n",
        "    model_name = model_id.split('/')[1]\n",
        "    launcher_config = TorchrunConfig(nproc_per_node=1)\n",
        "    input_shapes = {\"batch_size\": 1, \"num_choices\": 1, \"sequence_length\": 200}\n",
        "\n",
        "    scenario_config = InferenceConfig(latency=True, memory=True, input_shapes=input_shapes)\n",
        "    if quant:\n",
        "      name = \"benchmark_inference_report_quant\"+model_name+\".csv\"\n",
        "      quantization_scheme = 'bnb'\n",
        "      quantization_config = {\n",
        "                              \"bnb_4bit_compute_dtype\": \"float16\",\n",
        "                              \"bnb_4bit_quant_type\": \"nf4\",\n",
        "                              \"bnb_4bit_use_double_quant\": True,\n",
        "                              \"llm_int8_enable_fp32_cpu_offload\": False,\n",
        "                              \"llm_int8_has_fp16_weight\": False,\n",
        "                              \"llm_int8_threshold\": 6.0,\n",
        "                              \"load_in_4bit\": True,\n",
        "                              \"load_in_8bit\": False,\n",
        "                            }\n",
        "      backend_config = PyTorchConfig(model=model_id, quantization_scheme=quantization_scheme, torch_dtype=\"bfloat16\", quantization_config=quantization_config, device=\"cuda\", device_ids=\"0\", no_weights=False)\n",
        "    else:\n",
        "      name = \"benchmark_inference_report_\"+model_name+\".csv\"\n",
        "      backend_config = PyTorchConfig(model=model_id, device=\"cuda\", torch_dtype=\"bfloat16\", device_ids=\"0\", no_weights=False)\n",
        "    benchmark_config = BenchmarkConfig(\n",
        "        name=\"pytorch_\"+model_name,\n",
        "        scenario=scenario_config,\n",
        "        launcher=launcher_config,\n",
        "        backend=backend_config,\n",
        "    )\n",
        "    benchmark_report = Benchmark.launch(benchmark_config)\n",
        "\n",
        "\n",
        "    benchmark_report.log()\n",
        "    benchmark_config.to_dict()\n",
        "    benchmark_report.save_csv(name)\n",
        "\n",
        "\n",
        "for m in model_names:\n",
        "  LoRA(m, True) #QLoRA\n",
        "  LoRA(m) #LoRA\n",
        "\n",
        "  inference_bench(m) #Inference, not quantized (bfloat16)\n",
        "  inference_bench(m, True) #Inference, quantized\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ca6bb5d9c0945a3b6c14ac735680e95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10290c4735c8478991e5cf62dce99d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f477d087260146deb216d1b4d57fa528",
            "placeholder": "​",
            "style": "IPY_MODEL_376cabaacb8d4119876f5fb7611ddace",
            "value": " 518/518 [00:00&lt;00:00, 422.33 examples/s]"
          }
        },
        "11eb26573e424f4f89850d09f091b022": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30dd3974f9e84f0c888bbf56c2af13b4",
            "placeholder": "​",
            "style": "IPY_MODEL_492a7a5d98fa4e3bb2a0bd25cc8c2d28",
            "value": " 4/4 [00:10&lt;00:00,  2.21s/it]"
          }
        },
        "20d9ac3b059e433fa3f5d510102e2db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef05b9250f8e4be0a3ecbc67fb8ab00e",
              "IPY_MODEL_ee60529639724fc2929756fc679b59a7",
              "IPY_MODEL_11eb26573e424f4f89850d09f091b022"
            ],
            "layout": "IPY_MODEL_4df8b62bd5c74626b4da1149d9c33bd7"
          }
        },
        "21be7bb3ac9141d28c00151b2e1075bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eedd7afac584dc4bf05e6abbf8469e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f0cc0636c584c3e95aaa7bf6864286f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30dd3974f9e84f0c888bbf56c2af13b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "376cabaacb8d4119876f5fb7611ddace": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39379a89ce2146aeba8d30ff936ed2e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_685a57a3a9e2415eb7e7803514095c65",
            "placeholder": "​",
            "style": "IPY_MODEL_47892706e07044fdbf3b5175cdbd0edb",
            "value": "Map (num_proc=12): 100%"
          }
        },
        "4052dc6505b94068a1d9a619ed5e2b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42dd7b2edc5f43a7a25d803049016a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47892706e07044fdbf3b5175cdbd0edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "492a7a5d98fa4e3bb2a0bd25cc8c2d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b8bd73dfb4b4a6fa752e74f54f52e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4df8b62bd5c74626b4da1149d9c33bd7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f6922996ab34cd0a261a438a3101be4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "559f424e9fce4413aec67b0d58149542": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "564e88aab96c4fbead4b5821a292d617": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4ade128bb244c56ba9cf39893101ae4",
            "placeholder": "​",
            "style": "IPY_MODEL_bde5680cd79c46e0b637c8f556cd7e94",
            "value": "Map (num_proc=12): 100%"
          }
        },
        "5811626d8b1e4dc8b87c0af505375741": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d93e0d36c93f4e6f8e2b31819791349d",
              "IPY_MODEL_601cea16930b4c1cb304dbeaf8ff1426",
              "IPY_MODEL_5b32f16115be45eaa4f653d275c06d9c"
            ],
            "layout": "IPY_MODEL_7fb8809d05e24d29aea92eacca0f5068"
          }
        },
        "597d520b85a243eaa7b0dee6b339978a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5aca3509a1fe4b2d9dc1cf21192ed901": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b32f16115be45eaa4f653d275c06d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c95cb7b121fb48d1bad811e81561660a",
            "placeholder": "​",
            "style": "IPY_MODEL_4052dc6505b94068a1d9a619ed5e2b2b",
            "value": " 9846/9846 [00:00&lt;00:00, 45790.70 examples/s]"
          }
        },
        "5c43528c71344e00ae2086982c71cf59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f6922996ab34cd0a261a438a3101be4",
            "placeholder": "​",
            "style": "IPY_MODEL_8626597972454679a3f3486b4e6a23bd",
            "value": " 9846/9846 [00:00&lt;00:00, 4109.71 examples/s]"
          }
        },
        "601cea16930b4c1cb304dbeaf8ff1426": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73e80bdf50564c8fae9c4e37875a94ab",
            "max": 9846,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4e793be316d43be8e80d767514de4bb",
            "value": 9846
          }
        },
        "659e331f0566400bb6d1e13a268c23c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "685a57a3a9e2415eb7e7803514095c65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69375bfe83cd496f9b411de40c1aa517": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a47508c08844a139502172b60bcf8bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b74c454d50a42c08c2eec01e8b14721": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9ca546c378041f88358ee4d18bdcccf",
            "placeholder": "​",
            "style": "IPY_MODEL_5aca3509a1fe4b2d9dc1cf21192ed901",
            "value": " 4/4 [00:05&lt;00:00,  1.30s/it]"
          }
        },
        "6ff660ccd8404a95ae1f5aaa6764beab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72e1ae246bf44130bcde89e60e8645b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73e80bdf50564c8fae9c4e37875a94ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78e83aef087b46c2b23655ea0675ca4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7975344ad8b0442d85b2bd4cc1181336": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fb8809d05e24d29aea92eacca0f5068": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80d1fb7464d44a83885f758b571cc5f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ca6bb5d9c0945a3b6c14ac735680e95",
            "placeholder": "​",
            "style": "IPY_MODEL_659e331f0566400bb6d1e13a268c23c6",
            "value": "Map (num_proc=12): 100%"
          }
        },
        "8626597972454679a3f3486b4e6a23bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "898b4d7387c641fbb7bdbb8fb2986d1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "948481067e2541728cf2b8e4024a4a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eedd7afac584dc4bf05e6abbf8469e1",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7975344ad8b0442d85b2bd4cc1181336",
            "value": 4
          }
        },
        "96d7127d58b54ad98a859fe76c152fe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39379a89ce2146aeba8d30ff936ed2e7",
              "IPY_MODEL_f86caa4407c84530bd7a14c0e4293383",
              "IPY_MODEL_10290c4735c8478991e5cf62dce99d32"
            ],
            "layout": "IPY_MODEL_72e1ae246bf44130bcde89e60e8645b5"
          }
        },
        "977e34f4c4c944feb33efe167452956c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb4b388360bd4b8a8495565e284fb002",
              "IPY_MODEL_948481067e2541728cf2b8e4024a4a5f",
              "IPY_MODEL_6b74c454d50a42c08c2eec01e8b14721"
            ],
            "layout": "IPY_MODEL_99e2156a858b479ea39e6ad519bce447"
          }
        },
        "98e69412b20b47dc89233bb68f4100b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_564e88aab96c4fbead4b5821a292d617",
              "IPY_MODEL_ad00e0a87b6141e6bfc02d48066a6003",
              "IPY_MODEL_dfad0154611445078492c05e8e983d66"
            ],
            "layout": "IPY_MODEL_21be7bb3ac9141d28c00151b2e1075bf"
          }
        },
        "99e2156a858b479ea39e6ad519bce447": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9ca546c378041f88358ee4d18bdcccf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac84116afb0440a68edd1879e8991743": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad00e0a87b6141e6bfc02d48066a6003": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_898b4d7387c641fbb7bdbb8fb2986d1c",
            "max": 518,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5064212fd9b496baa3b837f216cc309",
            "value": 518
          }
        },
        "bde5680cd79c46e0b637c8f556cd7e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c09805b8560c49adb91745418b5345e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80d1fb7464d44a83885f758b571cc5f3",
              "IPY_MODEL_e9ec4ac30e864404b2e846bd374bfe65",
              "IPY_MODEL_5c43528c71344e00ae2086982c71cf59"
            ],
            "layout": "IPY_MODEL_2f0cc0636c584c3e95aaa7bf6864286f"
          }
        },
        "c4ade128bb244c56ba9cf39893101ae4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6259128930c48a5953b069eeb01af9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c95cb7b121fb48d1bad811e81561660a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca3c3e6ccf2344c29687c78252b1c37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d93e0d36c93f4e6f8e2b31819791349d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac84116afb0440a68edd1879e8991743",
            "placeholder": "​",
            "style": "IPY_MODEL_6ff660ccd8404a95ae1f5aaa6764beab",
            "value": "Map (num_proc=12): 100%"
          }
        },
        "dfad0154611445078492c05e8e983d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69375bfe83cd496f9b411de40c1aa517",
            "placeholder": "​",
            "style": "IPY_MODEL_559f424e9fce4413aec67b0d58149542",
            "value": " 518/518 [00:00&lt;00:00, 399.57 examples/s]"
          }
        },
        "e4014a0107e64efa8d4dddbaf2c0cee9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9ec4ac30e864404b2e846bd374bfe65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f346ca9d5b2d4dc194730c9198a9141b",
            "max": 9846,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42dd7b2edc5f43a7a25d803049016a61",
            "value": 9846
          }
        },
        "ee60529639724fc2929756fc679b59a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4014a0107e64efa8d4dddbaf2c0cee9",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b8bd73dfb4b4a6fa752e74f54f52e49",
            "value": 4
          }
        },
        "ef05b9250f8e4be0a3ecbc67fb8ab00e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6259128930c48a5953b069eeb01af9d",
            "placeholder": "​",
            "style": "IPY_MODEL_78e83aef087b46c2b23655ea0675ca4e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f346ca9d5b2d4dc194730c9198a9141b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f477d087260146deb216d1b4d57fa528": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4e793be316d43be8e80d767514de4bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5064212fd9b496baa3b837f216cc309": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f57ff4608390461b9640003e0971e311": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f86caa4407c84530bd7a14c0e4293383": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a47508c08844a139502172b60bcf8bc",
            "max": 518,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_597d520b85a243eaa7b0dee6b339978a",
            "value": 518
          }
        },
        "fb4b388360bd4b8a8495565e284fb002": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f57ff4608390461b9640003e0971e311",
            "placeholder": "​",
            "style": "IPY_MODEL_ca3c3e6ccf2344c29687c78252b1c37e",
            "value": "Loading checkpoint shards: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}