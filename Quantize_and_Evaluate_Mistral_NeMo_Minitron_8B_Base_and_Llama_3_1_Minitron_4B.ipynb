{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tuhinmallick/AI-for-Fashion/blob/main/Quantize_and_Evaluate_Mistral_NeMo_Minitron_8B_Base_and_Llama_3_1_Minitron_4B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*All the details in this article: [Mistral-NeMo: 4.1x Smaller with Quantized Minitron](https://newsletter.kaitchup.com/p/mistral-nemo-41x-smaller-with-quantized)*\n",
        "\n",
        "\n",
        "To quantize, run, and evaluate, the Minitron models with AutoRound and bitsandbytes, we need to install the following libraries:\n",
        "\n",
        "*Note: As I’m writing this, the Minitron models are not supported by the latest stable version of Transformers, we need to install it from source:*\n",
        "\n",
        "This notebook has only been tested on an the GPUs RTX 3090 and A40. It should work with any NVIDIA GPUs from the Ampere generation or more recent."
      ],
      "metadata": {
        "id": "8CjED0zWDxR2"
      },
      "id": "8CjED0zWDxR2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2adc5e8b-b388-4a82-b6a9-dd9d069b70d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2adc5e8b-b388-4a82-b6a9-dd9d069b70d4",
        "outputId": "d2ad2ac5-e68b-4eb8-91df-eafb99a3df62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting auto-round\n",
            "  Downloading auto_round-0.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting flash_attn\n",
            "  Downloading flash_attn-2.6.3.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting optimum\n",
            "  Downloading optimum-1.21.4-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting auto-gptq\n",
            "  Downloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from auto-round) (0.32.1)\n",
            "Collecting datasets (from auto-round)\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from auto-round) (9.0.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from auto-round) (0.1.99)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from auto-round) (2.3.1+cu121)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from auto-round) (2.3.1)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from auto-round) (3.5.0)\n",
            "Collecting intel-extension-for-transformers (from auto-round)\n",
            "  Downloading intel_extension_for_transformers-1.4.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash_attn) (0.8.0)\n",
            "Collecting coloredlogs (from optimum)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum) (1.13.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge (from auto-gptq)\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting gekko (from auto-gptq)\n",
            "  Downloading gekko-1.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting peft>=0.5.0 (from auto-gptq)\n",
            "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->auto-round) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->auto-round) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->auto-round) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->auto-round)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->auto-round)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->auto-round)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->auto-round)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->auto-round)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->auto-round)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->auto-round)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->auto-round)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->auto-round)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->auto-round)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->auto-round)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->auto-round)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.44.0,>=4.29.0->optimum) (3.20.3)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->optimum)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting pyarrow>=15.0.0 (from datasets->auto-round)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->auto-round)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto-round) (2.1.4)\n",
            "Collecting xxhash (from datasets->auto-round)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets->auto-round)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto-round) (3.10.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Collecting schema (from intel-extension-for-transformers->auto-round)\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Collecting neural-compressor (from intel-extension-for-transformers->auto-round)\n",
            "  Downloading neural_compressor-3.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto-gptq) (1.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-round) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-round) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-round) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-round) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-round) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-round) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-round) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->auto-round) (2.1.5)\n",
            "Collecting deprecated>=1.2.13 (from neural-compressor->intel-extension-for-transformers->auto-round)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from neural-compressor->intel-extension-for-transformers->auto-round) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from neural-compressor->intel-extension-for-transformers->auto-round) (9.4.0)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from neural-compressor->intel-extension-for-transformers->auto-round) (3.11.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from neural-compressor->intel-extension-for-transformers->auto-round) (1.3.2)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from neural-compressor->intel-extension-for-transformers->auto-round) (2.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-round) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-round) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-round) (2024.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->neural-compressor->intel-extension-for-transformers->auto-round) (1.16.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->neural-compressor->intel-extension-for-transformers->auto-round) (0.2.13)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools->neural-compressor->intel-extension-for-transformers->auto-round) (3.7.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->neural-compressor->intel-extension-for-transformers->auto-round) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->neural-compressor->intel-extension-for-transformers->auto-round) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers->auto-round) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers->auto-round) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers->auto-round) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers->auto-round) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers->auto-round) (3.1.2)\n",
            "Downloading auto_round-0.3-py3-none-any.whl (136 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.4/136.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optimum-1.21.4-py3-none-any.whl (421 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.43.4-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gekko-1.2.1-py3-none-any.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading intel_extension_for_transformers-1.4.2-cp310-cp310-manylinux_2_28_x86_64.whl (45.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading neural_compressor-3.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Building wheels for collected packages: flash_attn\n",
            "  Building wheel for flash_attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash_attn: filename=flash_attn-2.6.3-cp310-cp310-linux_x86_64.whl size=187290390 sha256=c50f5de67a8b75bcfcf4a34257622475f9b56d59da58a539476a21db9d5b9867\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/e3/c3/89c7a2f3c4adc07cd1c675f8bb7b9ad4d18f64a72bccdfe826\n",
            "Successfully built flash_attn\n",
            "Installing collected packages: schema, xxhash, rouge, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, gekko, dill, deprecated, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, coloredlogs, nvidia-cusolver-cu12, transformers, neural-compressor, datasets, intel-extension-for-transformers, flash_attn, bitsandbytes, peft, optimum, auto-round, auto-gptq\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.42.4\n",
            "    Uninstalling transformers-4.42.4:\n",
            "      Successfully uninstalled transformers-4.42.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed auto-gptq-0.7.1 auto-round-0.3 bitsandbytes-0.43.3 coloredlogs-15.0.1 datasets-2.21.0 deprecated-1.2.14 dill-0.3.8 flash_attn-2.6.3 gekko-1.2.1 humanfriendly-10.0 intel-extension-for-transformers-1.4.2 multiprocess-0.70.16 neural-compressor-3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 optimum-1.21.4 peft-0.12.0 pyarrow-17.0.0 rouge-1.0.1 schema-0.7.7 transformers-4.43.4 xxhash-3.5.0\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-4cjb2qtn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-4cjb2qtn\n",
            "  Resolved https://github.com/huggingface/transformers to commit 0a7af19f4dc868bafc82f35eb7e8d13bac87a594\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.23.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.4.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (2024.7.4)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.45.0.dev0-py3-none-any.whl size=9557589 sha256=d227731b5b71876609f0ea6583ef09d675b1ec55a750c3af0f8bc5b05b22d7c2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ul55c72m/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.43.4\n",
            "    Uninstalling transformers-4.43.4:\n",
            "      Successfully uninstalled transformers-4.43.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "optimum 1.21.4 requires transformers[sentencepiece]<4.44.0,>=4.29.0, but you have transformers 4.45.0.dev0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed transformers-4.45.0.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade transformers auto-round flash_attn optimum auto-gptq bitsandbytes\n",
        "!pip install git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Quantization"
      ],
      "metadata": {
        "id": "c0kpsNPdEQHC"
      },
      "id": "c0kpsNPdEQHC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##With bitsandbytes"
      ],
      "metadata": {
        "id": "AkfIJ-P2ESR7"
      },
      "id": "AkfIJ-P2ESR7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example for 8-bit quantization of nvidia/Mistral-NeMo-Minitron-8B-Base. Change \"model_name\" to quantize another model."
      ],
      "metadata": {
        "id": "28paPqnsEJjC"
      },
      "id": "28paPqnsEJjC"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "if torch.cuda.is_bf16_supported():\n",
        "  compute_dtype = torch.bfloat16\n",
        "else:\n",
        "  compute_dtype = torch.float16\n",
        "\n",
        "model_name = \"nvidia/Mistral-NeMo-Minitron-8B-Base\"\n",
        "quant_path = 'Mistral-NeMo-Minitron-8B-Base-bnb-8bit'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "        load_in_8bit=True,\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "          model_name, quantization_config=bnb_config\n",
        ")\n",
        "\n",
        "model.save_pretrained(\"./\"+quant_path, safetensors=True)\n",
        "tokenizer.save_pretrained(\"./\"+quant_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "08b0fee0606e49f39c4f8d4746ec0812",
            "cbc79140a7dc4e8f9e231a3d8758afc1",
            "c5b289881b614b19b83219fedf39e370",
            "fabe96a6e6a9455484426ff92fd284e8",
            "257822dc16ad427db4f2ae848240c903",
            "b02c7a30c95542dcb85abfb1be4e2068",
            "71cbbf2e4e1b4169b33f2a7f19026b93",
            "f586bc30d720478da774a8fbb1df82af",
            "b567d8d3f52445d1a970499b6cb74466",
            "464846cfa4424fdeb3e12ba810688f13",
            "437b89e93984486cb3c3787364c4bd30"
          ]
        },
        "id": "lOl2kQ0WgUzL",
        "outputId": "9fa8245f-5b3c-42ff-a82d-5c64e4415f0a"
      },
      "id": "lOl2kQ0WgUzL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08b0fee0606e49f39c4f8d4746ec0812"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./Mistral-Nemo-Base-2407-bnb-8bit/tokenizer_config.json',\n",
              " './Mistral-Nemo-Base-2407-bnb-8bit/special_tokens_map.json',\n",
              " './Mistral-Nemo-Base-2407-bnb-8bit/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##With AutoRound\n",
        "\n",
        "Symmetric quantization.\n",
        "\n",
        "Change \"model_name\" to quantize another model."
      ],
      "metadata": {
        "id": "APdy6E1DEiUw"
      },
      "id": "APdy6E1DEiUw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cea320d-9b7e-4359-ba42-060b73aaf56f",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "b2e2cfd61a3342599be247e2c241813d",
            "acc7ed9a78e64b66b237a4f19d04b219",
            "bb959cf90adf40f28f56f56776139280",
            "63bb336da0a943368b717bb3907ab5d4",
            "9459a5efe6ea45efaa69a7467b6203b7",
            "e225788743664395b8a0a219fbd0bf96",
            "edb41265714c4d668722e830b6131d5c"
          ]
        },
        "id": "4cea320d-9b7e-4359-ba42-060b73aaf56f",
        "outputId": "1efd2788-230a-4b86-a715-6e2945609e55"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2e2cfd61a3342599be247e2c241813d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-08-24 16:11:39 INFO autoround.py L209: using torch.float16 for quantization tuning\n",
            "2024-08-24 16:11:44,360 INFO utils.py L145: Note: detected 96 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
            "2024-08-24 16:11:44,362 INFO utils.py L148: Note: NumExpr detected 96 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 16.\n",
            "2024-08-24 16:11:44,363 INFO utils.py L161: NumExpr defaulting to 16 threads.\n",
            "2024-08-24 16:11:44,550 INFO config.py L59: PyTorch version 2.1.0+cu118 available.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acc7ed9a78e64b66b237a4f19d04b219",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/373 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb959cf90adf40f28f56f56776139280",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/921 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63bb336da0a943368b717bb3907ab5d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/33.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9459a5efe6ea45efaa69a7467b6203b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e225788743664395b8a0a219fbd0bf96",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edb41265714c4d668722e830b6131d5c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n",
            "2024-08-24 16:12:23 INFO autoround.py L1039: quantizing 1/40, model.layers.0\n",
            "2024-08-24 16:13:29 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.005015 -> iter 101: 0.001826\n",
            "2024-08-24 16:13:30 INFO autoround.py L1039: quantizing 2/40, model.layers.1\n",
            "2024-08-24 16:14:35 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.001793 -> iter 178: 0.000575\n",
            "2024-08-24 16:14:36 INFO autoround.py L1039: quantizing 3/40, model.layers.2\n",
            "2024-08-24 16:15:42 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.014820 -> iter 48: 0.001951\n",
            "2024-08-24 16:15:43 INFO autoround.py L1039: quantizing 4/40, model.layers.3\n",
            "2024-08-24 16:16:50 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.002394 -> iter 152: 0.001592\n",
            "2024-08-24 16:16:50 INFO autoround.py L1039: quantizing 5/40, model.layers.4\n",
            "2024-08-24 16:17:58 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.016184 -> iter 128: 0.001544\n",
            "2024-08-24 16:17:59 INFO autoround.py L1039: quantizing 6/40, model.layers.5\n",
            "2024-08-24 16:19:06 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.002292 -> iter 179: 0.001556\n",
            "2024-08-24 16:19:07 INFO autoround.py L1039: quantizing 7/40, model.layers.6\n",
            "2024-08-24 16:20:12 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.002354 -> iter 146: 0.001479\n",
            "2024-08-24 16:20:13 INFO autoround.py L1039: quantizing 8/40, model.layers.7\n",
            "2024-08-24 16:21:21 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.002544 -> iter 144: 0.001591\n",
            "2024-08-24 16:21:22 INFO autoround.py L1039: quantizing 9/40, model.layers.8\n",
            "2024-08-24 16:22:30 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.002594 -> iter 163: 0.001624\n",
            "2024-08-24 16:22:30 INFO autoround.py L1039: quantizing 10/40, model.layers.9\n",
            "2024-08-24 16:23:38 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.002953 -> iter 195: 0.001581\n",
            "2024-08-24 16:23:39 INFO autoround.py L1039: quantizing 11/40, model.layers.10\n",
            "2024-08-24 16:24:45 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.003344 -> iter 189: 0.001588\n",
            "2024-08-24 16:24:46 INFO autoround.py L1039: quantizing 12/40, model.layers.11\n",
            "2024-08-24 16:25:52 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.002926 -> iter 173: 0.001652\n",
            "2024-08-24 16:25:53 INFO autoround.py L1039: quantizing 13/40, model.layers.12\n",
            "2024-08-24 16:26:58 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.002790 -> iter 178: 0.001837\n",
            "2024-08-24 16:26:59 INFO autoround.py L1039: quantizing 14/40, model.layers.13\n",
            "2024-08-24 16:28:05 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.004313 -> iter 177: 0.002559\n",
            "2024-08-24 16:28:06 INFO autoround.py L1039: quantizing 15/40, model.layers.14\n",
            "2024-08-24 16:29:12 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.004750 -> iter 198: 0.002125\n",
            "2024-08-24 16:29:13 INFO autoround.py L1039: quantizing 16/40, model.layers.15\n",
            "2024-08-24 16:30:19 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.016930 -> iter 166: 0.002170\n",
            "2024-08-24 16:30:19 INFO autoround.py L1039: quantizing 17/40, model.layers.16\n",
            "2024-08-24 16:31:25 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.005107 -> iter 193: 0.002364\n",
            "2024-08-24 16:31:26 INFO autoround.py L1039: quantizing 18/40, model.layers.17\n",
            "2024-08-24 16:32:32 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.005019 -> iter 197: 0.002691\n",
            "2024-08-24 16:32:33 INFO autoround.py L1039: quantizing 19/40, model.layers.18\n",
            "2024-08-24 16:33:41 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.019755 -> iter 197: 0.003117\n",
            "2024-08-24 16:33:41 INFO autoround.py L1039: quantizing 20/40, model.layers.19\n",
            "2024-08-24 16:34:48 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.006922 -> iter 188: 0.003661\n",
            "2024-08-24 16:34:49 INFO autoround.py L1039: quantizing 21/40, model.layers.20\n",
            "2024-08-24 16:35:55 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.007112 -> iter 168: 0.004095\n",
            "2024-08-24 16:35:55 INFO autoround.py L1039: quantizing 22/40, model.layers.21\n",
            "2024-08-24 16:37:01 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.008337 -> iter 196: 0.004279\n",
            "2024-08-24 16:37:02 INFO autoround.py L1039: quantizing 23/40, model.layers.22\n",
            "2024-08-24 16:38:08 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.008698 -> iter 187: 0.005122\n",
            "2024-08-24 16:38:08 INFO autoround.py L1039: quantizing 24/40, model.layers.23\n",
            "2024-08-24 16:39:14 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.009931 -> iter 180: 0.005659\n",
            "2024-08-24 16:39:15 INFO autoround.py L1039: quantizing 25/40, model.layers.24\n",
            "2024-08-24 16:40:21 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.012236 -> iter 187: 0.006844\n",
            "2024-08-24 16:40:22 INFO autoround.py L1039: quantizing 26/40, model.layers.25\n",
            "2024-08-24 16:41:30 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.013738 -> iter 152: 0.008722\n",
            "2024-08-24 16:41:31 INFO autoround.py L1039: quantizing 27/40, model.layers.26\n",
            "2024-08-24 16:42:38 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.014442 -> iter 160: 0.009139\n",
            "2024-08-24 16:42:39 INFO autoround.py L1039: quantizing 28/40, model.layers.27\n",
            "2024-08-24 16:43:47 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.015817 -> iter 171: 0.009773\n",
            "2024-08-24 16:43:48 INFO autoround.py L1039: quantizing 29/40, model.layers.28\n",
            "2024-08-24 16:44:57 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.018272 -> iter 171: 0.011281\n",
            "2024-08-24 16:44:58 INFO autoround.py L1039: quantizing 30/40, model.layers.29\n",
            "2024-08-24 16:46:04 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.019540 -> iter 194: 0.012698\n",
            "2024-08-24 16:46:05 INFO autoround.py L1039: quantizing 31/40, model.layers.30\n",
            "2024-08-24 16:47:12 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.020520 -> iter 124: 0.014163\n",
            "2024-08-24 16:47:12 INFO autoround.py L1039: quantizing 32/40, model.layers.31\n",
            "2024-08-24 16:48:19 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.026240 -> iter 186: 0.016174\n",
            "2024-08-24 16:48:19 INFO autoround.py L1039: quantizing 33/40, model.layers.32\n",
            "2024-08-24 16:49:25 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.041619 -> iter 121: 0.016635\n",
            "2024-08-24 16:49:26 INFO autoround.py L1039: quantizing 34/40, model.layers.33\n",
            "2024-08-24 16:50:32 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.035654 -> iter 181: 0.021244\n",
            "2024-08-24 16:50:32 INFO autoround.py L1039: quantizing 35/40, model.layers.34\n",
            "2024-08-24 16:51:38 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.045672 -> iter 199: 0.025068\n",
            "2024-08-24 16:51:39 INFO autoround.py L1039: quantizing 36/40, model.layers.35\n",
            "2024-08-24 16:52:48 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.048453 -> iter 199: 0.028432\n",
            "2024-08-24 16:52:48 INFO autoround.py L1039: quantizing 37/40, model.layers.36\n",
            "2024-08-24 16:53:56 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.065820 -> iter 198: 0.036384\n",
            "2024-08-24 16:53:56 INFO autoround.py L1039: quantizing 38/40, model.layers.37\n",
            "2024-08-24 16:55:05 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.094927 -> iter 189: 0.050655\n",
            "2024-08-24 16:55:05 INFO autoround.py L1039: quantizing 39/40, model.layers.38\n",
            "2024-08-24 16:56:15 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.160774 -> iter 195: 0.073367\n",
            "2024-08-24 16:56:15 INFO autoround.py L1039: quantizing 40/40, model.layers.39\n",
            "2024-08-24 16:57:24 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.261087 -> iter 198: 0.112969\n",
            "2024-08-24 16:57:25 INFO autoround.py L288: quantization tuning time 2746.0725071430206\n",
            "2024-08-24 16:57:25 INFO autoround.py L304: Summary: quantized 280/281 in the model,  ['lm_head'] have not been quantized\n",
            "2024-08-24 16:57:25 INFO export.py L112: Saving quantized model to autogptq format, this may take a while...\n",
            "2024-08-24 16:57:25 INFO export.py L152: packing model.layers.0.self_attn.q_proj\n",
            "2024-08-24 16:57:26 INFO export.py L152: packing model.layers.0.self_attn.k_proj\n",
            "2024-08-24 16:57:26 INFO export.py L152: packing model.layers.0.self_attn.v_proj\n",
            "2024-08-24 16:57:27 INFO export.py L152: packing model.layers.0.self_attn.o_proj\n",
            "2024-08-24 16:57:27 INFO export.py L152: packing model.layers.0.mlp.gate_proj\n",
            "2024-08-24 16:57:29 INFO export.py L152: packing model.layers.0.mlp.up_proj\n",
            "2024-08-24 16:57:31 INFO export.py L152: packing model.layers.0.mlp.down_proj\n",
            "2024-08-24 16:57:32 INFO export.py L152: packing model.layers.1.self_attn.q_proj\n",
            "2024-08-24 16:57:33 INFO export.py L152: packing model.layers.1.self_attn.k_proj\n",
            "2024-08-24 16:57:33 INFO export.py L152: packing model.layers.1.self_attn.v_proj\n",
            "2024-08-24 16:57:34 INFO export.py L152: packing model.layers.1.self_attn.o_proj\n",
            "2024-08-24 16:57:34 INFO export.py L152: packing model.layers.1.mlp.gate_proj\n",
            "2024-08-24 16:57:36 INFO export.py L152: packing model.layers.1.mlp.up_proj\n",
            "2024-08-24 16:57:37 INFO export.py L152: packing model.layers.1.mlp.down_proj\n",
            "2024-08-24 16:57:39 INFO export.py L152: packing model.layers.2.self_attn.q_proj\n",
            "2024-08-24 16:57:40 INFO export.py L152: packing model.layers.2.self_attn.k_proj\n",
            "2024-08-24 16:57:40 INFO export.py L152: packing model.layers.2.self_attn.v_proj\n",
            "2024-08-24 16:57:40 INFO export.py L152: packing model.layers.2.self_attn.o_proj\n",
            "2024-08-24 16:57:41 INFO export.py L152: packing model.layers.2.mlp.gate_proj\n",
            "2024-08-24 16:57:42 INFO export.py L152: packing model.layers.2.mlp.up_proj\n",
            "2024-08-24 16:57:44 INFO export.py L152: packing model.layers.2.mlp.down_proj\n",
            "2024-08-24 16:57:45 INFO export.py L152: packing model.layers.3.self_attn.q_proj\n",
            "2024-08-24 16:57:46 INFO export.py L152: packing model.layers.3.self_attn.k_proj\n",
            "2024-08-24 16:57:46 INFO export.py L152: packing model.layers.3.self_attn.v_proj\n",
            "2024-08-24 16:57:46 INFO export.py L152: packing model.layers.3.self_attn.o_proj\n",
            "2024-08-24 16:57:47 INFO export.py L152: packing model.layers.3.mlp.gate_proj\n",
            "2024-08-24 16:57:49 INFO export.py L152: packing model.layers.3.mlp.up_proj\n",
            "2024-08-24 16:57:50 INFO export.py L152: packing model.layers.3.mlp.down_proj\n",
            "2024-08-24 16:57:52 INFO export.py L152: packing model.layers.4.self_attn.q_proj\n",
            "2024-08-24 16:57:53 INFO export.py L152: packing model.layers.4.self_attn.k_proj\n",
            "2024-08-24 16:57:53 INFO export.py L152: packing model.layers.4.self_attn.v_proj\n",
            "2024-08-24 16:57:53 INFO export.py L152: packing model.layers.4.self_attn.o_proj\n",
            "2024-08-24 16:57:54 INFO export.py L152: packing model.layers.4.mlp.gate_proj\n",
            "2024-08-24 16:57:55 INFO export.py L152: packing model.layers.4.mlp.up_proj\n",
            "2024-08-24 16:57:57 INFO export.py L152: packing model.layers.4.mlp.down_proj\n",
            "2024-08-24 16:57:59 INFO export.py L152: packing model.layers.5.self_attn.q_proj\n",
            "2024-08-24 16:57:59 INFO export.py L152: packing model.layers.5.self_attn.k_proj\n",
            "2024-08-24 16:57:59 INFO export.py L152: packing model.layers.5.self_attn.v_proj\n",
            "2024-08-24 16:58:00 INFO export.py L152: packing model.layers.5.self_attn.o_proj\n",
            "2024-08-24 16:58:00 INFO export.py L152: packing model.layers.5.mlp.gate_proj\n",
            "2024-08-24 16:58:02 INFO export.py L152: packing model.layers.5.mlp.up_proj\n",
            "2024-08-24 16:58:04 INFO export.py L152: packing model.layers.5.mlp.down_proj\n",
            "2024-08-24 16:58:05 INFO export.py L152: packing model.layers.6.self_attn.q_proj\n",
            "2024-08-24 16:58:06 INFO export.py L152: packing model.layers.6.self_attn.k_proj\n",
            "2024-08-24 16:58:06 INFO export.py L152: packing model.layers.6.self_attn.v_proj\n",
            "2024-08-24 16:58:06 INFO export.py L152: packing model.layers.6.self_attn.o_proj\n",
            "2024-08-24 16:58:07 INFO export.py L152: packing model.layers.6.mlp.gate_proj\n",
            "2024-08-24 16:58:09 INFO export.py L152: packing model.layers.6.mlp.up_proj\n",
            "2024-08-24 16:58:10 INFO export.py L152: packing model.layers.6.mlp.down_proj\n",
            "2024-08-24 16:58:12 INFO export.py L152: packing model.layers.7.self_attn.q_proj\n",
            "2024-08-24 16:58:12 INFO export.py L152: packing model.layers.7.self_attn.k_proj\n",
            "2024-08-24 16:58:13 INFO export.py L152: packing model.layers.7.self_attn.v_proj\n",
            "2024-08-24 16:58:13 INFO export.py L152: packing model.layers.7.self_attn.o_proj\n",
            "2024-08-24 16:58:14 INFO export.py L152: packing model.layers.7.mlp.gate_proj\n",
            "2024-08-24 16:58:15 INFO export.py L152: packing model.layers.7.mlp.up_proj\n",
            "2024-08-24 16:58:17 INFO export.py L152: packing model.layers.7.mlp.down_proj\n",
            "2024-08-24 16:58:19 INFO export.py L152: packing model.layers.8.self_attn.q_proj\n",
            "2024-08-24 16:58:19 INFO export.py L152: packing model.layers.8.self_attn.k_proj\n",
            "2024-08-24 16:58:19 INFO export.py L152: packing model.layers.8.self_attn.v_proj\n",
            "2024-08-24 16:58:20 INFO export.py L152: packing model.layers.8.self_attn.o_proj\n",
            "2024-08-24 16:58:20 INFO export.py L152: packing model.layers.8.mlp.gate_proj\n",
            "2024-08-24 16:58:22 INFO export.py L152: packing model.layers.8.mlp.up_proj\n",
            "2024-08-24 16:58:23 INFO export.py L152: packing model.layers.8.mlp.down_proj\n",
            "2024-08-24 16:58:25 INFO export.py L152: packing model.layers.9.self_attn.q_proj\n",
            "2024-08-24 16:58:26 INFO export.py L152: packing model.layers.9.self_attn.k_proj\n",
            "2024-08-24 16:58:26 INFO export.py L152: packing model.layers.9.self_attn.v_proj\n",
            "2024-08-24 16:58:26 INFO export.py L152: packing model.layers.9.self_attn.o_proj\n",
            "2024-08-24 16:58:27 INFO export.py L152: packing model.layers.9.mlp.gate_proj\n",
            "2024-08-24 16:58:28 INFO export.py L152: packing model.layers.9.mlp.up_proj\n",
            "2024-08-24 16:58:30 INFO export.py L152: packing model.layers.9.mlp.down_proj\n",
            "2024-08-24 16:58:32 INFO export.py L152: packing model.layers.10.self_attn.q_proj\n",
            "2024-08-24 16:58:32 INFO export.py L152: packing model.layers.10.self_attn.k_proj\n",
            "2024-08-24 16:58:32 INFO export.py L152: packing model.layers.10.self_attn.v_proj\n",
            "2024-08-24 16:58:33 INFO export.py L152: packing model.layers.10.self_attn.o_proj\n",
            "2024-08-24 16:58:33 INFO export.py L152: packing model.layers.10.mlp.gate_proj\n",
            "2024-08-24 16:58:35 INFO export.py L152: packing model.layers.10.mlp.up_proj\n",
            "2024-08-24 16:58:37 INFO export.py L152: packing model.layers.10.mlp.down_proj\n",
            "2024-08-24 16:58:38 INFO export.py L152: packing model.layers.11.self_attn.q_proj\n",
            "2024-08-24 16:58:39 INFO export.py L152: packing model.layers.11.self_attn.k_proj\n",
            "2024-08-24 16:58:39 INFO export.py L152: packing model.layers.11.self_attn.v_proj\n",
            "2024-08-24 16:58:39 INFO export.py L152: packing model.layers.11.self_attn.o_proj\n",
            "2024-08-24 16:58:40 INFO export.py L152: packing model.layers.11.mlp.gate_proj\n",
            "2024-08-24 16:58:42 INFO export.py L152: packing model.layers.11.mlp.up_proj\n",
            "2024-08-24 16:58:43 INFO export.py L152: packing model.layers.11.mlp.down_proj\n",
            "2024-08-24 16:58:45 INFO export.py L152: packing model.layers.12.self_attn.q_proj\n",
            "2024-08-24 16:58:45 INFO export.py L152: packing model.layers.12.self_attn.k_proj\n",
            "2024-08-24 16:58:46 INFO export.py L152: packing model.layers.12.self_attn.v_proj\n",
            "2024-08-24 16:58:46 INFO export.py L152: packing model.layers.12.self_attn.o_proj\n",
            "2024-08-24 16:58:46 INFO export.py L152: packing model.layers.12.mlp.gate_proj\n",
            "2024-08-24 16:58:48 INFO export.py L152: packing model.layers.12.mlp.up_proj\n",
            "2024-08-24 16:58:50 INFO export.py L152: packing model.layers.12.mlp.down_proj\n",
            "2024-08-24 16:58:51 INFO export.py L152: packing model.layers.13.self_attn.q_proj\n",
            "2024-08-24 16:58:52 INFO export.py L152: packing model.layers.13.self_attn.k_proj\n",
            "2024-08-24 16:58:52 INFO export.py L152: packing model.layers.13.self_attn.v_proj\n",
            "2024-08-24 16:58:52 INFO export.py L152: packing model.layers.13.self_attn.o_proj\n",
            "2024-08-24 16:58:53 INFO export.py L152: packing model.layers.13.mlp.gate_proj\n",
            "2024-08-24 16:58:55 INFO export.py L152: packing model.layers.13.mlp.up_proj\n",
            "2024-08-24 16:58:56 INFO export.py L152: packing model.layers.13.mlp.down_proj\n",
            "2024-08-24 16:58:58 INFO export.py L152: packing model.layers.14.self_attn.q_proj\n",
            "2024-08-24 16:58:59 INFO export.py L152: packing model.layers.14.self_attn.k_proj\n",
            "2024-08-24 16:58:59 INFO export.py L152: packing model.layers.14.self_attn.v_proj\n",
            "2024-08-24 16:58:59 INFO export.py L152: packing model.layers.14.self_attn.o_proj\n",
            "2024-08-24 16:59:00 INFO export.py L152: packing model.layers.14.mlp.gate_proj\n",
            "2024-08-24 16:59:01 INFO export.py L152: packing model.layers.14.mlp.up_proj\n",
            "2024-08-24 16:59:03 INFO export.py L152: packing model.layers.14.mlp.down_proj\n",
            "2024-08-24 16:59:05 INFO export.py L152: packing model.layers.15.self_attn.q_proj\n",
            "2024-08-24 16:59:05 INFO export.py L152: packing model.layers.15.self_attn.k_proj\n",
            "2024-08-24 16:59:05 INFO export.py L152: packing model.layers.15.self_attn.v_proj\n",
            "2024-08-24 16:59:06 INFO export.py L152: packing model.layers.15.self_attn.o_proj\n",
            "2024-08-24 16:59:06 INFO export.py L152: packing model.layers.15.mlp.gate_proj\n",
            "2024-08-24 16:59:08 INFO export.py L152: packing model.layers.15.mlp.up_proj\n",
            "2024-08-24 16:59:10 INFO export.py L152: packing model.layers.15.mlp.down_proj\n",
            "2024-08-24 16:59:11 INFO export.py L152: packing model.layers.16.self_attn.q_proj\n",
            "2024-08-24 16:59:12 INFO export.py L152: packing model.layers.16.self_attn.k_proj\n",
            "2024-08-24 16:59:12 INFO export.py L152: packing model.layers.16.self_attn.v_proj\n",
            "2024-08-24 16:59:12 INFO export.py L152: packing model.layers.16.self_attn.o_proj\n",
            "2024-08-24 16:59:13 INFO export.py L152: packing model.layers.16.mlp.gate_proj\n",
            "2024-08-24 16:59:14 INFO export.py L152: packing model.layers.16.mlp.up_proj\n",
            "2024-08-24 16:59:16 INFO export.py L152: packing model.layers.16.mlp.down_proj\n",
            "2024-08-24 16:59:18 INFO export.py L152: packing model.layers.17.self_attn.q_proj\n",
            "2024-08-24 16:59:18 INFO export.py L152: packing model.layers.17.self_attn.k_proj\n",
            "2024-08-24 16:59:18 INFO export.py L152: packing model.layers.17.self_attn.v_proj\n",
            "2024-08-24 16:59:19 INFO export.py L152: packing model.layers.17.self_attn.o_proj\n",
            "2024-08-24 16:59:19 INFO export.py L152: packing model.layers.17.mlp.gate_proj\n",
            "2024-08-24 16:59:21 INFO export.py L152: packing model.layers.17.mlp.up_proj\n",
            "2024-08-24 16:59:23 INFO export.py L152: packing model.layers.17.mlp.down_proj\n",
            "2024-08-24 16:59:24 INFO export.py L152: packing model.layers.18.self_attn.q_proj\n",
            "2024-08-24 16:59:25 INFO export.py L152: packing model.layers.18.self_attn.k_proj\n",
            "2024-08-24 16:59:25 INFO export.py L152: packing model.layers.18.self_attn.v_proj\n",
            "2024-08-24 16:59:25 INFO export.py L152: packing model.layers.18.self_attn.o_proj\n",
            "2024-08-24 16:59:26 INFO export.py L152: packing model.layers.18.mlp.gate_proj\n",
            "2024-08-24 16:59:27 INFO export.py L152: packing model.layers.18.mlp.up_proj\n",
            "2024-08-24 16:59:29 INFO export.py L152: packing model.layers.18.mlp.down_proj\n",
            "2024-08-24 16:59:31 INFO export.py L152: packing model.layers.19.self_attn.q_proj\n",
            "2024-08-24 16:59:31 INFO export.py L152: packing model.layers.19.self_attn.k_proj\n",
            "2024-08-24 16:59:31 INFO export.py L152: packing model.layers.19.self_attn.v_proj\n",
            "2024-08-24 16:59:32 INFO export.py L152: packing model.layers.19.self_attn.o_proj\n",
            "2024-08-24 16:59:32 INFO export.py L152: packing model.layers.19.mlp.gate_proj\n",
            "2024-08-24 16:59:34 INFO export.py L152: packing model.layers.19.mlp.up_proj\n",
            "2024-08-24 16:59:36 INFO export.py L152: packing model.layers.19.mlp.down_proj\n",
            "2024-08-24 16:59:37 INFO export.py L152: packing model.layers.20.self_attn.q_proj\n",
            "2024-08-24 16:59:38 INFO export.py L152: packing model.layers.20.self_attn.k_proj\n",
            "2024-08-24 16:59:38 INFO export.py L152: packing model.layers.20.self_attn.v_proj\n",
            "2024-08-24 16:59:38 INFO export.py L152: packing model.layers.20.self_attn.o_proj\n",
            "2024-08-24 16:59:39 INFO export.py L152: packing model.layers.20.mlp.gate_proj\n",
            "2024-08-24 16:59:41 INFO export.py L152: packing model.layers.20.mlp.up_proj\n",
            "2024-08-24 16:59:43 INFO export.py L152: packing model.layers.20.mlp.down_proj\n",
            "2024-08-24 16:59:44 INFO export.py L152: packing model.layers.21.self_attn.q_proj\n",
            "2024-08-24 16:59:45 INFO export.py L152: packing model.layers.21.self_attn.k_proj\n",
            "2024-08-24 16:59:45 INFO export.py L152: packing model.layers.21.self_attn.v_proj\n",
            "2024-08-24 16:59:45 INFO export.py L152: packing model.layers.21.self_attn.o_proj\n",
            "2024-08-24 16:59:46 INFO export.py L152: packing model.layers.21.mlp.gate_proj\n",
            "2024-08-24 16:59:47 INFO export.py L152: packing model.layers.21.mlp.up_proj\n",
            "2024-08-24 16:59:49 INFO export.py L152: packing model.layers.21.mlp.down_proj\n",
            "2024-08-24 16:59:51 INFO export.py L152: packing model.layers.22.self_attn.q_proj\n",
            "2024-08-24 16:59:51 INFO export.py L152: packing model.layers.22.self_attn.k_proj\n",
            "2024-08-24 16:59:52 INFO export.py L152: packing model.layers.22.self_attn.v_proj\n",
            "2024-08-24 16:59:52 INFO export.py L152: packing model.layers.22.self_attn.o_proj\n",
            "2024-08-24 16:59:52 INFO export.py L152: packing model.layers.22.mlp.gate_proj\n",
            "2024-08-24 16:59:54 INFO export.py L152: packing model.layers.22.mlp.up_proj\n",
            "2024-08-24 16:59:56 INFO export.py L152: packing model.layers.22.mlp.down_proj\n",
            "2024-08-24 16:59:57 INFO export.py L152: packing model.layers.23.self_attn.q_proj\n",
            "2024-08-24 16:59:58 INFO export.py L152: packing model.layers.23.self_attn.k_proj\n",
            "2024-08-24 16:59:58 INFO export.py L152: packing model.layers.23.self_attn.v_proj\n",
            "2024-08-24 16:59:58 INFO export.py L152: packing model.layers.23.self_attn.o_proj\n",
            "2024-08-24 16:59:59 INFO export.py L152: packing model.layers.23.mlp.gate_proj\n",
            "2024-08-24 17:00:01 INFO export.py L152: packing model.layers.23.mlp.up_proj\n",
            "2024-08-24 17:00:02 INFO export.py L152: packing model.layers.23.mlp.down_proj\n",
            "2024-08-24 17:00:04 INFO export.py L152: packing model.layers.24.self_attn.q_proj\n",
            "2024-08-24 17:00:04 INFO export.py L152: packing model.layers.24.self_attn.k_proj\n",
            "2024-08-24 17:00:05 INFO export.py L152: packing model.layers.24.self_attn.v_proj\n",
            "2024-08-24 17:00:05 INFO export.py L152: packing model.layers.24.self_attn.o_proj\n",
            "2024-08-24 17:00:05 INFO export.py L152: packing model.layers.24.mlp.gate_proj\n",
            "2024-08-24 17:00:07 INFO export.py L152: packing model.layers.24.mlp.up_proj\n",
            "2024-08-24 17:00:09 INFO export.py L152: packing model.layers.24.mlp.down_proj\n",
            "2024-08-24 17:00:10 INFO export.py L152: packing model.layers.25.self_attn.q_proj\n",
            "2024-08-24 17:00:11 INFO export.py L152: packing model.layers.25.self_attn.k_proj\n",
            "2024-08-24 17:00:11 INFO export.py L152: packing model.layers.25.self_attn.v_proj\n",
            "2024-08-24 17:00:11 INFO export.py L152: packing model.layers.25.self_attn.o_proj\n",
            "2024-08-24 17:00:12 INFO export.py L152: packing model.layers.25.mlp.gate_proj\n",
            "2024-08-24 17:00:14 INFO export.py L152: packing model.layers.25.mlp.up_proj\n",
            "2024-08-24 17:00:15 INFO export.py L152: packing model.layers.25.mlp.down_proj\n",
            "2024-08-24 17:00:17 INFO export.py L152: packing model.layers.26.self_attn.q_proj\n",
            "2024-08-24 17:00:17 INFO export.py L152: packing model.layers.26.self_attn.k_proj\n",
            "2024-08-24 17:00:18 INFO export.py L152: packing model.layers.26.self_attn.v_proj\n",
            "2024-08-24 17:00:18 INFO export.py L152: packing model.layers.26.self_attn.o_proj\n",
            "2024-08-24 17:00:19 INFO export.py L152: packing model.layers.26.mlp.gate_proj\n",
            "2024-08-24 17:00:20 INFO export.py L152: packing model.layers.26.mlp.up_proj\n",
            "2024-08-24 17:00:22 INFO export.py L152: packing model.layers.26.mlp.down_proj\n",
            "2024-08-24 17:00:24 INFO export.py L152: packing model.layers.27.self_attn.q_proj\n",
            "2024-08-24 17:00:24 INFO export.py L152: packing model.layers.27.self_attn.k_proj\n",
            "2024-08-24 17:00:24 INFO export.py L152: packing model.layers.27.self_attn.v_proj\n",
            "2024-08-24 17:00:25 INFO export.py L152: packing model.layers.27.self_attn.o_proj\n",
            "2024-08-24 17:00:25 INFO export.py L152: packing model.layers.27.mlp.gate_proj\n",
            "2024-08-24 17:00:27 INFO export.py L152: packing model.layers.27.mlp.up_proj\n",
            "2024-08-24 17:00:28 INFO export.py L152: packing model.layers.27.mlp.down_proj\n",
            "2024-08-24 17:00:30 INFO export.py L152: packing model.layers.28.self_attn.q_proj\n",
            "2024-08-24 17:00:31 INFO export.py L152: packing model.layers.28.self_attn.k_proj\n",
            "2024-08-24 17:00:31 INFO export.py L152: packing model.layers.28.self_attn.v_proj\n",
            "2024-08-24 17:00:31 INFO export.py L152: packing model.layers.28.self_attn.o_proj\n",
            "2024-08-24 17:00:32 INFO export.py L152: packing model.layers.28.mlp.gate_proj\n",
            "2024-08-24 17:00:33 INFO export.py L152: packing model.layers.28.mlp.up_proj\n",
            "2024-08-24 17:00:35 INFO export.py L152: packing model.layers.28.mlp.down_proj\n",
            "2024-08-24 17:00:37 INFO export.py L152: packing model.layers.29.self_attn.q_proj\n",
            "2024-08-24 17:00:37 INFO export.py L152: packing model.layers.29.self_attn.k_proj\n",
            "2024-08-24 17:00:37 INFO export.py L152: packing model.layers.29.self_attn.v_proj\n",
            "2024-08-24 17:00:38 INFO export.py L152: packing model.layers.29.self_attn.o_proj\n",
            "2024-08-24 17:00:38 INFO export.py L152: packing model.layers.29.mlp.gate_proj\n",
            "2024-08-24 17:00:40 INFO export.py L152: packing model.layers.29.mlp.up_proj\n",
            "2024-08-24 17:00:42 INFO export.py L152: packing model.layers.29.mlp.down_proj\n",
            "2024-08-24 17:00:43 INFO export.py L152: packing model.layers.30.self_attn.q_proj\n",
            "2024-08-24 17:00:44 INFO export.py L152: packing model.layers.30.self_attn.k_proj\n",
            "2024-08-24 17:00:44 INFO export.py L152: packing model.layers.30.self_attn.v_proj\n",
            "2024-08-24 17:00:44 INFO export.py L152: packing model.layers.30.self_attn.o_proj\n",
            "2024-08-24 17:00:45 INFO export.py L152: packing model.layers.30.mlp.gate_proj\n",
            "2024-08-24 17:00:46 INFO export.py L152: packing model.layers.30.mlp.up_proj\n",
            "2024-08-24 17:00:48 INFO export.py L152: packing model.layers.30.mlp.down_proj\n",
            "2024-08-24 17:00:50 INFO export.py L152: packing model.layers.31.self_attn.q_proj\n",
            "2024-08-24 17:00:50 INFO export.py L152: packing model.layers.31.self_attn.k_proj\n",
            "2024-08-24 17:00:50 INFO export.py L152: packing model.layers.31.self_attn.v_proj\n",
            "2024-08-24 17:00:51 INFO export.py L152: packing model.layers.31.self_attn.o_proj\n",
            "2024-08-24 17:00:51 INFO export.py L152: packing model.layers.31.mlp.gate_proj\n",
            "2024-08-24 17:00:53 INFO export.py L152: packing model.layers.31.mlp.up_proj\n",
            "2024-08-24 17:00:55 INFO export.py L152: packing model.layers.31.mlp.down_proj\n",
            "2024-08-24 17:00:56 INFO export.py L152: packing model.layers.32.self_attn.q_proj\n",
            "2024-08-24 17:00:57 INFO export.py L152: packing model.layers.32.self_attn.k_proj\n",
            "2024-08-24 17:00:57 INFO export.py L152: packing model.layers.32.self_attn.v_proj\n",
            "2024-08-24 17:00:57 INFO export.py L152: packing model.layers.32.self_attn.o_proj\n",
            "2024-08-24 17:00:58 INFO export.py L152: packing model.layers.32.mlp.gate_proj\n",
            "2024-08-24 17:00:59 INFO export.py L152: packing model.layers.32.mlp.up_proj\n",
            "2024-08-24 17:01:01 INFO export.py L152: packing model.layers.32.mlp.down_proj\n",
            "2024-08-24 17:01:03 INFO export.py L152: packing model.layers.33.self_attn.q_proj\n",
            "2024-08-24 17:01:03 INFO export.py L152: packing model.layers.33.self_attn.k_proj\n",
            "2024-08-24 17:01:03 INFO export.py L152: packing model.layers.33.self_attn.v_proj\n",
            "2024-08-24 17:01:04 INFO export.py L152: packing model.layers.33.self_attn.o_proj\n",
            "2024-08-24 17:01:04 INFO export.py L152: packing model.layers.33.mlp.gate_proj\n",
            "2024-08-24 17:01:06 INFO export.py L152: packing model.layers.33.mlp.up_proj\n",
            "2024-08-24 17:01:08 INFO export.py L152: packing model.layers.33.mlp.down_proj\n",
            "2024-08-24 17:01:09 INFO export.py L152: packing model.layers.34.self_attn.q_proj\n",
            "2024-08-24 17:01:10 INFO export.py L152: packing model.layers.34.self_attn.k_proj\n",
            "2024-08-24 17:01:10 INFO export.py L152: packing model.layers.34.self_attn.v_proj\n",
            "2024-08-24 17:01:10 INFO export.py L152: packing model.layers.34.self_attn.o_proj\n",
            "2024-08-24 17:01:11 INFO export.py L152: packing model.layers.34.mlp.gate_proj\n",
            "2024-08-24 17:01:13 INFO export.py L152: packing model.layers.34.mlp.up_proj\n",
            "2024-08-24 17:01:14 INFO export.py L152: packing model.layers.34.mlp.down_proj\n",
            "2024-08-24 17:01:16 INFO export.py L152: packing model.layers.35.self_attn.q_proj\n",
            "2024-08-24 17:01:16 INFO export.py L152: packing model.layers.35.self_attn.k_proj\n",
            "2024-08-24 17:01:17 INFO export.py L152: packing model.layers.35.self_attn.v_proj\n",
            "2024-08-24 17:01:17 INFO export.py L152: packing model.layers.35.self_attn.o_proj\n",
            "2024-08-24 17:01:18 INFO export.py L152: packing model.layers.35.mlp.gate_proj\n",
            "2024-08-24 17:01:19 INFO export.py L152: packing model.layers.35.mlp.up_proj\n",
            "2024-08-24 17:01:21 INFO export.py L152: packing model.layers.35.mlp.down_proj\n",
            "2024-08-24 17:01:22 INFO export.py L152: packing model.layers.36.self_attn.q_proj\n",
            "2024-08-24 17:01:23 INFO export.py L152: packing model.layers.36.self_attn.k_proj\n",
            "2024-08-24 17:01:23 INFO export.py L152: packing model.layers.36.self_attn.v_proj\n",
            "2024-08-24 17:01:23 INFO export.py L152: packing model.layers.36.self_attn.o_proj\n",
            "2024-08-24 17:01:24 INFO export.py L152: packing model.layers.36.mlp.gate_proj\n",
            "2024-08-24 17:01:26 INFO export.py L152: packing model.layers.36.mlp.up_proj\n",
            "2024-08-24 17:01:27 INFO export.py L152: packing model.layers.36.mlp.down_proj\n",
            "2024-08-24 17:01:29 INFO export.py L152: packing model.layers.37.self_attn.q_proj\n",
            "2024-08-24 17:01:29 INFO export.py L152: packing model.layers.37.self_attn.k_proj\n",
            "2024-08-24 17:01:30 INFO export.py L152: packing model.layers.37.self_attn.v_proj\n",
            "2024-08-24 17:01:30 INFO export.py L152: packing model.layers.37.self_attn.o_proj\n",
            "2024-08-24 17:01:31 INFO export.py L152: packing model.layers.37.mlp.gate_proj\n",
            "2024-08-24 17:01:32 INFO export.py L152: packing model.layers.37.mlp.up_proj\n",
            "2024-08-24 17:01:34 INFO export.py L152: packing model.layers.37.mlp.down_proj\n",
            "2024-08-24 17:01:36 INFO export.py L152: packing model.layers.38.self_attn.q_proj\n",
            "2024-08-24 17:01:36 INFO export.py L152: packing model.layers.38.self_attn.k_proj\n",
            "2024-08-24 17:01:36 INFO export.py L152: packing model.layers.38.self_attn.v_proj\n",
            "2024-08-24 17:01:37 INFO export.py L152: packing model.layers.38.self_attn.o_proj\n",
            "2024-08-24 17:01:37 INFO export.py L152: packing model.layers.38.mlp.gate_proj\n",
            "2024-08-24 17:01:39 INFO export.py L152: packing model.layers.38.mlp.up_proj\n",
            "2024-08-24 17:01:41 INFO export.py L152: packing model.layers.38.mlp.down_proj\n",
            "2024-08-24 17:01:42 INFO export.py L152: packing model.layers.39.self_attn.q_proj\n",
            "2024-08-24 17:01:43 INFO export.py L152: packing model.layers.39.self_attn.k_proj\n",
            "2024-08-24 17:01:43 INFO export.py L152: packing model.layers.39.self_attn.v_proj\n",
            "2024-08-24 17:01:43 INFO export.py L152: packing model.layers.39.self_attn.o_proj\n",
            "2024-08-24 17:01:44 INFO export.py L152: packing model.layers.39.mlp.gate_proj\n",
            "2024-08-24 17:01:46 INFO export.py L152: packing model.layers.39.mlp.up_proj\n",
            "2024-08-24 17:01:47 INFO export.py L152: packing model.layers.39.mlp.down_proj\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "model_name = \"nvidia/Mistral-NeMo-Minitron-8B-Base\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "from auto_round import AutoRound\n",
        "\n",
        "bits, group_size, sym = 4, 128, True\n",
        "autoround = AutoRound(model, tokenizer, bits=bits, group_size=group_size, batch_size=2, seqlen=512, sym=sym, gradient_accumulate_steps=4, device='cuda')\n",
        "autoround.quantize()\n",
        "output_dir = \"./AutoRound/Mistral-NeMo-Minitron-8B-Base-AutoRound-GPTQ-sym-4bit/\"\n",
        "autoround.save_quantized(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The same as above but for an asymmetric quantization."
      ],
      "metadata": {
        "id": "q30SQy9BEqPf"
      },
      "id": "q30SQy9BEqPf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5b72c4e-c018-4afd-9afc-53a25a80d09d",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "0e0431a964fe4e4cabd07cb23a1b86d7"
          ]
        },
        "id": "b5b72c4e-c018-4afd-9afc-53a25a80d09d",
        "outputId": "ec3b73b5-8f15-4fbe-82c0-919adc1101f9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e0431a964fe4e4cabd07cb23a1b86d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-08-24 17:02:32 INFO autoround.py L209: using torch.float16 for quantization tuning\n",
            "2024-08-24 17:02:36,883 INFO utils.py L145: Note: detected 96 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
            "2024-08-24 17:02:36,885 INFO utils.py L148: Note: NumExpr detected 96 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 16.\n",
            "2024-08-24 17:02:36,886 INFO utils.py L161: NumExpr defaulting to 16 threads.\n",
            "2024-08-24 17:02:37,047 INFO config.py L59: PyTorch version 2.1.0+cu118 available.\n",
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n",
            "2024-08-24 17:02:48 INFO autoround.py L1039: quantizing 1/40, model.layers.0\n",
            "2024-08-24 17:03:54 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.002202 -> iter 3: 0.001155\n",
            "2024-08-24 17:03:54 INFO autoround.py L1039: quantizing 2/40, model.layers.1\n",
            "2024-08-24 17:05:00 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.001543 -> iter 173: 0.000552\n",
            "2024-08-24 17:05:00 INFO autoround.py L1039: quantizing 3/40, model.layers.2\n",
            "2024-08-24 17:06:06 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.004909 -> iter 22: 0.002414\n",
            "2024-08-24 17:06:07 INFO autoround.py L1039: quantizing 4/40, model.layers.3\n",
            "2024-08-24 17:07:12 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.002708 -> iter 152: 0.002153\n",
            "2024-08-24 17:07:13 INFO autoround.py L1039: quantizing 5/40, model.layers.4\n",
            "2024-08-24 17:08:18 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.026674 -> iter 128: 0.002050\n",
            "2024-08-24 17:08:19 INFO autoround.py L1039: quantizing 6/40, model.layers.5\n",
            "2024-08-24 17:09:24 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.013849 -> iter 178: 0.001941\n",
            "2024-08-24 17:09:25 INFO autoround.py L1039: quantizing 7/40, model.layers.6\n",
            "2024-08-24 17:10:30 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.002903 -> iter 151: 0.001905\n",
            "2024-08-24 17:10:31 INFO autoround.py L1039: quantizing 8/40, model.layers.7\n",
            "2024-08-24 17:11:36 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.003137 -> iter 172: 0.001876\n",
            "2024-08-24 17:11:37 INFO autoround.py L1039: quantizing 9/40, model.layers.8\n",
            "2024-08-24 17:12:42 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.002976 -> iter 191: 0.001831\n",
            "2024-08-24 17:12:42 INFO autoround.py L1039: quantizing 10/40, model.layers.9\n",
            "2024-08-24 17:13:48 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.002911 -> iter 172: 0.001690\n",
            "2024-08-24 17:13:49 INFO autoround.py L1039: quantizing 11/40, model.layers.10\n",
            "2024-08-24 17:14:54 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.011966 -> iter 189: 0.001638\n",
            "2024-08-24 17:14:55 INFO autoround.py L1039: quantizing 12/40, model.layers.11\n",
            "2024-08-24 17:16:00 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.002709 -> iter 146: 0.001694\n",
            "2024-08-24 17:16:01 INFO autoround.py L1039: quantizing 13/40, model.layers.12\n",
            "2024-08-24 17:17:06 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.002735 -> iter 199: 0.001803\n",
            "2024-08-24 17:17:07 INFO autoround.py L1039: quantizing 14/40, model.layers.13\n",
            "2024-08-24 17:18:12 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.004095 -> iter 182: 0.002404\n",
            "2024-08-24 17:18:13 INFO autoround.py L1039: quantizing 15/40, model.layers.14\n",
            "2024-08-24 17:19:18 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.003779 -> iter 170: 0.002140\n",
            "2024-08-24 17:19:18 INFO autoround.py L1039: quantizing 16/40, model.layers.15\n",
            "2024-08-24 17:20:24 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.026858 -> iter 176: 0.002170\n",
            "2024-08-24 17:20:24 INFO autoround.py L1039: quantizing 17/40, model.layers.16\n",
            "2024-08-24 17:21:29 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.014872 -> iter 151: 0.002371\n",
            "2024-08-24 17:21:30 INFO autoround.py L1039: quantizing 18/40, model.layers.17\n",
            "2024-08-24 17:22:35 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.004330 -> iter 196: 0.002615\n",
            "2024-08-24 17:22:36 INFO autoround.py L1039: quantizing 19/40, model.layers.18\n",
            "2024-08-24 17:23:41 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.005618 -> iter 148: 0.003115\n",
            "2024-08-24 17:23:42 INFO autoround.py L1039: quantizing 20/40, model.layers.19\n",
            "2024-08-24 17:24:47 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.008429 -> iter 188: 0.003458\n",
            "2024-08-24 17:24:47 INFO autoround.py L1039: quantizing 21/40, model.layers.20\n",
            "2024-08-24 17:25:53 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.006454 -> iter 153: 0.003773\n",
            "2024-08-24 17:25:53 INFO autoround.py L1039: quantizing 22/40, model.layers.21\n",
            "2024-08-24 17:26:58 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.007656 -> iter 170: 0.004046\n",
            "2024-08-24 17:26:59 INFO autoround.py L1039: quantizing 23/40, model.layers.22\n",
            "2024-08-24 17:28:04 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.007772 -> iter 170: 0.004530\n",
            "2024-08-24 17:28:05 INFO autoround.py L1039: quantizing 24/40, model.layers.23\n",
            "2024-08-24 17:29:10 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.011533 -> iter 180: 0.005313\n",
            "2024-08-24 17:29:11 INFO autoround.py L1039: quantizing 25/40, model.layers.24\n",
            "2024-08-24 17:30:16 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.010677 -> iter 187: 0.006373\n",
            "2024-08-24 17:30:16 INFO autoround.py L1039: quantizing 26/40, model.layers.25\n",
            "2024-08-24 17:31:21 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.011345 -> iter 152: 0.007850\n",
            "2024-08-24 17:31:22 INFO autoround.py L1039: quantizing 27/40, model.layers.26\n",
            "2024-08-24 17:32:27 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.012563 -> iter 179: 0.008231\n",
            "2024-08-24 17:32:28 INFO autoround.py L1039: quantizing 28/40, model.layers.27\n",
            "2024-08-24 17:33:33 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.013493 -> iter 170: 0.008694\n",
            "2024-08-24 17:33:34 INFO autoround.py L1039: quantizing 29/40, model.layers.28\n",
            "2024-08-24 17:34:39 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.015776 -> iter 165: 0.010081\n",
            "2024-08-24 17:34:40 INFO autoround.py L1039: quantizing 30/40, model.layers.29\n",
            "2024-08-24 17:35:45 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.016866 -> iter 194: 0.011325\n",
            "2024-08-24 17:35:45 INFO autoround.py L1039: quantizing 31/40, model.layers.30\n",
            "2024-08-24 17:36:51 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.017413 -> iter 162: 0.012396\n",
            "2024-08-24 17:36:51 INFO autoround.py L1039: quantizing 32/40, model.layers.31\n",
            "2024-08-24 17:37:57 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.022079 -> iter 186: 0.014298\n",
            "2024-08-24 17:37:58 INFO autoround.py L1039: quantizing 33/40, model.layers.32\n",
            "2024-08-24 17:39:03 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.052319 -> iter 121: 0.014769\n",
            "2024-08-24 17:39:04 INFO autoround.py L1039: quantizing 34/40, model.layers.33\n",
            "2024-08-24 17:40:09 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.032580 -> iter 181: 0.018963\n",
            "2024-08-24 17:40:09 INFO autoround.py L1039: quantizing 35/40, model.layers.34\n",
            "2024-08-24 17:41:15 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.043299 -> iter 189: 0.022173\n",
            "2024-08-24 17:41:15 INFO autoround.py L1039: quantizing 36/40, model.layers.35\n",
            "2024-08-24 17:42:21 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.043836 -> iter 144: 0.025913\n",
            "2024-08-24 17:42:22 INFO autoround.py L1039: quantizing 37/40, model.layers.36\n",
            "2024-08-24 17:43:27 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.055601 -> iter 198: 0.032390\n",
            "2024-08-24 17:43:28 INFO autoround.py L1039: quantizing 38/40, model.layers.37\n",
            "2024-08-24 17:44:33 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.079098 -> iter 167: 0.045129\n",
            "2024-08-24 17:44:34 INFO autoround.py L1039: quantizing 39/40, model.layers.38\n",
            "2024-08-24 17:45:39 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.124662 -> iter 195: 0.064569\n",
            "2024-08-24 17:45:40 INFO autoround.py L1039: quantizing 40/40, model.layers.39\n",
            "2024-08-24 17:46:45 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.211447 -> iter 198: 0.096545\n",
            "2024-08-24 17:46:46 INFO autoround.py L288: quantization tuning time 2653.8871941566467\n",
            "2024-08-24 17:46:46 INFO autoround.py L304: Summary: quantized 280/281 in the model,  ['lm_head'] have not been quantized\n",
            "2024-08-24 17:46:46 INFO export.py L112: Saving quantized model to autogptq format, this may take a while...\n",
            "2024-08-24 17:46:46 INFO export.py L152: packing model.layers.0.self_attn.q_proj\n",
            "2024-08-24 17:46:47 INFO export.py L152: packing model.layers.0.self_attn.k_proj\n",
            "2024-08-24 17:46:47 INFO export.py L152: packing model.layers.0.self_attn.v_proj\n",
            "2024-08-24 17:46:47 INFO export.py L152: packing model.layers.0.self_attn.o_proj\n",
            "2024-08-24 17:46:48 INFO export.py L152: packing model.layers.0.mlp.gate_proj\n",
            "2024-08-24 17:46:50 INFO export.py L152: packing model.layers.0.mlp.up_proj\n",
            "2024-08-24 17:46:51 INFO export.py L152: packing model.layers.0.mlp.down_proj\n",
            "2024-08-24 17:46:53 INFO export.py L152: packing model.layers.1.self_attn.q_proj\n",
            "2024-08-24 17:46:54 INFO export.py L152: packing model.layers.1.self_attn.k_proj\n",
            "2024-08-24 17:46:54 INFO export.py L152: packing model.layers.1.self_attn.v_proj\n",
            "2024-08-24 17:46:54 INFO export.py L152: packing model.layers.1.self_attn.o_proj\n",
            "2024-08-24 17:46:55 INFO export.py L152: packing model.layers.1.mlp.gate_proj\n",
            "2024-08-24 17:46:56 INFO export.py L152: packing model.layers.1.mlp.up_proj\n",
            "2024-08-24 17:46:58 INFO export.py L152: packing model.layers.1.mlp.down_proj\n",
            "2024-08-24 17:47:00 INFO export.py L152: packing model.layers.2.self_attn.q_proj\n",
            "2024-08-24 17:47:00 INFO export.py L152: packing model.layers.2.self_attn.k_proj\n",
            "2024-08-24 17:47:00 INFO export.py L152: packing model.layers.2.self_attn.v_proj\n",
            "2024-08-24 17:47:01 INFO export.py L152: packing model.layers.2.self_attn.o_proj\n",
            "2024-08-24 17:47:01 INFO export.py L152: packing model.layers.2.mlp.gate_proj\n",
            "2024-08-24 17:47:03 INFO export.py L152: packing model.layers.2.mlp.up_proj\n",
            "2024-08-24 17:47:04 INFO export.py L152: packing model.layers.2.mlp.down_proj\n",
            "2024-08-24 17:47:06 INFO export.py L152: packing model.layers.3.self_attn.q_proj\n",
            "2024-08-24 17:47:06 INFO export.py L152: packing model.layers.3.self_attn.k_proj\n",
            "2024-08-24 17:47:07 INFO export.py L152: packing model.layers.3.self_attn.v_proj\n",
            "2024-08-24 17:47:07 INFO export.py L152: packing model.layers.3.self_attn.o_proj\n",
            "2024-08-24 17:47:07 INFO export.py L152: packing model.layers.3.mlp.gate_proj\n",
            "2024-08-24 17:47:09 INFO export.py L152: packing model.layers.3.mlp.up_proj\n",
            "2024-08-24 17:47:11 INFO export.py L152: packing model.layers.3.mlp.down_proj\n",
            "2024-08-24 17:47:12 INFO export.py L152: packing model.layers.4.self_attn.q_proj\n",
            "2024-08-24 17:47:13 INFO export.py L152: packing model.layers.4.self_attn.k_proj\n",
            "2024-08-24 17:47:13 INFO export.py L152: packing model.layers.4.self_attn.v_proj\n",
            "2024-08-24 17:47:13 INFO export.py L152: packing model.layers.4.self_attn.o_proj\n",
            "2024-08-24 17:47:14 INFO export.py L152: packing model.layers.4.mlp.gate_proj\n",
            "2024-08-24 17:47:16 INFO export.py L152: packing model.layers.4.mlp.up_proj\n",
            "2024-08-24 17:47:17 INFO export.py L152: packing model.layers.4.mlp.down_proj\n",
            "2024-08-24 17:47:19 INFO export.py L152: packing model.layers.5.self_attn.q_proj\n",
            "2024-08-24 17:47:19 INFO export.py L152: packing model.layers.5.self_attn.k_proj\n",
            "2024-08-24 17:47:20 INFO export.py L152: packing model.layers.5.self_attn.v_proj\n",
            "2024-08-24 17:47:20 INFO export.py L152: packing model.layers.5.self_attn.o_proj\n",
            "2024-08-24 17:47:20 INFO export.py L152: packing model.layers.5.mlp.gate_proj\n",
            "2024-08-24 17:47:22 INFO export.py L152: packing model.layers.5.mlp.up_proj\n",
            "2024-08-24 17:47:24 INFO export.py L152: packing model.layers.5.mlp.down_proj\n",
            "2024-08-24 17:47:25 INFO export.py L152: packing model.layers.6.self_attn.q_proj\n",
            "2024-08-24 17:47:26 INFO export.py L152: packing model.layers.6.self_attn.k_proj\n",
            "2024-08-24 17:47:26 INFO export.py L152: packing model.layers.6.self_attn.v_proj\n",
            "2024-08-24 17:47:27 INFO export.py L152: packing model.layers.6.self_attn.o_proj\n",
            "2024-08-24 17:47:27 INFO export.py L152: packing model.layers.6.mlp.gate_proj\n",
            "2024-08-24 17:47:29 INFO export.py L152: packing model.layers.6.mlp.up_proj\n",
            "2024-08-24 17:47:31 INFO export.py L152: packing model.layers.6.mlp.down_proj\n",
            "2024-08-24 17:47:32 INFO export.py L152: packing model.layers.7.self_attn.q_proj\n",
            "2024-08-24 17:47:33 INFO export.py L152: packing model.layers.7.self_attn.k_proj\n",
            "2024-08-24 17:47:33 INFO export.py L152: packing model.layers.7.self_attn.v_proj\n",
            "2024-08-24 17:47:33 INFO export.py L152: packing model.layers.7.self_attn.o_proj\n",
            "2024-08-24 17:47:34 INFO export.py L152: packing model.layers.7.mlp.gate_proj\n",
            "2024-08-24 17:47:36 INFO export.py L152: packing model.layers.7.mlp.up_proj\n",
            "2024-08-24 17:47:37 INFO export.py L152: packing model.layers.7.mlp.down_proj\n",
            "2024-08-24 17:47:39 INFO export.py L152: packing model.layers.8.self_attn.q_proj\n",
            "2024-08-24 17:47:40 INFO export.py L152: packing model.layers.8.self_attn.k_proj\n",
            "2024-08-24 17:47:40 INFO export.py L152: packing model.layers.8.self_attn.v_proj\n",
            "2024-08-24 17:47:40 INFO export.py L152: packing model.layers.8.self_attn.o_proj\n",
            "2024-08-24 17:47:41 INFO export.py L152: packing model.layers.8.mlp.gate_proj\n",
            "2024-08-24 17:47:42 INFO export.py L152: packing model.layers.8.mlp.up_proj\n",
            "2024-08-24 17:47:44 INFO export.py L152: packing model.layers.8.mlp.down_proj\n",
            "2024-08-24 17:47:46 INFO export.py L152: packing model.layers.9.self_attn.q_proj\n",
            "2024-08-24 17:47:46 INFO export.py L152: packing model.layers.9.self_attn.k_proj\n",
            "2024-08-24 17:47:46 INFO export.py L152: packing model.layers.9.self_attn.v_proj\n",
            "2024-08-24 17:47:47 INFO export.py L152: packing model.layers.9.self_attn.o_proj\n",
            "2024-08-24 17:47:47 INFO export.py L152: packing model.layers.9.mlp.gate_proj\n",
            "2024-08-24 17:47:49 INFO export.py L152: packing model.layers.9.mlp.up_proj\n",
            "2024-08-24 17:47:51 INFO export.py L152: packing model.layers.9.mlp.down_proj\n",
            "2024-08-24 17:47:52 INFO export.py L152: packing model.layers.10.self_attn.q_proj\n",
            "2024-08-24 17:47:53 INFO export.py L152: packing model.layers.10.self_attn.k_proj\n",
            "2024-08-24 17:47:53 INFO export.py L152: packing model.layers.10.self_attn.v_proj\n",
            "2024-08-24 17:47:53 INFO export.py L152: packing model.layers.10.self_attn.o_proj\n",
            "2024-08-24 17:47:54 INFO export.py L152: packing model.layers.10.mlp.gate_proj\n",
            "2024-08-24 17:47:55 INFO export.py L152: packing model.layers.10.mlp.up_proj\n",
            "2024-08-24 17:47:57 INFO export.py L152: packing model.layers.10.mlp.down_proj\n",
            "2024-08-24 17:47:59 INFO export.py L152: packing model.layers.11.self_attn.q_proj\n",
            "2024-08-24 17:47:59 INFO export.py L152: packing model.layers.11.self_attn.k_proj\n",
            "2024-08-24 17:48:00 INFO export.py L152: packing model.layers.11.self_attn.v_proj\n",
            "2024-08-24 17:48:00 INFO export.py L152: packing model.layers.11.self_attn.o_proj\n",
            "2024-08-24 17:48:00 INFO export.py L152: packing model.layers.11.mlp.gate_proj\n",
            "2024-08-24 17:48:02 INFO export.py L152: packing model.layers.11.mlp.up_proj\n",
            "2024-08-24 17:48:04 INFO export.py L152: packing model.layers.11.mlp.down_proj\n",
            "2024-08-24 17:48:05 INFO export.py L152: packing model.layers.12.self_attn.q_proj\n",
            "2024-08-24 17:48:06 INFO export.py L152: packing model.layers.12.self_attn.k_proj\n",
            "2024-08-24 17:48:06 INFO export.py L152: packing model.layers.12.self_attn.v_proj\n",
            "2024-08-24 17:48:06 INFO export.py L152: packing model.layers.12.self_attn.o_proj\n",
            "2024-08-24 17:48:07 INFO export.py L152: packing model.layers.12.mlp.gate_proj\n",
            "2024-08-24 17:48:09 INFO export.py L152: packing model.layers.12.mlp.up_proj\n",
            "2024-08-24 17:48:11 INFO export.py L152: packing model.layers.12.mlp.down_proj\n",
            "2024-08-24 17:48:12 INFO export.py L152: packing model.layers.13.self_attn.q_proj\n",
            "2024-08-24 17:48:13 INFO export.py L152: packing model.layers.13.self_attn.k_proj\n",
            "2024-08-24 17:48:13 INFO export.py L152: packing model.layers.13.self_attn.v_proj\n",
            "2024-08-24 17:48:13 INFO export.py L152: packing model.layers.13.self_attn.o_proj\n",
            "2024-08-24 17:48:14 INFO export.py L152: packing model.layers.13.mlp.gate_proj\n",
            "2024-08-24 17:48:16 INFO export.py L152: packing model.layers.13.mlp.up_proj\n",
            "2024-08-24 17:48:17 INFO export.py L152: packing model.layers.13.mlp.down_proj\n",
            "2024-08-24 17:48:19 INFO export.py L152: packing model.layers.14.self_attn.q_proj\n",
            "2024-08-24 17:48:19 INFO export.py L152: packing model.layers.14.self_attn.k_proj\n",
            "2024-08-24 17:48:20 INFO export.py L152: packing model.layers.14.self_attn.v_proj\n",
            "2024-08-24 17:48:20 INFO export.py L152: packing model.layers.14.self_attn.o_proj\n",
            "2024-08-24 17:48:20 INFO export.py L152: packing model.layers.14.mlp.gate_proj\n",
            "2024-08-24 17:48:22 INFO export.py L152: packing model.layers.14.mlp.up_proj\n",
            "2024-08-24 17:48:24 INFO export.py L152: packing model.layers.14.mlp.down_proj\n",
            "2024-08-24 17:48:25 INFO export.py L152: packing model.layers.15.self_attn.q_proj\n",
            "2024-08-24 17:48:26 INFO export.py L152: packing model.layers.15.self_attn.k_proj\n",
            "2024-08-24 17:48:26 INFO export.py L152: packing model.layers.15.self_attn.v_proj\n",
            "2024-08-24 17:48:27 INFO export.py L152: packing model.layers.15.self_attn.o_proj\n",
            "2024-08-24 17:48:27 INFO export.py L152: packing model.layers.15.mlp.gate_proj\n",
            "2024-08-24 17:48:29 INFO export.py L152: packing model.layers.15.mlp.up_proj\n",
            "2024-08-24 17:48:31 INFO export.py L152: packing model.layers.15.mlp.down_proj\n",
            "2024-08-24 17:48:32 INFO export.py L152: packing model.layers.16.self_attn.q_proj\n",
            "2024-08-24 17:48:33 INFO export.py L152: packing model.layers.16.self_attn.k_proj\n",
            "2024-08-24 17:48:33 INFO export.py L152: packing model.layers.16.self_attn.v_proj\n",
            "2024-08-24 17:48:33 INFO export.py L152: packing model.layers.16.self_attn.o_proj\n",
            "2024-08-24 17:48:34 INFO export.py L152: packing model.layers.16.mlp.gate_proj\n",
            "2024-08-24 17:48:35 INFO export.py L152: packing model.layers.16.mlp.up_proj\n",
            "2024-08-24 17:48:37 INFO export.py L152: packing model.layers.16.mlp.down_proj\n",
            "2024-08-24 17:48:39 INFO export.py L152: packing model.layers.17.self_attn.q_proj\n",
            "2024-08-24 17:48:39 INFO export.py L152: packing model.layers.17.self_attn.k_proj\n",
            "2024-08-24 17:48:39 INFO export.py L152: packing model.layers.17.self_attn.v_proj\n",
            "2024-08-24 17:48:40 INFO export.py L152: packing model.layers.17.self_attn.o_proj\n",
            "2024-08-24 17:48:40 INFO export.py L152: packing model.layers.17.mlp.gate_proj\n",
            "2024-08-24 17:48:42 INFO export.py L152: packing model.layers.17.mlp.up_proj\n",
            "2024-08-24 17:48:44 INFO export.py L152: packing model.layers.17.mlp.down_proj\n",
            "2024-08-24 17:48:45 INFO export.py L152: packing model.layers.18.self_attn.q_proj\n",
            "2024-08-24 17:48:46 INFO export.py L152: packing model.layers.18.self_attn.k_proj\n",
            "2024-08-24 17:48:46 INFO export.py L152: packing model.layers.18.self_attn.v_proj\n",
            "2024-08-24 17:48:46 INFO export.py L152: packing model.layers.18.self_attn.o_proj\n",
            "2024-08-24 17:48:47 INFO export.py L152: packing model.layers.18.mlp.gate_proj\n",
            "2024-08-24 17:48:49 INFO export.py L152: packing model.layers.18.mlp.up_proj\n",
            "2024-08-24 17:48:50 INFO export.py L152: packing model.layers.18.mlp.down_proj\n",
            "2024-08-24 17:48:52 INFO export.py L152: packing model.layers.19.self_attn.q_proj\n",
            "2024-08-24 17:48:53 INFO export.py L152: packing model.layers.19.self_attn.k_proj\n",
            "2024-08-24 17:48:53 INFO export.py L152: packing model.layers.19.self_attn.v_proj\n",
            "2024-08-24 17:48:53 INFO export.py L152: packing model.layers.19.self_attn.o_proj\n",
            "2024-08-24 17:48:54 INFO export.py L152: packing model.layers.19.mlp.gate_proj\n",
            "2024-08-24 17:48:55 INFO export.py L152: packing model.layers.19.mlp.up_proj\n",
            "2024-08-24 17:48:57 INFO export.py L152: packing model.layers.19.mlp.down_proj\n",
            "2024-08-24 17:48:59 INFO export.py L152: packing model.layers.20.self_attn.q_proj\n",
            "2024-08-24 17:48:59 INFO export.py L152: packing model.layers.20.self_attn.k_proj\n",
            "2024-08-24 17:48:59 INFO export.py L152: packing model.layers.20.self_attn.v_proj\n",
            "2024-08-24 17:49:00 INFO export.py L152: packing model.layers.20.self_attn.o_proj\n",
            "2024-08-24 17:49:00 INFO export.py L152: packing model.layers.20.mlp.gate_proj\n",
            "2024-08-24 17:49:02 INFO export.py L152: packing model.layers.20.mlp.up_proj\n",
            "2024-08-24 17:49:04 INFO export.py L152: packing model.layers.20.mlp.down_proj\n",
            "2024-08-24 17:49:05 INFO export.py L152: packing model.layers.21.self_attn.q_proj\n",
            "2024-08-24 17:49:06 INFO export.py L152: packing model.layers.21.self_attn.k_proj\n",
            "2024-08-24 17:49:06 INFO export.py L152: packing model.layers.21.self_attn.v_proj\n",
            "2024-08-24 17:49:06 INFO export.py L152: packing model.layers.21.self_attn.o_proj\n",
            "2024-08-24 17:49:07 INFO export.py L152: packing model.layers.21.mlp.gate_proj\n",
            "2024-08-24 17:49:09 INFO export.py L152: packing model.layers.21.mlp.up_proj\n",
            "2024-08-24 17:49:10 INFO export.py L152: packing model.layers.21.mlp.down_proj\n",
            "2024-08-24 17:49:12 INFO export.py L152: packing model.layers.22.self_attn.q_proj\n",
            "2024-08-24 17:49:13 INFO export.py L152: packing model.layers.22.self_attn.k_proj\n",
            "2024-08-24 17:49:13 INFO export.py L152: packing model.layers.22.self_attn.v_proj\n",
            "2024-08-24 17:49:13 INFO export.py L152: packing model.layers.22.self_attn.o_proj\n",
            "2024-08-24 17:49:14 INFO export.py L152: packing model.layers.22.mlp.gate_proj\n",
            "2024-08-24 17:49:15 INFO export.py L152: packing model.layers.22.mlp.up_proj\n",
            "2024-08-24 17:49:17 INFO export.py L152: packing model.layers.22.mlp.down_proj\n",
            "2024-08-24 17:49:18 INFO export.py L152: packing model.layers.23.self_attn.q_proj\n",
            "2024-08-24 17:49:19 INFO export.py L152: packing model.layers.23.self_attn.k_proj\n",
            "2024-08-24 17:49:19 INFO export.py L152: packing model.layers.23.self_attn.v_proj\n",
            "2024-08-24 17:49:20 INFO export.py L152: packing model.layers.23.self_attn.o_proj\n",
            "2024-08-24 17:49:20 INFO export.py L152: packing model.layers.23.mlp.gate_proj\n",
            "2024-08-24 17:49:22 INFO export.py L152: packing model.layers.23.mlp.up_proj\n",
            "2024-08-24 17:49:24 INFO export.py L152: packing model.layers.23.mlp.down_proj\n",
            "2024-08-24 17:49:25 INFO export.py L152: packing model.layers.24.self_attn.q_proj\n",
            "2024-08-24 17:49:26 INFO export.py L152: packing model.layers.24.self_attn.k_proj\n",
            "2024-08-24 17:49:26 INFO export.py L152: packing model.layers.24.self_attn.v_proj\n",
            "2024-08-24 17:49:26 INFO export.py L152: packing model.layers.24.self_attn.o_proj\n",
            "2024-08-24 17:49:27 INFO export.py L152: packing model.layers.24.mlp.gate_proj\n",
            "2024-08-24 17:49:28 INFO export.py L152: packing model.layers.24.mlp.up_proj\n",
            "2024-08-24 17:49:30 INFO export.py L152: packing model.layers.24.mlp.down_proj\n",
            "2024-08-24 17:49:32 INFO export.py L152: packing model.layers.25.self_attn.q_proj\n",
            "2024-08-24 17:49:33 INFO export.py L152: packing model.layers.25.self_attn.k_proj\n",
            "2024-08-24 17:49:33 INFO export.py L152: packing model.layers.25.self_attn.v_proj\n",
            "2024-08-24 17:49:33 INFO export.py L152: packing model.layers.25.self_attn.o_proj\n",
            "2024-08-24 17:49:34 INFO export.py L152: packing model.layers.25.mlp.gate_proj\n",
            "2024-08-24 17:49:35 INFO export.py L152: packing model.layers.25.mlp.up_proj\n",
            "2024-08-24 17:49:37 INFO export.py L152: packing model.layers.25.mlp.down_proj\n",
            "2024-08-24 17:49:39 INFO export.py L152: packing model.layers.26.self_attn.q_proj\n",
            "2024-08-24 17:49:39 INFO export.py L152: packing model.layers.26.self_attn.k_proj\n",
            "2024-08-24 17:49:39 INFO export.py L152: packing model.layers.26.self_attn.v_proj\n",
            "2024-08-24 17:49:40 INFO export.py L152: packing model.layers.26.self_attn.o_proj\n",
            "2024-08-24 17:49:40 INFO export.py L152: packing model.layers.26.mlp.gate_proj\n",
            "2024-08-24 17:49:42 INFO export.py L152: packing model.layers.26.mlp.up_proj\n",
            "2024-08-24 17:49:44 INFO export.py L152: packing model.layers.26.mlp.down_proj\n",
            "2024-08-24 17:49:45 INFO export.py L152: packing model.layers.27.self_attn.q_proj\n",
            "2024-08-24 17:49:46 INFO export.py L152: packing model.layers.27.self_attn.k_proj\n",
            "2024-08-24 17:49:46 INFO export.py L152: packing model.layers.27.self_attn.v_proj\n",
            "2024-08-24 17:49:46 INFO export.py L152: packing model.layers.27.self_attn.o_proj\n",
            "2024-08-24 17:49:47 INFO export.py L152: packing model.layers.27.mlp.gate_proj\n",
            "2024-08-24 17:49:49 INFO export.py L152: packing model.layers.27.mlp.up_proj\n",
            "2024-08-24 17:49:50 INFO export.py L152: packing model.layers.27.mlp.down_proj\n",
            "2024-08-24 17:49:52 INFO export.py L152: packing model.layers.28.self_attn.q_proj\n",
            "2024-08-24 17:49:52 INFO export.py L152: packing model.layers.28.self_attn.k_proj\n",
            "2024-08-24 17:49:53 INFO export.py L152: packing model.layers.28.self_attn.v_proj\n",
            "2024-08-24 17:49:53 INFO export.py L152: packing model.layers.28.self_attn.o_proj\n",
            "2024-08-24 17:49:53 INFO export.py L152: packing model.layers.28.mlp.gate_proj\n",
            "2024-08-24 17:49:55 INFO export.py L152: packing model.layers.28.mlp.up_proj\n",
            "2024-08-24 17:49:57 INFO export.py L152: packing model.layers.28.mlp.down_proj\n",
            "2024-08-24 17:49:58 INFO export.py L152: packing model.layers.29.self_attn.q_proj\n",
            "2024-08-24 17:49:59 INFO export.py L152: packing model.layers.29.self_attn.k_proj\n",
            "2024-08-24 17:49:59 INFO export.py L152: packing model.layers.29.self_attn.v_proj\n",
            "2024-08-24 17:49:59 INFO export.py L152: packing model.layers.29.self_attn.o_proj\n",
            "2024-08-24 17:50:00 INFO export.py L152: packing model.layers.29.mlp.gate_proj\n",
            "2024-08-24 17:50:02 INFO export.py L152: packing model.layers.29.mlp.up_proj\n",
            "2024-08-24 17:50:03 INFO export.py L152: packing model.layers.29.mlp.down_proj\n",
            "2024-08-24 17:50:05 INFO export.py L152: packing model.layers.30.self_attn.q_proj\n",
            "2024-08-24 17:50:06 INFO export.py L152: packing model.layers.30.self_attn.k_proj\n",
            "2024-08-24 17:50:06 INFO export.py L152: packing model.layers.30.self_attn.v_proj\n",
            "2024-08-24 17:50:06 INFO export.py L152: packing model.layers.30.self_attn.o_proj\n",
            "2024-08-24 17:50:07 INFO export.py L152: packing model.layers.30.mlp.gate_proj\n",
            "2024-08-24 17:50:08 INFO export.py L152: packing model.layers.30.mlp.up_proj\n",
            "2024-08-24 17:50:10 INFO export.py L152: packing model.layers.30.mlp.down_proj\n",
            "2024-08-24 17:50:12 INFO export.py L152: packing model.layers.31.self_attn.q_proj\n",
            "2024-08-24 17:50:12 INFO export.py L152: packing model.layers.31.self_attn.k_proj\n",
            "2024-08-24 17:50:12 INFO export.py L152: packing model.layers.31.self_attn.v_proj\n",
            "2024-08-24 17:50:13 INFO export.py L152: packing model.layers.31.self_attn.o_proj\n",
            "2024-08-24 17:50:13 INFO export.py L152: packing model.layers.31.mlp.gate_proj\n",
            "2024-08-24 17:50:15 INFO export.py L152: packing model.layers.31.mlp.up_proj\n",
            "2024-08-24 17:50:17 INFO export.py L152: packing model.layers.31.mlp.down_proj\n",
            "2024-08-24 17:50:18 INFO export.py L152: packing model.layers.32.self_attn.q_proj\n",
            "2024-08-24 17:50:19 INFO export.py L152: packing model.layers.32.self_attn.k_proj\n",
            "2024-08-24 17:50:19 INFO export.py L152: packing model.layers.32.self_attn.v_proj\n",
            "2024-08-24 17:50:19 INFO export.py L152: packing model.layers.32.self_attn.o_proj\n",
            "2024-08-24 17:50:20 INFO export.py L152: packing model.layers.32.mlp.gate_proj\n",
            "2024-08-24 17:50:21 INFO export.py L152: packing model.layers.32.mlp.up_proj\n",
            "2024-08-24 17:50:23 INFO export.py L152: packing model.layers.32.mlp.down_proj\n",
            "2024-08-24 17:50:25 INFO export.py L152: packing model.layers.33.self_attn.q_proj\n",
            "2024-08-24 17:50:25 INFO export.py L152: packing model.layers.33.self_attn.k_proj\n",
            "2024-08-24 17:50:26 INFO export.py L152: packing model.layers.33.self_attn.v_proj\n",
            "2024-08-24 17:50:26 INFO export.py L152: packing model.layers.33.self_attn.o_proj\n",
            "2024-08-24 17:50:26 INFO export.py L152: packing model.layers.33.mlp.gate_proj\n",
            "2024-08-24 17:50:28 INFO export.py L152: packing model.layers.33.mlp.up_proj\n",
            "2024-08-24 17:50:30 INFO export.py L152: packing model.layers.33.mlp.down_proj\n",
            "2024-08-24 17:50:31 INFO export.py L152: packing model.layers.34.self_attn.q_proj\n",
            "2024-08-24 17:50:32 INFO export.py L152: packing model.layers.34.self_attn.k_proj\n",
            "2024-08-24 17:50:32 INFO export.py L152: packing model.layers.34.self_attn.v_proj\n",
            "2024-08-24 17:50:32 INFO export.py L152: packing model.layers.34.self_attn.o_proj\n",
            "2024-08-24 17:50:33 INFO export.py L152: packing model.layers.34.mlp.gate_proj\n",
            "2024-08-24 17:50:35 INFO export.py L152: packing model.layers.34.mlp.up_proj\n",
            "2024-08-24 17:50:36 INFO export.py L152: packing model.layers.34.mlp.down_proj\n",
            "2024-08-24 17:50:38 INFO export.py L152: packing model.layers.35.self_attn.q_proj\n",
            "2024-08-24 17:50:39 INFO export.py L152: packing model.layers.35.self_attn.k_proj\n",
            "2024-08-24 17:50:39 INFO export.py L152: packing model.layers.35.self_attn.v_proj\n",
            "2024-08-24 17:50:39 INFO export.py L152: packing model.layers.35.self_attn.o_proj\n",
            "2024-08-24 17:50:40 INFO export.py L152: packing model.layers.35.mlp.gate_proj\n",
            "2024-08-24 17:50:41 INFO export.py L152: packing model.layers.35.mlp.up_proj\n",
            "2024-08-24 17:50:43 INFO export.py L152: packing model.layers.35.mlp.down_proj\n",
            "2024-08-24 17:50:45 INFO export.py L152: packing model.layers.36.self_attn.q_proj\n",
            "2024-08-24 17:50:45 INFO export.py L152: packing model.layers.36.self_attn.k_proj\n",
            "2024-08-24 17:50:45 INFO export.py L152: packing model.layers.36.self_attn.v_proj\n",
            "2024-08-24 17:50:46 INFO export.py L152: packing model.layers.36.self_attn.o_proj\n",
            "2024-08-24 17:50:46 INFO export.py L152: packing model.layers.36.mlp.gate_proj\n",
            "2024-08-24 17:50:48 INFO export.py L152: packing model.layers.36.mlp.up_proj\n",
            "2024-08-24 17:50:49 INFO export.py L152: packing model.layers.36.mlp.down_proj\n",
            "2024-08-24 17:50:51 INFO export.py L152: packing model.layers.37.self_attn.q_proj\n",
            "2024-08-24 17:50:52 INFO export.py L152: packing model.layers.37.self_attn.k_proj\n",
            "2024-08-24 17:50:52 INFO export.py L152: packing model.layers.37.self_attn.v_proj\n",
            "2024-08-24 17:50:52 INFO export.py L152: packing model.layers.37.self_attn.o_proj\n",
            "2024-08-24 17:50:53 INFO export.py L152: packing model.layers.37.mlp.gate_proj\n",
            "2024-08-24 17:50:55 INFO export.py L152: packing model.layers.37.mlp.up_proj\n",
            "2024-08-24 17:50:56 INFO export.py L152: packing model.layers.37.mlp.down_proj\n",
            "2024-08-24 17:50:58 INFO export.py L152: packing model.layers.38.self_attn.q_proj\n",
            "2024-08-24 17:50:58 INFO export.py L152: packing model.layers.38.self_attn.k_proj\n",
            "2024-08-24 17:50:59 INFO export.py L152: packing model.layers.38.self_attn.v_proj\n",
            "2024-08-24 17:50:59 INFO export.py L152: packing model.layers.38.self_attn.o_proj\n",
            "2024-08-24 17:51:00 INFO export.py L152: packing model.layers.38.mlp.gate_proj\n",
            "2024-08-24 17:51:01 INFO export.py L152: packing model.layers.38.mlp.up_proj\n",
            "2024-08-24 17:51:03 INFO export.py L152: packing model.layers.38.mlp.down_proj\n",
            "2024-08-24 17:51:05 INFO export.py L152: packing model.layers.39.self_attn.q_proj\n",
            "2024-08-24 17:51:06 INFO export.py L152: packing model.layers.39.self_attn.k_proj\n",
            "2024-08-24 17:51:06 INFO export.py L152: packing model.layers.39.self_attn.v_proj\n",
            "2024-08-24 17:51:06 INFO export.py L152: packing model.layers.39.self_attn.o_proj\n",
            "2024-08-24 17:51:07 INFO export.py L152: packing model.layers.39.mlp.gate_proj\n",
            "2024-08-24 17:51:08 INFO export.py L152: packing model.layers.39.mlp.up_proj\n",
            "2024-08-24 17:51:10 INFO export.py L152: packing model.layers.39.mlp.down_proj\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "model_name = \"nvidia/Mistral-NeMo-Minitron-8B-Base\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "from auto_round import AutoRound\n",
        "\n",
        "bits, group_size, sym = 4, 128, False\n",
        "autoround = AutoRound(model, tokenizer, bits=bits, group_size=group_size, batch_size=2, seqlen=512, sym=sym, gradient_accumulate_steps=4, device='cuda')\n",
        "autoround.quantize()\n",
        "output_dir = \"./AutoRound/Mistral-NeMo-Minitron-8B-Base-AutoRound-GPTQ-asym-4bit/\"\n",
        "autoround.save_quantized(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example for a 2-bit quantization (not used in the article; if you want the model, contact me)."
      ],
      "metadata": {
        "id": "oQlTrwkMEz7E"
      },
      "id": "oQlTrwkMEz7E"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0adef7d-26ae-41ca-8757-51b24b4f3aa0",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "adf161b79c0c431982cb9861b571250a"
          ]
        },
        "id": "d0adef7d-26ae-41ca-8757-51b24b4f3aa0",
        "outputId": "47828c26-b1c3-4b29-b505-3d7bf75a04bf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "adf161b79c0c431982cb9861b571250a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-08-22 20:02:05 INFO autoround.py L209: using torch.float16 for quantization tuning\n",
            "2024-08-22 20:02:08,430 INFO config.py L59: PyTorch version 2.1.0+cu118 available.\n",
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
            "2024-08-22 20:02:21 INFO autoround.py L1039: quantizing 1/40, model.layers.0\n",
            "2024-08-22 20:03:16 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.197240 -> iter 193: 0.001448\n",
            "2024-08-22 20:03:17 INFO autoround.py L1039: quantizing 2/40, model.layers.1\n",
            "2024-08-22 20:04:12 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.003790 -> iter 152: 0.000544\n",
            "2024-08-22 20:04:13 INFO autoround.py L1039: quantizing 3/40, model.layers.2\n",
            "2024-08-22 20:05:08 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.222797 -> iter 118: 0.005667\n",
            "2024-08-22 20:05:08 INFO autoround.py L1039: quantizing 4/40, model.layers.3\n",
            "2024-08-22 20:06:04 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.012412 -> iter 169: 0.003764\n",
            "2024-08-22 20:06:05 INFO autoround.py L1039: quantizing 5/40, model.layers.4\n",
            "2024-08-22 20:07:00 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.015921 -> iter 179: 0.004532\n",
            "2024-08-22 20:07:01 INFO autoround.py L1039: quantizing 6/40, model.layers.5\n",
            "2024-08-22 20:07:57 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.014499 -> iter 185: 0.005780\n",
            "2024-08-22 20:07:58 INFO autoround.py L1039: quantizing 7/40, model.layers.6\n",
            "2024-08-22 20:08:53 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.021159 -> iter 198: 0.006752\n",
            "2024-08-22 20:08:54 INFO autoround.py L1039: quantizing 8/40, model.layers.7\n",
            "2024-08-22 20:09:50 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.036181 -> iter 187: 0.008570\n",
            "2024-08-22 20:09:51 INFO autoround.py L1039: quantizing 9/40, model.layers.8\n",
            "2024-08-22 20:10:47 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.027999 -> iter 198: 0.010253\n",
            "2024-08-22 20:10:48 INFO autoround.py L1039: quantizing 10/40, model.layers.9\n",
            "2024-08-22 20:11:44 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.049366 -> iter 199: 0.011974\n",
            "2024-08-22 20:11:45 INFO autoround.py L1039: quantizing 11/40, model.layers.10\n",
            "2024-08-22 20:12:41 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.036660 -> iter 189: 0.012638\n",
            "2024-08-22 20:12:42 INFO autoround.py L1039: quantizing 12/40, model.layers.11\n",
            "2024-08-22 20:13:38 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.039984 -> iter 196: 0.014414\n",
            "2024-08-22 20:13:39 INFO autoround.py L1039: quantizing 13/40, model.layers.12\n",
            "2024-08-22 20:14:34 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.041311 -> iter 199: 0.015751\n",
            "2024-08-22 20:14:35 INFO autoround.py L1039: quantizing 14/40, model.layers.13\n",
            "2024-08-22 20:15:31 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.059798 -> iter 177: 0.019301\n",
            "2024-08-22 20:15:32 INFO autoround.py L1039: quantizing 15/40, model.layers.14\n",
            "2024-08-22 20:16:28 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.078633 -> iter 198: 0.020900\n",
            "2024-08-22 20:16:29 INFO autoround.py L1039: quantizing 16/40, model.layers.15\n",
            "2024-08-22 20:17:24 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.077472 -> iter 169: 0.022832\n",
            "2024-08-22 20:17:25 INFO autoround.py L1039: quantizing 17/40, model.layers.16\n",
            "2024-08-22 20:18:20 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.088247 -> iter 193: 0.026575\n",
            "2024-08-22 20:18:21 INFO autoround.py L1039: quantizing 18/40, model.layers.17\n",
            "2024-08-22 20:19:17 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.078732 -> iter 197: 0.029281\n",
            "2024-08-22 20:19:18 INFO autoround.py L1039: quantizing 19/40, model.layers.18\n",
            "2024-08-22 20:20:13 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.114220 -> iter 197: 0.036288\n",
            "2024-08-22 20:20:14 INFO autoround.py L1039: quantizing 20/40, model.layers.19\n",
            "2024-08-22 20:21:10 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.112854 -> iter 188: 0.044584\n",
            "2024-08-22 20:21:11 INFO autoround.py L1039: quantizing 21/40, model.layers.20\n",
            "2024-08-22 20:22:07 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.109426 -> iter 187: 0.051096\n",
            "2024-08-22 20:22:08 INFO autoround.py L1039: quantizing 22/40, model.layers.21\n",
            "2024-08-22 20:23:03 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.154562 -> iter 187: 0.055782\n",
            "2024-08-22 20:23:04 INFO autoround.py L1039: quantizing 23/40, model.layers.22\n",
            "2024-08-22 20:24:01 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.153327 -> iter 192: 0.066184\n",
            "2024-08-22 20:24:02 INFO autoround.py L1039: quantizing 24/40, model.layers.23\n",
            "2024-08-22 20:24:58 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.164319 -> iter 180: 0.076467\n",
            "2024-08-22 20:24:58 INFO autoround.py L1039: quantizing 25/40, model.layers.24\n",
            "2024-08-22 20:25:54 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.221741 -> iter 187: 0.094693\n",
            "2024-08-22 20:25:55 INFO autoround.py L1039: quantizing 26/40, model.layers.25\n",
            "2024-08-22 20:26:50 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.238136 -> iter 188: 0.112767\n",
            "2024-08-22 20:26:51 INFO autoround.py L1039: quantizing 27/40, model.layers.26\n",
            "2024-08-22 20:27:46 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.233493 -> iter 194: 0.126581\n",
            "2024-08-22 20:27:47 INFO autoround.py L1039: quantizing 28/40, model.layers.27\n",
            "2024-08-22 20:28:43 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.272622 -> iter 171: 0.138574\n",
            "2024-08-22 20:28:44 INFO autoround.py L1039: quantizing 29/40, model.layers.28\n",
            "2024-08-22 20:29:40 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.316939 -> iter 171: 0.161398\n",
            "2024-08-22 20:29:40 INFO autoround.py L1039: quantizing 30/40, model.layers.29\n",
            "2024-08-22 20:30:37 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.363677 -> iter 174: 0.183470\n",
            "2024-08-22 20:30:38 INFO autoround.py L1039: quantizing 31/40, model.layers.30\n",
            "2024-08-22 20:31:33 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.373628 -> iter 162: 0.203061\n",
            "2024-08-22 20:31:34 INFO autoround.py L1039: quantizing 32/40, model.layers.31\n",
            "2024-08-22 20:32:30 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.446800 -> iter 142: 0.234497\n",
            "2024-08-22 20:32:30 INFO autoround.py L1039: quantizing 33/40, model.layers.32\n",
            "2024-08-22 20:33:27 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.543240 -> iter 182: 0.240133\n",
            "2024-08-22 20:33:27 INFO autoround.py L1039: quantizing 34/40, model.layers.33\n",
            "2024-08-22 20:34:25 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.594406 -> iter 181: 0.305505\n",
            "2024-08-22 20:34:25 INFO autoround.py L1039: quantizing 35/40, model.layers.34\n",
            "2024-08-22 20:35:23 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.894533 -> iter 122: 0.354890\n",
            "2024-08-22 20:35:24 INFO autoround.py L1039: quantizing 36/40, model.layers.35\n",
            "2024-08-22 20:36:22 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.905462 -> iter 199: 0.418572\n",
            "2024-08-22 20:36:22 INFO autoround.py L1039: quantizing 37/40, model.layers.36\n",
            "2024-08-22 20:37:18 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 1.224628 -> iter 106: 0.543288\n",
            "2024-08-22 20:37:19 INFO autoround.py L1039: quantizing 38/40, model.layers.37\n",
            "2024-08-22 20:38:15 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 1.983304 -> iter 175: 0.739281\n",
            "2024-08-22 20:38:16 INFO autoround.py L1039: quantizing 39/40, model.layers.38\n",
            "2024-08-22 20:39:11 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 3.434111 -> iter 195: 1.015065\n",
            "2024-08-22 20:39:12 INFO autoround.py L1039: quantizing 40/40, model.layers.39\n",
            "2024-08-22 20:40:08 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 6.452668 -> iter 197: 1.599477\n",
            "2024-08-22 20:40:09 INFO autoround.py L288: quantization tuning time 2283.8545954227448\n",
            "2024-08-22 20:40:09 INFO autoround.py L304: Summary: quantized 280/281 in the model,  ['lm_head'] have not been quantized\n",
            "2024-08-22 20:40:09 INFO export.py L112: Saving quantized model to autogptq format, this may take a while...\n",
            "2024-08-22 20:40:09 INFO export.py L152: packing model.layers.0.self_attn.q_proj\n",
            "2024-08-22 20:40:10 INFO export.py L152: packing model.layers.0.self_attn.k_proj\n",
            "2024-08-22 20:40:10 INFO export.py L152: packing model.layers.0.self_attn.v_proj\n",
            "2024-08-22 20:40:10 INFO export.py L152: packing model.layers.0.self_attn.o_proj\n",
            "2024-08-22 20:40:11 INFO export.py L152: packing model.layers.0.mlp.gate_proj\n",
            "2024-08-22 20:40:12 INFO export.py L152: packing model.layers.0.mlp.up_proj\n",
            "2024-08-22 20:40:13 INFO export.py L152: packing model.layers.0.mlp.down_proj\n",
            "2024-08-22 20:40:14 INFO export.py L152: packing model.layers.1.self_attn.q_proj\n",
            "2024-08-22 20:40:15 INFO export.py L152: packing model.layers.1.self_attn.k_proj\n",
            "2024-08-22 20:40:15 INFO export.py L152: packing model.layers.1.self_attn.v_proj\n",
            "2024-08-22 20:40:15 INFO export.py L152: packing model.layers.1.self_attn.o_proj\n",
            "2024-08-22 20:40:16 INFO export.py L152: packing model.layers.1.mlp.gate_proj\n",
            "2024-08-22 20:40:17 INFO export.py L152: packing model.layers.1.mlp.up_proj\n",
            "2024-08-22 20:40:19 INFO export.py L152: packing model.layers.1.mlp.down_proj\n",
            "2024-08-22 20:40:20 INFO export.py L152: packing model.layers.2.self_attn.q_proj\n",
            "2024-08-22 20:40:20 INFO export.py L152: packing model.layers.2.self_attn.k_proj\n",
            "2024-08-22 20:40:21 INFO export.py L152: packing model.layers.2.self_attn.v_proj\n",
            "2024-08-22 20:40:21 INFO export.py L152: packing model.layers.2.self_attn.o_proj\n",
            "2024-08-22 20:40:21 INFO export.py L152: packing model.layers.2.mlp.gate_proj\n",
            "2024-08-22 20:40:22 INFO export.py L152: packing model.layers.2.mlp.up_proj\n",
            "2024-08-22 20:40:24 INFO export.py L152: packing model.layers.2.mlp.down_proj\n",
            "2024-08-22 20:40:25 INFO export.py L152: packing model.layers.3.self_attn.q_proj\n",
            "2024-08-22 20:40:25 INFO export.py L152: packing model.layers.3.self_attn.k_proj\n",
            "2024-08-22 20:40:25 INFO export.py L152: packing model.layers.3.self_attn.v_proj\n",
            "2024-08-22 20:40:26 INFO export.py L152: packing model.layers.3.self_attn.o_proj\n",
            "2024-08-22 20:40:26 INFO export.py L152: packing model.layers.3.mlp.gate_proj\n",
            "2024-08-22 20:40:27 INFO export.py L152: packing model.layers.3.mlp.up_proj\n",
            "2024-08-22 20:40:28 INFO export.py L152: packing model.layers.3.mlp.down_proj\n",
            "2024-08-22 20:40:30 INFO export.py L152: packing model.layers.4.self_attn.q_proj\n",
            "2024-08-22 20:40:30 INFO export.py L152: packing model.layers.4.self_attn.k_proj\n",
            "2024-08-22 20:40:31 INFO export.py L152: packing model.layers.4.self_attn.v_proj\n",
            "2024-08-22 20:40:31 INFO export.py L152: packing model.layers.4.self_attn.o_proj\n",
            "2024-08-22 20:40:31 INFO export.py L152: packing model.layers.4.mlp.gate_proj\n",
            "2024-08-22 20:40:32 INFO export.py L152: packing model.layers.4.mlp.up_proj\n",
            "2024-08-22 20:40:34 INFO export.py L152: packing model.layers.4.mlp.down_proj\n",
            "2024-08-22 20:40:35 INFO export.py L152: packing model.layers.5.self_attn.q_proj\n",
            "2024-08-22 20:40:35 INFO export.py L152: packing model.layers.5.self_attn.k_proj\n",
            "2024-08-22 20:40:36 INFO export.py L152: packing model.layers.5.self_attn.v_proj\n",
            "2024-08-22 20:40:36 INFO export.py L152: packing model.layers.5.self_attn.o_proj\n",
            "2024-08-22 20:40:36 INFO export.py L152: packing model.layers.5.mlp.gate_proj\n",
            "2024-08-22 20:40:37 INFO export.py L152: packing model.layers.5.mlp.up_proj\n",
            "2024-08-22 20:40:39 INFO export.py L152: packing model.layers.5.mlp.down_proj\n",
            "2024-08-22 20:40:40 INFO export.py L152: packing model.layers.6.self_attn.q_proj\n",
            "2024-08-22 20:40:40 INFO export.py L152: packing model.layers.6.self_attn.k_proj\n",
            "2024-08-22 20:40:41 INFO export.py L152: packing model.layers.6.self_attn.v_proj\n",
            "2024-08-22 20:40:41 INFO export.py L152: packing model.layers.6.self_attn.o_proj\n",
            "2024-08-22 20:40:41 INFO export.py L152: packing model.layers.6.mlp.gate_proj\n",
            "2024-08-22 20:40:43 INFO export.py L152: packing model.layers.6.mlp.up_proj\n",
            "2024-08-22 20:40:44 INFO export.py L152: packing model.layers.6.mlp.down_proj\n",
            "2024-08-22 20:40:45 INFO export.py L152: packing model.layers.7.self_attn.q_proj\n",
            "2024-08-22 20:40:46 INFO export.py L152: packing model.layers.7.self_attn.k_proj\n",
            "2024-08-22 20:40:46 INFO export.py L152: packing model.layers.7.self_attn.v_proj\n",
            "2024-08-22 20:40:46 INFO export.py L152: packing model.layers.7.self_attn.o_proj\n",
            "2024-08-22 20:40:47 INFO export.py L152: packing model.layers.7.mlp.gate_proj\n",
            "2024-08-22 20:40:48 INFO export.py L152: packing model.layers.7.mlp.up_proj\n",
            "2024-08-22 20:40:49 INFO export.py L152: packing model.layers.7.mlp.down_proj\n",
            "2024-08-22 20:40:51 INFO export.py L152: packing model.layers.8.self_attn.q_proj\n",
            "2024-08-22 20:40:51 INFO export.py L152: packing model.layers.8.self_attn.k_proj\n",
            "2024-08-22 20:40:52 INFO export.py L152: packing model.layers.8.self_attn.v_proj\n",
            "2024-08-22 20:40:52 INFO export.py L152: packing model.layers.8.self_attn.o_proj\n",
            "2024-08-22 20:40:52 INFO export.py L152: packing model.layers.8.mlp.gate_proj\n",
            "2024-08-22 20:40:54 INFO export.py L152: packing model.layers.8.mlp.up_proj\n",
            "2024-08-22 20:40:55 INFO export.py L152: packing model.layers.8.mlp.down_proj\n",
            "2024-08-22 20:40:56 INFO export.py L152: packing model.layers.9.self_attn.q_proj\n",
            "2024-08-22 20:40:57 INFO export.py L152: packing model.layers.9.self_attn.k_proj\n",
            "2024-08-22 20:40:57 INFO export.py L152: packing model.layers.9.self_attn.v_proj\n",
            "2024-08-22 20:40:57 INFO export.py L152: packing model.layers.9.self_attn.o_proj\n",
            "2024-08-22 20:40:58 INFO export.py L152: packing model.layers.9.mlp.gate_proj\n",
            "2024-08-22 20:40:59 INFO export.py L152: packing model.layers.9.mlp.up_proj\n",
            "2024-08-22 20:41:00 INFO export.py L152: packing model.layers.9.mlp.down_proj\n",
            "2024-08-22 20:41:01 INFO export.py L152: packing model.layers.10.self_attn.q_proj\n",
            "2024-08-22 20:41:02 INFO export.py L152: packing model.layers.10.self_attn.k_proj\n",
            "2024-08-22 20:41:02 INFO export.py L152: packing model.layers.10.self_attn.v_proj\n",
            "2024-08-22 20:41:02 INFO export.py L152: packing model.layers.10.self_attn.o_proj\n",
            "2024-08-22 20:41:03 INFO export.py L152: packing model.layers.10.mlp.gate_proj\n",
            "2024-08-22 20:41:04 INFO export.py L152: packing model.layers.10.mlp.up_proj\n",
            "2024-08-22 20:41:06 INFO export.py L152: packing model.layers.10.mlp.down_proj\n",
            "2024-08-22 20:41:07 INFO export.py L152: packing model.layers.11.self_attn.q_proj\n",
            "2024-08-22 20:41:07 INFO export.py L152: packing model.layers.11.self_attn.k_proj\n",
            "2024-08-22 20:41:08 INFO export.py L152: packing model.layers.11.self_attn.v_proj\n",
            "2024-08-22 20:41:08 INFO export.py L152: packing model.layers.11.self_attn.o_proj\n",
            "2024-08-22 20:41:08 INFO export.py L152: packing model.layers.11.mlp.gate_proj\n",
            "2024-08-22 20:41:10 INFO export.py L152: packing model.layers.11.mlp.up_proj\n",
            "2024-08-22 20:41:11 INFO export.py L152: packing model.layers.11.mlp.down_proj\n",
            "2024-08-22 20:41:12 INFO export.py L152: packing model.layers.12.self_attn.q_proj\n",
            "2024-08-22 20:41:13 INFO export.py L152: packing model.layers.12.self_attn.k_proj\n",
            "2024-08-22 20:41:13 INFO export.py L152: packing model.layers.12.self_attn.v_proj\n",
            "2024-08-22 20:41:14 INFO export.py L152: packing model.layers.12.self_attn.o_proj\n",
            "2024-08-22 20:41:14 INFO export.py L152: packing model.layers.12.mlp.gate_proj\n",
            "2024-08-22 20:41:15 INFO export.py L152: packing model.layers.12.mlp.up_proj\n",
            "2024-08-22 20:41:17 INFO export.py L152: packing model.layers.12.mlp.down_proj\n",
            "2024-08-22 20:41:18 INFO export.py L152: packing model.layers.13.self_attn.q_proj\n",
            "2024-08-22 20:41:18 INFO export.py L152: packing model.layers.13.self_attn.k_proj\n",
            "2024-08-22 20:41:19 INFO export.py L152: packing model.layers.13.self_attn.v_proj\n",
            "2024-08-22 20:41:19 INFO export.py L152: packing model.layers.13.self_attn.o_proj\n",
            "2024-08-22 20:41:19 INFO export.py L152: packing model.layers.13.mlp.gate_proj\n",
            "2024-08-22 20:41:21 INFO export.py L152: packing model.layers.13.mlp.up_proj\n",
            "2024-08-22 20:41:22 INFO export.py L152: packing model.layers.13.mlp.down_proj\n",
            "2024-08-22 20:41:23 INFO export.py L152: packing model.layers.14.self_attn.q_proj\n",
            "2024-08-22 20:41:24 INFO export.py L152: packing model.layers.14.self_attn.k_proj\n",
            "2024-08-22 20:41:24 INFO export.py L152: packing model.layers.14.self_attn.v_proj\n",
            "2024-08-22 20:41:24 INFO export.py L152: packing model.layers.14.self_attn.o_proj\n",
            "2024-08-22 20:41:24 INFO export.py L152: packing model.layers.14.mlp.gate_proj\n",
            "2024-08-22 20:41:26 INFO export.py L152: packing model.layers.14.mlp.up_proj\n",
            "2024-08-22 20:41:27 INFO export.py L152: packing model.layers.14.mlp.down_proj\n",
            "2024-08-22 20:41:28 INFO export.py L152: packing model.layers.15.self_attn.q_proj\n",
            "2024-08-22 20:41:29 INFO export.py L152: packing model.layers.15.self_attn.k_proj\n",
            "2024-08-22 20:41:29 INFO export.py L152: packing model.layers.15.self_attn.v_proj\n",
            "2024-08-22 20:41:29 INFO export.py L152: packing model.layers.15.self_attn.o_proj\n",
            "2024-08-22 20:41:30 INFO export.py L152: packing model.layers.15.mlp.gate_proj\n",
            "2024-08-22 20:41:31 INFO export.py L152: packing model.layers.15.mlp.up_proj\n",
            "2024-08-22 20:41:32 INFO export.py L152: packing model.layers.15.mlp.down_proj\n",
            "2024-08-22 20:41:33 INFO export.py L152: packing model.layers.16.self_attn.q_proj\n",
            "2024-08-22 20:41:34 INFO export.py L152: packing model.layers.16.self_attn.k_proj\n",
            "2024-08-22 20:41:34 INFO export.py L152: packing model.layers.16.self_attn.v_proj\n",
            "2024-08-22 20:41:34 INFO export.py L152: packing model.layers.16.self_attn.o_proj\n",
            "2024-08-22 20:41:35 INFO export.py L152: packing model.layers.16.mlp.gate_proj\n",
            "2024-08-22 20:41:36 INFO export.py L152: packing model.layers.16.mlp.up_proj\n",
            "2024-08-22 20:41:38 INFO export.py L152: packing model.layers.16.mlp.down_proj\n",
            "2024-08-22 20:41:39 INFO export.py L152: packing model.layers.17.self_attn.q_proj\n",
            "2024-08-22 20:41:39 INFO export.py L152: packing model.layers.17.self_attn.k_proj\n",
            "2024-08-22 20:41:40 INFO export.py L152: packing model.layers.17.self_attn.v_proj\n",
            "2024-08-22 20:41:40 INFO export.py L152: packing model.layers.17.self_attn.o_proj\n",
            "2024-08-22 20:41:40 INFO export.py L152: packing model.layers.17.mlp.gate_proj\n",
            "2024-08-22 20:41:42 INFO export.py L152: packing model.layers.17.mlp.up_proj\n",
            "2024-08-22 20:41:43 INFO export.py L152: packing model.layers.17.mlp.down_proj\n",
            "2024-08-22 20:41:44 INFO export.py L152: packing model.layers.18.self_attn.q_proj\n",
            "2024-08-22 20:41:44 INFO export.py L152: packing model.layers.18.self_attn.k_proj\n",
            "2024-08-22 20:41:45 INFO export.py L152: packing model.layers.18.self_attn.v_proj\n",
            "2024-08-22 20:41:45 INFO export.py L152: packing model.layers.18.self_attn.o_proj\n",
            "2024-08-22 20:41:45 INFO export.py L152: packing model.layers.18.mlp.gate_proj\n",
            "2024-08-22 20:41:47 INFO export.py L152: packing model.layers.18.mlp.up_proj\n",
            "2024-08-22 20:41:48 INFO export.py L152: packing model.layers.18.mlp.down_proj\n",
            "2024-08-22 20:41:49 INFO export.py L152: packing model.layers.19.self_attn.q_proj\n",
            "2024-08-22 20:41:50 INFO export.py L152: packing model.layers.19.self_attn.k_proj\n",
            "2024-08-22 20:41:50 INFO export.py L152: packing model.layers.19.self_attn.v_proj\n",
            "2024-08-22 20:41:50 INFO export.py L152: packing model.layers.19.self_attn.o_proj\n",
            "2024-08-22 20:41:51 INFO export.py L152: packing model.layers.19.mlp.gate_proj\n",
            "2024-08-22 20:41:52 INFO export.py L152: packing model.layers.19.mlp.up_proj\n",
            "2024-08-22 20:41:53 INFO export.py L152: packing model.layers.19.mlp.down_proj\n",
            "2024-08-22 20:41:54 INFO export.py L152: packing model.layers.20.self_attn.q_proj\n",
            "2024-08-22 20:41:55 INFO export.py L152: packing model.layers.20.self_attn.k_proj\n",
            "2024-08-22 20:41:55 INFO export.py L152: packing model.layers.20.self_attn.v_proj\n",
            "2024-08-22 20:41:55 INFO export.py L152: packing model.layers.20.self_attn.o_proj\n",
            "2024-08-22 20:41:56 INFO export.py L152: packing model.layers.20.mlp.gate_proj\n",
            "2024-08-22 20:41:57 INFO export.py L152: packing model.layers.20.mlp.up_proj\n",
            "2024-08-22 20:41:58 INFO export.py L152: packing model.layers.20.mlp.down_proj\n",
            "2024-08-22 20:42:00 INFO export.py L152: packing model.layers.21.self_attn.q_proj\n",
            "2024-08-22 20:42:00 INFO export.py L152: packing model.layers.21.self_attn.k_proj\n",
            "2024-08-22 20:42:00 INFO export.py L152: packing model.layers.21.self_attn.v_proj\n",
            "2024-08-22 20:42:01 INFO export.py L152: packing model.layers.21.self_attn.o_proj\n",
            "2024-08-22 20:42:01 INFO export.py L152: packing model.layers.21.mlp.gate_proj\n",
            "2024-08-22 20:42:03 INFO export.py L152: packing model.layers.21.mlp.up_proj\n",
            "2024-08-22 20:42:04 INFO export.py L152: packing model.layers.21.mlp.down_proj\n",
            "2024-08-22 20:42:05 INFO export.py L152: packing model.layers.22.self_attn.q_proj\n",
            "2024-08-22 20:42:06 INFO export.py L152: packing model.layers.22.self_attn.k_proj\n",
            "2024-08-22 20:42:06 INFO export.py L152: packing model.layers.22.self_attn.v_proj\n",
            "2024-08-22 20:42:06 INFO export.py L152: packing model.layers.22.self_attn.o_proj\n",
            "2024-08-22 20:42:07 INFO export.py L152: packing model.layers.22.mlp.gate_proj\n",
            "2024-08-22 20:42:08 INFO export.py L152: packing model.layers.22.mlp.up_proj\n",
            "2024-08-22 20:42:09 INFO export.py L152: packing model.layers.22.mlp.down_proj\n",
            "2024-08-22 20:42:11 INFO export.py L152: packing model.layers.23.self_attn.q_proj\n",
            "2024-08-22 20:42:11 INFO export.py L152: packing model.layers.23.self_attn.k_proj\n",
            "2024-08-22 20:42:11 INFO export.py L152: packing model.layers.23.self_attn.v_proj\n",
            "2024-08-22 20:42:12 INFO export.py L152: packing model.layers.23.self_attn.o_proj\n",
            "2024-08-22 20:42:12 INFO export.py L152: packing model.layers.23.mlp.gate_proj\n",
            "2024-08-22 20:42:14 INFO export.py L152: packing model.layers.23.mlp.up_proj\n",
            "2024-08-22 20:42:15 INFO export.py L152: packing model.layers.23.mlp.down_proj\n",
            "2024-08-22 20:42:16 INFO export.py L152: packing model.layers.24.self_attn.q_proj\n",
            "2024-08-22 20:42:17 INFO export.py L152: packing model.layers.24.self_attn.k_proj\n",
            "2024-08-22 20:42:17 INFO export.py L152: packing model.layers.24.self_attn.v_proj\n",
            "2024-08-22 20:42:17 INFO export.py L152: packing model.layers.24.self_attn.o_proj\n",
            "2024-08-22 20:42:17 INFO export.py L152: packing model.layers.24.mlp.gate_proj\n",
            "2024-08-22 20:42:19 INFO export.py L152: packing model.layers.24.mlp.up_proj\n",
            "2024-08-22 20:42:20 INFO export.py L152: packing model.layers.24.mlp.down_proj\n",
            "2024-08-22 20:42:21 INFO export.py L152: packing model.layers.25.self_attn.q_proj\n",
            "2024-08-22 20:42:22 INFO export.py L152: packing model.layers.25.self_attn.k_proj\n",
            "2024-08-22 20:42:22 INFO export.py L152: packing model.layers.25.self_attn.v_proj\n",
            "2024-08-22 20:42:22 INFO export.py L152: packing model.layers.25.self_attn.o_proj\n",
            "2024-08-22 20:42:23 INFO export.py L152: packing model.layers.25.mlp.gate_proj\n",
            "2024-08-22 20:42:24 INFO export.py L152: packing model.layers.25.mlp.up_proj\n",
            "2024-08-22 20:42:25 INFO export.py L152: packing model.layers.25.mlp.down_proj\n",
            "2024-08-22 20:42:26 INFO export.py L152: packing model.layers.26.self_attn.q_proj\n",
            "2024-08-22 20:42:27 INFO export.py L152: packing model.layers.26.self_attn.k_proj\n",
            "2024-08-22 20:42:27 INFO export.py L152: packing model.layers.26.self_attn.v_proj\n",
            "2024-08-22 20:42:27 INFO export.py L152: packing model.layers.26.self_attn.o_proj\n",
            "2024-08-22 20:42:28 INFO export.py L152: packing model.layers.26.mlp.gate_proj\n",
            "2024-08-22 20:42:29 INFO export.py L152: packing model.layers.26.mlp.up_proj\n",
            "2024-08-22 20:42:30 INFO export.py L152: packing model.layers.26.mlp.down_proj\n",
            "2024-08-22 20:42:32 INFO export.py L152: packing model.layers.27.self_attn.q_proj\n",
            "2024-08-22 20:42:32 INFO export.py L152: packing model.layers.27.self_attn.k_proj\n",
            "2024-08-22 20:42:32 INFO export.py L152: packing model.layers.27.self_attn.v_proj\n",
            "2024-08-22 20:42:33 INFO export.py L152: packing model.layers.27.self_attn.o_proj\n",
            "2024-08-22 20:42:33 INFO export.py L152: packing model.layers.27.mlp.gate_proj\n",
            "2024-08-22 20:42:34 INFO export.py L152: packing model.layers.27.mlp.up_proj\n",
            "2024-08-22 20:42:36 INFO export.py L152: packing model.layers.27.mlp.down_proj\n",
            "2024-08-22 20:42:37 INFO export.py L152: packing model.layers.28.self_attn.q_proj\n",
            "2024-08-22 20:42:37 INFO export.py L152: packing model.layers.28.self_attn.k_proj\n",
            "2024-08-22 20:42:38 INFO export.py L152: packing model.layers.28.self_attn.v_proj\n",
            "2024-08-22 20:42:38 INFO export.py L152: packing model.layers.28.self_attn.o_proj\n",
            "2024-08-22 20:42:38 INFO export.py L152: packing model.layers.28.mlp.gate_proj\n",
            "2024-08-22 20:42:40 INFO export.py L152: packing model.layers.28.mlp.up_proj\n",
            "2024-08-22 20:42:41 INFO export.py L152: packing model.layers.28.mlp.down_proj\n",
            "2024-08-22 20:42:42 INFO export.py L152: packing model.layers.29.self_attn.q_proj\n",
            "2024-08-22 20:42:42 INFO export.py L152: packing model.layers.29.self_attn.k_proj\n",
            "2024-08-22 20:42:43 INFO export.py L152: packing model.layers.29.self_attn.v_proj\n",
            "2024-08-22 20:42:43 INFO export.py L152: packing model.layers.29.self_attn.o_proj\n",
            "2024-08-22 20:42:43 INFO export.py L152: packing model.layers.29.mlp.gate_proj\n",
            "2024-08-22 20:42:45 INFO export.py L152: packing model.layers.29.mlp.up_proj\n",
            "2024-08-22 20:42:46 INFO export.py L152: packing model.layers.29.mlp.down_proj\n",
            "2024-08-22 20:42:47 INFO export.py L152: packing model.layers.30.self_attn.q_proj\n",
            "2024-08-22 20:42:48 INFO export.py L152: packing model.layers.30.self_attn.k_proj\n",
            "2024-08-22 20:42:48 INFO export.py L152: packing model.layers.30.self_attn.v_proj\n",
            "2024-08-22 20:42:48 INFO export.py L152: packing model.layers.30.self_attn.o_proj\n",
            "2024-08-22 20:42:49 INFO export.py L152: packing model.layers.30.mlp.gate_proj\n",
            "2024-08-22 20:42:50 INFO export.py L152: packing model.layers.30.mlp.up_proj\n",
            "2024-08-22 20:42:52 INFO export.py L152: packing model.layers.30.mlp.down_proj\n",
            "2024-08-22 20:42:53 INFO export.py L152: packing model.layers.31.self_attn.q_proj\n",
            "2024-08-22 20:42:53 INFO export.py L152: packing model.layers.31.self_attn.k_proj\n",
            "2024-08-22 20:42:54 INFO export.py L152: packing model.layers.31.self_attn.v_proj\n",
            "2024-08-22 20:42:54 INFO export.py L152: packing model.layers.31.self_attn.o_proj\n",
            "2024-08-22 20:42:54 INFO export.py L152: packing model.layers.31.mlp.gate_proj\n",
            "2024-08-22 20:42:56 INFO export.py L152: packing model.layers.31.mlp.up_proj\n",
            "2024-08-22 20:42:57 INFO export.py L152: packing model.layers.31.mlp.down_proj\n",
            "2024-08-22 20:42:58 INFO export.py L152: packing model.layers.32.self_attn.q_proj\n",
            "2024-08-22 20:42:59 INFO export.py L152: packing model.layers.32.self_attn.k_proj\n",
            "2024-08-22 20:42:59 INFO export.py L152: packing model.layers.32.self_attn.v_proj\n",
            "2024-08-22 20:42:59 INFO export.py L152: packing model.layers.32.self_attn.o_proj\n",
            "2024-08-22 20:43:00 INFO export.py L152: packing model.layers.32.mlp.gate_proj\n",
            "2024-08-22 20:43:01 INFO export.py L152: packing model.layers.32.mlp.up_proj\n",
            "2024-08-22 20:43:02 INFO export.py L152: packing model.layers.32.mlp.down_proj\n",
            "2024-08-22 20:43:03 INFO export.py L152: packing model.layers.33.self_attn.q_proj\n",
            "2024-08-22 20:43:04 INFO export.py L152: packing model.layers.33.self_attn.k_proj\n",
            "2024-08-22 20:43:04 INFO export.py L152: packing model.layers.33.self_attn.v_proj\n",
            "2024-08-22 20:43:04 INFO export.py L152: packing model.layers.33.self_attn.o_proj\n",
            "2024-08-22 20:43:05 INFO export.py L152: packing model.layers.33.mlp.gate_proj\n",
            "2024-08-22 20:43:06 INFO export.py L152: packing model.layers.33.mlp.up_proj\n",
            "2024-08-22 20:43:07 INFO export.py L152: packing model.layers.33.mlp.down_proj\n",
            "2024-08-22 20:43:08 INFO export.py L152: packing model.layers.34.self_attn.q_proj\n",
            "2024-08-22 20:43:09 INFO export.py L152: packing model.layers.34.self_attn.k_proj\n",
            "2024-08-22 20:43:09 INFO export.py L152: packing model.layers.34.self_attn.v_proj\n",
            "2024-08-22 20:43:09 INFO export.py L152: packing model.layers.34.self_attn.o_proj\n",
            "2024-08-22 20:43:10 INFO export.py L152: packing model.layers.34.mlp.gate_proj\n",
            "2024-08-22 20:43:11 INFO export.py L152: packing model.layers.34.mlp.up_proj\n",
            "2024-08-22 20:43:12 INFO export.py L152: packing model.layers.34.mlp.down_proj\n",
            "2024-08-22 20:43:14 INFO export.py L152: packing model.layers.35.self_attn.q_proj\n",
            "2024-08-22 20:43:14 INFO export.py L152: packing model.layers.35.self_attn.k_proj\n",
            "2024-08-22 20:43:14 INFO export.py L152: packing model.layers.35.self_attn.v_proj\n",
            "2024-08-22 20:43:15 INFO export.py L152: packing model.layers.35.self_attn.o_proj\n",
            "2024-08-22 20:43:15 INFO export.py L152: packing model.layers.35.mlp.gate_proj\n",
            "2024-08-22 20:43:16 INFO export.py L152: packing model.layers.35.mlp.up_proj\n",
            "2024-08-22 20:43:18 INFO export.py L152: packing model.layers.35.mlp.down_proj\n",
            "2024-08-22 20:43:19 INFO export.py L152: packing model.layers.36.self_attn.q_proj\n",
            "2024-08-22 20:43:19 INFO export.py L152: packing model.layers.36.self_attn.k_proj\n",
            "2024-08-22 20:43:19 INFO export.py L152: packing model.layers.36.self_attn.v_proj\n",
            "2024-08-22 20:43:20 INFO export.py L152: packing model.layers.36.self_attn.o_proj\n",
            "2024-08-22 20:43:20 INFO export.py L152: packing model.layers.36.mlp.gate_proj\n",
            "2024-08-22 20:43:22 INFO export.py L152: packing model.layers.36.mlp.up_proj\n",
            "2024-08-22 20:43:23 INFO export.py L152: packing model.layers.36.mlp.down_proj\n",
            "2024-08-22 20:43:24 INFO export.py L152: packing model.layers.37.self_attn.q_proj\n",
            "2024-08-22 20:43:24 INFO export.py L152: packing model.layers.37.self_attn.k_proj\n",
            "2024-08-22 20:43:25 INFO export.py L152: packing model.layers.37.self_attn.v_proj\n",
            "2024-08-22 20:43:25 INFO export.py L152: packing model.layers.37.self_attn.o_proj\n",
            "2024-08-22 20:43:25 INFO export.py L152: packing model.layers.37.mlp.gate_proj\n",
            "2024-08-22 20:43:27 INFO export.py L152: packing model.layers.37.mlp.up_proj\n",
            "2024-08-22 20:43:28 INFO export.py L152: packing model.layers.37.mlp.down_proj\n",
            "2024-08-22 20:43:29 INFO export.py L152: packing model.layers.38.self_attn.q_proj\n",
            "2024-08-22 20:43:30 INFO export.py L152: packing model.layers.38.self_attn.k_proj\n",
            "2024-08-22 20:43:30 INFO export.py L152: packing model.layers.38.self_attn.v_proj\n",
            "2024-08-22 20:43:30 INFO export.py L152: packing model.layers.38.self_attn.o_proj\n",
            "2024-08-22 20:43:31 INFO export.py L152: packing model.layers.38.mlp.gate_proj\n",
            "2024-08-22 20:43:32 INFO export.py L152: packing model.layers.38.mlp.up_proj\n",
            "2024-08-22 20:43:33 INFO export.py L152: packing model.layers.38.mlp.down_proj\n",
            "2024-08-22 20:43:34 INFO export.py L152: packing model.layers.39.self_attn.q_proj\n",
            "2024-08-22 20:43:35 INFO export.py L152: packing model.layers.39.self_attn.k_proj\n",
            "2024-08-22 20:43:35 INFO export.py L152: packing model.layers.39.self_attn.v_proj\n",
            "2024-08-22 20:43:35 INFO export.py L152: packing model.layers.39.self_attn.o_proj\n",
            "2024-08-22 20:43:36 INFO export.py L152: packing model.layers.39.mlp.gate_proj\n",
            "2024-08-22 20:43:37 INFO export.py L152: packing model.layers.39.mlp.up_proj\n",
            "2024-08-22 20:43:39 INFO export.py L152: packing model.layers.39.mlp.down_proj\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "model_name = \"nvidia/Mistral-NeMo-Minitron-8B-Base\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "from auto_round import AutoRound\n",
        "\n",
        "bits, group_size, sym = 2, 128, True\n",
        "autoround = AutoRound(model, tokenizer, bits=bits, group_size=group_size, batch_size=2, seqlen=512, sym=sym, gradient_accumulate_steps=4, device='cuda')\n",
        "autoround.quantize()\n",
        "output_dir = \"./AutoRound/Mistral-NeMo-Minitron-8B-Base-AutoRound-GPTQ-sym-2bit/\"\n",
        "autoround.save_quantized(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another example for nvidia/Llama-3.1-Minitron-4B-Width-Base"
      ],
      "metadata": {
        "id": "mLr6quWXFEAx"
      },
      "id": "mLr6quWXFEAx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4de441ac-3984-4c58-b701-18e07ced15ca",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c153c01407d241fcb9d82623947de905",
            "384469947c27413d9a54544b4f64017a",
            "d98a9d8f0ed343498a2d1dc68d5ee0ae",
            "446ff73113f14fe69d14e59ce503b298",
            "aa14bfa3823240bda48e58b43057278f",
            "703866f4e9bc471881e37a3d56c416fd",
            "447e1a5dd79b48a79d98123935907262",
            "e6bcd466bf2243cea36d6b0d5361fbeb",
            "2d57aa78e9ba45d6a14ff3ea76dea852",
            "9e4a936cffd14ad3bdaf84172542da1c",
            "0e86e571a1514ee3a06585d4ed232428",
            "e26b583e36d84383bda4ce4581baae75"
          ]
        },
        "id": "4de441ac-3984-4c58-b701-18e07ced15ca",
        "outputId": "967de68e-29fa-4959-f31a-c5ca26fed7c1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c153c01407d241fcb9d82623947de905",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/906 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "384469947c27413d9a54544b4f64017a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d98a9d8f0ed343498a2d1dc68d5ee0ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "446ff73113f14fe69d14e59ce503b298",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa14bfa3823240bda48e58b43057278f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/4.05G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "703866f4e9bc471881e37a3d56c416fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "447e1a5dd79b48a79d98123935907262",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/126 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6bcd466bf2243cea36d6b0d5361fbeb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d57aa78e9ba45d6a14ff3ea76dea852",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e4a936cffd14ad3bdaf84172542da1c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-08-25 06:54:59 INFO autoround.py L209: using torch.float16 for quantization tuning\n",
            "2024-08-25 06:55:01,134 INFO utils.py L145: Note: detected 96 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
            "2024-08-25 06:55:01,135 INFO utils.py L148: Note: NumExpr detected 96 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 16.\n",
            "2024-08-25 06:55:01,137 INFO utils.py L161: NumExpr defaulting to 16 threads.\n",
            "2024-08-25 06:55:01,286 INFO config.py L59: PyTorch version 2.1.0+cu118 available.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e86e571a1514ee3a06585d4ed232428",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e26b583e36d84383bda4ce4581baae75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n",
            "2024-08-25 06:55:40 INFO autoround.py L1039: quantizing 1/32, model.layers.0\n",
            "The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "2024-08-25 06:56:23 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000005 -> iter 191: 0.000002\n",
            "2024-08-25 06:56:23 INFO autoround.py L1039: quantizing 2/32, model.layers.1\n",
            "2024-08-25 06:57:07 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000306 -> iter 63: 0.000150\n",
            "2024-08-25 06:57:07 INFO autoround.py L1039: quantizing 3/32, model.layers.2\n",
            "2024-08-25 06:57:50 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000193 -> iter 196: 0.000117\n",
            "2024-08-25 06:57:51 INFO autoround.py L1039: quantizing 4/32, model.layers.3\n",
            "2024-08-25 06:58:34 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000176 -> iter 195: 0.000098\n",
            "2024-08-25 06:58:34 INFO autoround.py L1039: quantizing 5/32, model.layers.4\n",
            "2024-08-25 06:59:18 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000162 -> iter 171: 0.000086\n",
            "2024-08-25 06:59:18 INFO autoround.py L1039: quantizing 6/32, model.layers.5\n",
            "2024-08-25 07:00:01 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000160 -> iter 199: 0.000089\n",
            "2024-08-25 07:00:02 INFO autoround.py L1039: quantizing 7/32, model.layers.6\n",
            "2024-08-25 07:00:45 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000167 -> iter 197: 0.000092\n",
            "2024-08-25 07:00:45 INFO autoround.py L1039: quantizing 8/32, model.layers.7\n",
            "2024-08-25 07:01:29 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000184 -> iter 182: 0.000101\n",
            "2024-08-25 07:01:29 INFO autoround.py L1039: quantizing 9/32, model.layers.8\n",
            "2024-08-25 07:02:12 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000181 -> iter 176: 0.000108\n",
            "2024-08-25 07:02:13 INFO autoround.py L1039: quantizing 10/32, model.layers.9\n",
            "2024-08-25 07:02:56 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000206 -> iter 197: 0.000113\n",
            "2024-08-25 07:02:56 INFO autoround.py L1039: quantizing 11/32, model.layers.10\n",
            "2024-08-25 07:03:40 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000225 -> iter 189: 0.000125\n",
            "2024-08-25 07:03:40 INFO autoround.py L1039: quantizing 12/32, model.layers.11\n",
            "2024-08-25 07:04:23 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000250 -> iter 173: 0.000140\n",
            "2024-08-25 07:04:24 INFO autoround.py L1039: quantizing 13/32, model.layers.12\n",
            "2024-08-25 07:05:07 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000261 -> iter 190: 0.000146\n",
            "2024-08-25 07:05:07 INFO autoround.py L1039: quantizing 14/32, model.layers.13\n",
            "2024-08-25 07:05:50 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000315 -> iter 181: 0.000170\n",
            "2024-08-25 07:05:51 INFO autoround.py L1039: quantizing 15/32, model.layers.14\n",
            "2024-08-25 07:06:34 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000362 -> iter 183: 0.000194\n",
            "2024-08-25 07:06:35 INFO autoround.py L1039: quantizing 16/32, model.layers.15\n",
            "2024-08-25 07:07:18 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000374 -> iter 175: 0.000216\n",
            "2024-08-25 07:07:18 INFO autoround.py L1039: quantizing 17/32, model.layers.16\n",
            "2024-08-25 07:08:02 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000442 -> iter 199: 0.000233\n",
            "2024-08-25 07:08:02 INFO autoround.py L1039: quantizing 18/32, model.layers.17\n",
            "2024-08-25 07:08:45 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000467 -> iter 196: 0.000266\n",
            "2024-08-25 07:08:46 INFO autoround.py L1039: quantizing 19/32, model.layers.18\n",
            "2024-08-25 07:09:29 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000485 -> iter 177: 0.000309\n",
            "2024-08-25 07:09:29 INFO autoround.py L1039: quantizing 20/32, model.layers.19\n",
            "2024-08-25 07:10:12 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000597 -> iter 170: 0.000356\n",
            "2024-08-25 07:10:13 INFO autoround.py L1039: quantizing 21/32, model.layers.20\n",
            "2024-08-25 07:10:56 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000622 -> iter 171: 0.000396\n",
            "2024-08-25 07:10:57 INFO autoround.py L1039: quantizing 22/32, model.layers.21\n",
            "2024-08-25 07:11:40 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000762 -> iter 199: 0.000493\n",
            "2024-08-25 07:11:40 INFO autoround.py L1039: quantizing 23/32, model.layers.22\n",
            "2024-08-25 07:12:23 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000877 -> iter 162: 0.000566\n",
            "2024-08-25 07:12:24 INFO autoround.py L1039: quantizing 24/32, model.layers.23\n",
            "2024-08-25 07:13:07 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000982 -> iter 139: 0.000633\n",
            "2024-08-25 07:13:07 INFO autoround.py L1039: quantizing 25/32, model.layers.24\n",
            "2024-08-25 07:13:51 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.001185 -> iter 182: 0.000742\n",
            "2024-08-25 07:13:51 INFO autoround.py L1039: quantizing 26/32, model.layers.25\n",
            "2024-08-25 07:14:34 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.001344 -> iter 171: 0.000851\n",
            "2024-08-25 07:14:35 INFO autoround.py L1039: quantizing 27/32, model.layers.26\n",
            "2024-08-25 07:15:18 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.001442 -> iter 165: 0.001012\n",
            "2024-08-25 07:15:18 INFO autoround.py L1039: quantizing 28/32, model.layers.27\n",
            "2024-08-25 07:16:02 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.001861 -> iter 137: 0.001249\n",
            "2024-08-25 07:16:02 INFO autoround.py L1039: quantizing 29/32, model.layers.28\n",
            "2024-08-25 07:16:45 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.002289 -> iter 181: 0.001439\n",
            "2024-08-25 07:16:46 INFO autoround.py L1039: quantizing 30/32, model.layers.29\n",
            "2024-08-25 07:17:29 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.002871 -> iter 192: 0.001865\n",
            "2024-08-25 07:17:30 INFO autoround.py L1039: quantizing 31/32, model.layers.30\n",
            "2024-08-25 07:18:13 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.004687 -> iter 159: 0.002794\n",
            "2024-08-25 07:18:13 INFO autoround.py L1039: quantizing 32/32, model.layers.31\n",
            "2024-08-25 07:18:56 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.009741 -> iter 180: 0.005559\n",
            "2024-08-25 07:18:57 INFO autoround.py L288: quantization tuning time 1438.164046049118\n",
            "2024-08-25 07:18:57 INFO autoround.py L304: Summary: quantized 224/225 in the model,  ['lm_head'] have not been quantized\n",
            "2024-08-25 07:18:57 INFO export.py L112: Saving quantized model to autogptq format, this may take a while...\n",
            "2024-08-25 07:18:57 INFO export.py L152: packing model.layers.0.self_attn.q_proj\n",
            "2024-08-25 07:18:58 INFO export.py L152: packing model.layers.0.self_attn.k_proj\n",
            "2024-08-25 07:18:58 INFO export.py L152: packing model.layers.0.self_attn.v_proj\n",
            "2024-08-25 07:18:58 INFO export.py L152: packing model.layers.0.self_attn.o_proj\n",
            "2024-08-25 07:18:58 INFO export.py L152: packing model.layers.0.mlp.gate_proj\n",
            "2024-08-25 07:18:59 INFO export.py L152: packing model.layers.0.mlp.up_proj\n",
            "2024-08-25 07:19:00 INFO export.py L152: packing model.layers.0.mlp.down_proj\n",
            "2024-08-25 07:19:02 INFO export.py L152: packing model.layers.1.self_attn.q_proj\n",
            "2024-08-25 07:19:02 INFO export.py L152: packing model.layers.1.self_attn.k_proj\n",
            "2024-08-25 07:19:02 INFO export.py L152: packing model.layers.1.self_attn.v_proj\n",
            "2024-08-25 07:19:03 INFO export.py L152: packing model.layers.1.self_attn.o_proj\n",
            "2024-08-25 07:19:03 INFO export.py L152: packing model.layers.1.mlp.gate_proj\n",
            "2024-08-25 07:19:04 INFO export.py L152: packing model.layers.1.mlp.up_proj\n",
            "2024-08-25 07:19:05 INFO export.py L152: packing model.layers.1.mlp.down_proj\n",
            "2024-08-25 07:19:06 INFO export.py L152: packing model.layers.2.self_attn.q_proj\n",
            "2024-08-25 07:19:06 INFO export.py L152: packing model.layers.2.self_attn.k_proj\n",
            "2024-08-25 07:19:06 INFO export.py L152: packing model.layers.2.self_attn.v_proj\n",
            "2024-08-25 07:19:07 INFO export.py L152: packing model.layers.2.self_attn.o_proj\n",
            "2024-08-25 07:19:07 INFO export.py L152: packing model.layers.2.mlp.gate_proj\n",
            "2024-08-25 07:19:08 INFO export.py L152: packing model.layers.2.mlp.up_proj\n",
            "2024-08-25 07:19:09 INFO export.py L152: packing model.layers.2.mlp.down_proj\n",
            "2024-08-25 07:19:10 INFO export.py L152: packing model.layers.3.self_attn.q_proj\n",
            "2024-08-25 07:19:10 INFO export.py L152: packing model.layers.3.self_attn.k_proj\n",
            "2024-08-25 07:19:10 INFO export.py L152: packing model.layers.3.self_attn.v_proj\n",
            "2024-08-25 07:19:10 INFO export.py L152: packing model.layers.3.self_attn.o_proj\n",
            "2024-08-25 07:19:11 INFO export.py L152: packing model.layers.3.mlp.gate_proj\n",
            "2024-08-25 07:19:12 INFO export.py L152: packing model.layers.3.mlp.up_proj\n",
            "2024-08-25 07:19:13 INFO export.py L152: packing model.layers.3.mlp.down_proj\n",
            "2024-08-25 07:19:14 INFO export.py L152: packing model.layers.4.self_attn.q_proj\n",
            "2024-08-25 07:19:14 INFO export.py L152: packing model.layers.4.self_attn.k_proj\n",
            "2024-08-25 07:19:14 INFO export.py L152: packing model.layers.4.self_attn.v_proj\n",
            "2024-08-25 07:19:14 INFO export.py L152: packing model.layers.4.self_attn.o_proj\n",
            "2024-08-25 07:19:15 INFO export.py L152: packing model.layers.4.mlp.gate_proj\n",
            "2024-08-25 07:19:16 INFO export.py L152: packing model.layers.4.mlp.up_proj\n",
            "2024-08-25 07:19:17 INFO export.py L152: packing model.layers.4.mlp.down_proj\n",
            "2024-08-25 07:19:18 INFO export.py L152: packing model.layers.5.self_attn.q_proj\n",
            "2024-08-25 07:19:18 INFO export.py L152: packing model.layers.5.self_attn.k_proj\n",
            "2024-08-25 07:19:18 INFO export.py L152: packing model.layers.5.self_attn.v_proj\n",
            "2024-08-25 07:19:18 INFO export.py L152: packing model.layers.5.self_attn.o_proj\n",
            "2024-08-25 07:19:19 INFO export.py L152: packing model.layers.5.mlp.gate_proj\n",
            "2024-08-25 07:19:20 INFO export.py L152: packing model.layers.5.mlp.up_proj\n",
            "2024-08-25 07:19:21 INFO export.py L152: packing model.layers.5.mlp.down_proj\n",
            "2024-08-25 07:19:22 INFO export.py L152: packing model.layers.6.self_attn.q_proj\n",
            "2024-08-25 07:19:22 INFO export.py L152: packing model.layers.6.self_attn.k_proj\n",
            "2024-08-25 07:19:22 INFO export.py L152: packing model.layers.6.self_attn.v_proj\n",
            "2024-08-25 07:19:22 INFO export.py L152: packing model.layers.6.self_attn.o_proj\n",
            "2024-08-25 07:19:23 INFO export.py L152: packing model.layers.6.mlp.gate_proj\n",
            "2024-08-25 07:19:24 INFO export.py L152: packing model.layers.6.mlp.up_proj\n",
            "2024-08-25 07:19:24 INFO export.py L152: packing model.layers.6.mlp.down_proj\n",
            "2024-08-25 07:19:25 INFO export.py L152: packing model.layers.7.self_attn.q_proj\n",
            "2024-08-25 07:19:26 INFO export.py L152: packing model.layers.7.self_attn.k_proj\n",
            "2024-08-25 07:19:26 INFO export.py L152: packing model.layers.7.self_attn.v_proj\n",
            "2024-08-25 07:19:26 INFO export.py L152: packing model.layers.7.self_attn.o_proj\n",
            "2024-08-25 07:19:26 INFO export.py L152: packing model.layers.7.mlp.gate_proj\n",
            "2024-08-25 07:19:27 INFO export.py L152: packing model.layers.7.mlp.up_proj\n",
            "2024-08-25 07:19:28 INFO export.py L152: packing model.layers.7.mlp.down_proj\n",
            "2024-08-25 07:19:29 INFO export.py L152: packing model.layers.8.self_attn.q_proj\n",
            "2024-08-25 07:19:29 INFO export.py L152: packing model.layers.8.self_attn.k_proj\n",
            "2024-08-25 07:19:30 INFO export.py L152: packing model.layers.8.self_attn.v_proj\n",
            "2024-08-25 07:19:30 INFO export.py L152: packing model.layers.8.self_attn.o_proj\n",
            "2024-08-25 07:19:30 INFO export.py L152: packing model.layers.8.mlp.gate_proj\n",
            "2024-08-25 07:19:31 INFO export.py L152: packing model.layers.8.mlp.up_proj\n",
            "2024-08-25 07:19:32 INFO export.py L152: packing model.layers.8.mlp.down_proj\n",
            "2024-08-25 07:19:33 INFO export.py L152: packing model.layers.9.self_attn.q_proj\n",
            "2024-08-25 07:19:33 INFO export.py L152: packing model.layers.9.self_attn.k_proj\n",
            "2024-08-25 07:19:33 INFO export.py L152: packing model.layers.9.self_attn.v_proj\n",
            "2024-08-25 07:19:34 INFO export.py L152: packing model.layers.9.self_attn.o_proj\n",
            "2024-08-25 07:19:34 INFO export.py L152: packing model.layers.9.mlp.gate_proj\n",
            "2024-08-25 07:19:35 INFO export.py L152: packing model.layers.9.mlp.up_proj\n",
            "2024-08-25 07:19:36 INFO export.py L152: packing model.layers.9.mlp.down_proj\n",
            "2024-08-25 07:19:37 INFO export.py L152: packing model.layers.10.self_attn.q_proj\n",
            "2024-08-25 07:19:37 INFO export.py L152: packing model.layers.10.self_attn.k_proj\n",
            "2024-08-25 07:19:37 INFO export.py L152: packing model.layers.10.self_attn.v_proj\n",
            "2024-08-25 07:19:37 INFO export.py L152: packing model.layers.10.self_attn.o_proj\n",
            "2024-08-25 07:19:38 INFO export.py L152: packing model.layers.10.mlp.gate_proj\n",
            "2024-08-25 07:19:39 INFO export.py L152: packing model.layers.10.mlp.up_proj\n",
            "2024-08-25 07:19:40 INFO export.py L152: packing model.layers.10.mlp.down_proj\n",
            "2024-08-25 07:19:41 INFO export.py L152: packing model.layers.11.self_attn.q_proj\n",
            "2024-08-25 07:19:41 INFO export.py L152: packing model.layers.11.self_attn.k_proj\n",
            "2024-08-25 07:19:41 INFO export.py L152: packing model.layers.11.self_attn.v_proj\n",
            "2024-08-25 07:19:41 INFO export.py L152: packing model.layers.11.self_attn.o_proj\n",
            "2024-08-25 07:19:42 INFO export.py L152: packing model.layers.11.mlp.gate_proj\n",
            "2024-08-25 07:19:43 INFO export.py L152: packing model.layers.11.mlp.up_proj\n",
            "2024-08-25 07:19:43 INFO export.py L152: packing model.layers.11.mlp.down_proj\n",
            "2024-08-25 07:19:44 INFO export.py L152: packing model.layers.12.self_attn.q_proj\n",
            "2024-08-25 07:19:45 INFO export.py L152: packing model.layers.12.self_attn.k_proj\n",
            "2024-08-25 07:19:45 INFO export.py L152: packing model.layers.12.self_attn.v_proj\n",
            "2024-08-25 07:19:45 INFO export.py L152: packing model.layers.12.self_attn.o_proj\n",
            "2024-08-25 07:19:45 INFO export.py L152: packing model.layers.12.mlp.gate_proj\n",
            "2024-08-25 07:19:46 INFO export.py L152: packing model.layers.12.mlp.up_proj\n",
            "2024-08-25 07:19:47 INFO export.py L152: packing model.layers.12.mlp.down_proj\n",
            "2024-08-25 07:19:48 INFO export.py L152: packing model.layers.13.self_attn.q_proj\n",
            "2024-08-25 07:19:48 INFO export.py L152: packing model.layers.13.self_attn.k_proj\n",
            "2024-08-25 07:19:49 INFO export.py L152: packing model.layers.13.self_attn.v_proj\n",
            "2024-08-25 07:19:49 INFO export.py L152: packing model.layers.13.self_attn.o_proj\n",
            "2024-08-25 07:19:49 INFO export.py L152: packing model.layers.13.mlp.gate_proj\n",
            "2024-08-25 07:19:50 INFO export.py L152: packing model.layers.13.mlp.up_proj\n",
            "2024-08-25 07:19:51 INFO export.py L152: packing model.layers.13.mlp.down_proj\n",
            "2024-08-25 07:19:52 INFO export.py L152: packing model.layers.14.self_attn.q_proj\n",
            "2024-08-25 07:19:52 INFO export.py L152: packing model.layers.14.self_attn.k_proj\n",
            "2024-08-25 07:19:52 INFO export.py L152: packing model.layers.14.self_attn.v_proj\n",
            "2024-08-25 07:19:53 INFO export.py L152: packing model.layers.14.self_attn.o_proj\n",
            "2024-08-25 07:19:53 INFO export.py L152: packing model.layers.14.mlp.gate_proj\n",
            "2024-08-25 07:19:54 INFO export.py L152: packing model.layers.14.mlp.up_proj\n",
            "2024-08-25 07:19:55 INFO export.py L152: packing model.layers.14.mlp.down_proj\n",
            "2024-08-25 07:19:56 INFO export.py L152: packing model.layers.15.self_attn.q_proj\n",
            "2024-08-25 07:19:56 INFO export.py L152: packing model.layers.15.self_attn.k_proj\n",
            "2024-08-25 07:19:56 INFO export.py L152: packing model.layers.15.self_attn.v_proj\n",
            "2024-08-25 07:19:56 INFO export.py L152: packing model.layers.15.self_attn.o_proj\n",
            "2024-08-25 07:19:57 INFO export.py L152: packing model.layers.15.mlp.gate_proj\n",
            "2024-08-25 07:19:57 INFO export.py L152: packing model.layers.15.mlp.up_proj\n",
            "2024-08-25 07:19:58 INFO export.py L152: packing model.layers.15.mlp.down_proj\n",
            "2024-08-25 07:19:59 INFO export.py L152: packing model.layers.16.self_attn.q_proj\n",
            "2024-08-25 07:20:00 INFO export.py L152: packing model.layers.16.self_attn.k_proj\n",
            "2024-08-25 07:20:00 INFO export.py L152: packing model.layers.16.self_attn.v_proj\n",
            "2024-08-25 07:20:00 INFO export.py L152: packing model.layers.16.self_attn.o_proj\n",
            "2024-08-25 07:20:00 INFO export.py L152: packing model.layers.16.mlp.gate_proj\n",
            "2024-08-25 07:20:01 INFO export.py L152: packing model.layers.16.mlp.up_proj\n",
            "2024-08-25 07:20:02 INFO export.py L152: packing model.layers.16.mlp.down_proj\n",
            "2024-08-25 07:20:03 INFO export.py L152: packing model.layers.17.self_attn.q_proj\n",
            "2024-08-25 07:20:03 INFO export.py L152: packing model.layers.17.self_attn.k_proj\n",
            "2024-08-25 07:20:04 INFO export.py L152: packing model.layers.17.self_attn.v_proj\n",
            "2024-08-25 07:20:04 INFO export.py L152: packing model.layers.17.self_attn.o_proj\n",
            "2024-08-25 07:20:04 INFO export.py L152: packing model.layers.17.mlp.gate_proj\n",
            "2024-08-25 07:20:05 INFO export.py L152: packing model.layers.17.mlp.up_proj\n",
            "2024-08-25 07:20:06 INFO export.py L152: packing model.layers.17.mlp.down_proj\n",
            "2024-08-25 07:20:07 INFO export.py L152: packing model.layers.18.self_attn.q_proj\n",
            "2024-08-25 07:20:07 INFO export.py L152: packing model.layers.18.self_attn.k_proj\n",
            "2024-08-25 07:20:07 INFO export.py L152: packing model.layers.18.self_attn.v_proj\n",
            "2024-08-25 07:20:07 INFO export.py L152: packing model.layers.18.self_attn.o_proj\n",
            "2024-08-25 07:20:08 INFO export.py L152: packing model.layers.18.mlp.gate_proj\n",
            "2024-08-25 07:20:09 INFO export.py L152: packing model.layers.18.mlp.up_proj\n",
            "2024-08-25 07:20:10 INFO export.py L152: packing model.layers.18.mlp.down_proj\n",
            "2024-08-25 07:20:11 INFO export.py L152: packing model.layers.19.self_attn.q_proj\n",
            "2024-08-25 07:20:11 INFO export.py L152: packing model.layers.19.self_attn.k_proj\n",
            "2024-08-25 07:20:11 INFO export.py L152: packing model.layers.19.self_attn.v_proj\n",
            "2024-08-25 07:20:11 INFO export.py L152: packing model.layers.19.self_attn.o_proj\n",
            "2024-08-25 07:20:12 INFO export.py L152: packing model.layers.19.mlp.gate_proj\n",
            "2024-08-25 07:20:13 INFO export.py L152: packing model.layers.19.mlp.up_proj\n",
            "2024-08-25 07:20:14 INFO export.py L152: packing model.layers.19.mlp.down_proj\n",
            "2024-08-25 07:20:15 INFO export.py L152: packing model.layers.20.self_attn.q_proj\n",
            "2024-08-25 07:20:15 INFO export.py L152: packing model.layers.20.self_attn.k_proj\n",
            "2024-08-25 07:20:15 INFO export.py L152: packing model.layers.20.self_attn.v_proj\n",
            "2024-08-25 07:20:15 INFO export.py L152: packing model.layers.20.self_attn.o_proj\n",
            "2024-08-25 07:20:16 INFO export.py L152: packing model.layers.20.mlp.gate_proj\n",
            "2024-08-25 07:20:17 INFO export.py L152: packing model.layers.20.mlp.up_proj\n",
            "2024-08-25 07:20:18 INFO export.py L152: packing model.layers.20.mlp.down_proj\n",
            "2024-08-25 07:20:18 INFO export.py L152: packing model.layers.21.self_attn.q_proj\n",
            "2024-08-25 07:20:19 INFO export.py L152: packing model.layers.21.self_attn.k_proj\n",
            "2024-08-25 07:20:19 INFO export.py L152: packing model.layers.21.self_attn.v_proj\n",
            "2024-08-25 07:20:19 INFO export.py L152: packing model.layers.21.self_attn.o_proj\n",
            "2024-08-25 07:20:20 INFO export.py L152: packing model.layers.21.mlp.gate_proj\n",
            "2024-08-25 07:20:20 INFO export.py L152: packing model.layers.21.mlp.up_proj\n",
            "2024-08-25 07:20:21 INFO export.py L152: packing model.layers.21.mlp.down_proj\n",
            "2024-08-25 07:20:22 INFO export.py L152: packing model.layers.22.self_attn.q_proj\n",
            "2024-08-25 07:20:23 INFO export.py L152: packing model.layers.22.self_attn.k_proj\n",
            "2024-08-25 07:20:23 INFO export.py L152: packing model.layers.22.self_attn.v_proj\n",
            "2024-08-25 07:20:23 INFO export.py L152: packing model.layers.22.self_attn.o_proj\n",
            "2024-08-25 07:20:23 INFO export.py L152: packing model.layers.22.mlp.gate_proj\n",
            "2024-08-25 07:20:24 INFO export.py L152: packing model.layers.22.mlp.up_proj\n",
            "2024-08-25 07:20:25 INFO export.py L152: packing model.layers.22.mlp.down_proj\n",
            "2024-08-25 07:20:26 INFO export.py L152: packing model.layers.23.self_attn.q_proj\n",
            "2024-08-25 07:20:26 INFO export.py L152: packing model.layers.23.self_attn.k_proj\n",
            "2024-08-25 07:20:27 INFO export.py L152: packing model.layers.23.self_attn.v_proj\n",
            "2024-08-25 07:20:27 INFO export.py L152: packing model.layers.23.self_attn.o_proj\n",
            "2024-08-25 07:20:27 INFO export.py L152: packing model.layers.23.mlp.gate_proj\n",
            "2024-08-25 07:20:28 INFO export.py L152: packing model.layers.23.mlp.up_proj\n",
            "2024-08-25 07:20:29 INFO export.py L152: packing model.layers.23.mlp.down_proj\n",
            "2024-08-25 07:20:30 INFO export.py L152: packing model.layers.24.self_attn.q_proj\n",
            "2024-08-25 07:20:30 INFO export.py L152: packing model.layers.24.self_attn.k_proj\n",
            "2024-08-25 07:20:30 INFO export.py L152: packing model.layers.24.self_attn.v_proj\n",
            "2024-08-25 07:20:31 INFO export.py L152: packing model.layers.24.self_attn.o_proj\n",
            "2024-08-25 07:20:31 INFO export.py L152: packing model.layers.24.mlp.gate_proj\n",
            "2024-08-25 07:20:32 INFO export.py L152: packing model.layers.24.mlp.up_proj\n",
            "2024-08-25 07:20:33 INFO export.py L152: packing model.layers.24.mlp.down_proj\n",
            "2024-08-25 07:20:34 INFO export.py L152: packing model.layers.25.self_attn.q_proj\n",
            "2024-08-25 07:20:34 INFO export.py L152: packing model.layers.25.self_attn.k_proj\n",
            "2024-08-25 07:20:34 INFO export.py L152: packing model.layers.25.self_attn.v_proj\n",
            "2024-08-25 07:20:35 INFO export.py L152: packing model.layers.25.self_attn.o_proj\n",
            "2024-08-25 07:20:35 INFO export.py L152: packing model.layers.25.mlp.gate_proj\n",
            "2024-08-25 07:20:36 INFO export.py L152: packing model.layers.25.mlp.up_proj\n",
            "2024-08-25 07:20:37 INFO export.py L152: packing model.layers.25.mlp.down_proj\n",
            "2024-08-25 07:20:38 INFO export.py L152: packing model.layers.26.self_attn.q_proj\n",
            "2024-08-25 07:20:38 INFO export.py L152: packing model.layers.26.self_attn.k_proj\n",
            "2024-08-25 07:20:38 INFO export.py L152: packing model.layers.26.self_attn.v_proj\n",
            "2024-08-25 07:20:39 INFO export.py L152: packing model.layers.26.self_attn.o_proj\n",
            "2024-08-25 07:20:39 INFO export.py L152: packing model.layers.26.mlp.gate_proj\n",
            "2024-08-25 07:20:40 INFO export.py L152: packing model.layers.26.mlp.up_proj\n",
            "2024-08-25 07:20:41 INFO export.py L152: packing model.layers.26.mlp.down_proj\n",
            "2024-08-25 07:20:42 INFO export.py L152: packing model.layers.27.self_attn.q_proj\n",
            "2024-08-25 07:20:42 INFO export.py L152: packing model.layers.27.self_attn.k_proj\n",
            "2024-08-25 07:20:43 INFO export.py L152: packing model.layers.27.self_attn.v_proj\n",
            "2024-08-25 07:20:43 INFO export.py L152: packing model.layers.27.self_attn.o_proj\n",
            "2024-08-25 07:20:43 INFO export.py L152: packing model.layers.27.mlp.gate_proj\n",
            "2024-08-25 07:20:44 INFO export.py L152: packing model.layers.27.mlp.up_proj\n",
            "2024-08-25 07:20:45 INFO export.py L152: packing model.layers.27.mlp.down_proj\n",
            "2024-08-25 07:20:46 INFO export.py L152: packing model.layers.28.self_attn.q_proj\n",
            "2024-08-25 07:20:47 INFO export.py L152: packing model.layers.28.self_attn.k_proj\n",
            "2024-08-25 07:20:47 INFO export.py L152: packing model.layers.28.self_attn.v_proj\n",
            "2024-08-25 07:20:47 INFO export.py L152: packing model.layers.28.self_attn.o_proj\n",
            "2024-08-25 07:20:47 INFO export.py L152: packing model.layers.28.mlp.gate_proj\n",
            "2024-08-25 07:20:48 INFO export.py L152: packing model.layers.28.mlp.up_proj\n",
            "2024-08-25 07:20:49 INFO export.py L152: packing model.layers.28.mlp.down_proj\n",
            "2024-08-25 07:20:50 INFO export.py L152: packing model.layers.29.self_attn.q_proj\n",
            "2024-08-25 07:20:50 INFO export.py L152: packing model.layers.29.self_attn.k_proj\n",
            "2024-08-25 07:20:51 INFO export.py L152: packing model.layers.29.self_attn.v_proj\n",
            "2024-08-25 07:20:51 INFO export.py L152: packing model.layers.29.self_attn.o_proj\n",
            "2024-08-25 07:20:51 INFO export.py L152: packing model.layers.29.mlp.gate_proj\n",
            "2024-08-25 07:20:52 INFO export.py L152: packing model.layers.29.mlp.up_proj\n",
            "2024-08-25 07:20:53 INFO export.py L152: packing model.layers.29.mlp.down_proj\n",
            "2024-08-25 07:20:54 INFO export.py L152: packing model.layers.30.self_attn.q_proj\n",
            "2024-08-25 07:20:54 INFO export.py L152: packing model.layers.30.self_attn.k_proj\n",
            "2024-08-25 07:20:54 INFO export.py L152: packing model.layers.30.self_attn.v_proj\n",
            "2024-08-25 07:20:55 INFO export.py L152: packing model.layers.30.self_attn.o_proj\n",
            "2024-08-25 07:20:55 INFO export.py L152: packing model.layers.30.mlp.gate_proj\n",
            "2024-08-25 07:20:56 INFO export.py L152: packing model.layers.30.mlp.up_proj\n",
            "2024-08-25 07:20:57 INFO export.py L152: packing model.layers.30.mlp.down_proj\n",
            "2024-08-25 07:20:58 INFO export.py L152: packing model.layers.31.self_attn.q_proj\n",
            "2024-08-25 07:20:58 INFO export.py L152: packing model.layers.31.self_attn.k_proj\n",
            "2024-08-25 07:20:58 INFO export.py L152: packing model.layers.31.self_attn.v_proj\n",
            "2024-08-25 07:20:58 INFO export.py L152: packing model.layers.31.self_attn.o_proj\n",
            "2024-08-25 07:20:59 INFO export.py L152: packing model.layers.31.mlp.gate_proj\n",
            "2024-08-25 07:21:00 INFO export.py L152: packing model.layers.31.mlp.up_proj\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model_name = \"nvidia/Llama-3.1-Minitron-4B-Width-Base\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "from auto_round import AutoRound\n",
        "\n",
        "bits, group_size, sym = 4, 128, False\n",
        "autoround = AutoRound(model, tokenizer, bits=bits, group_size=group_size, batch_size=2, seqlen=512, sym=sym, gradient_accumulate_steps=4, device='cuda')\n",
        "autoround.quantize()\n",
        "output_dir = \"./AutoRound/Llama-3.1-Minitron-4B-Width-Base-AutoRound-GPTQ-asym-4bit/\"\n",
        "autoround.save_quantized(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "and nvidia/Llama-3.1-Minitron-4B-Depth-Base"
      ],
      "metadata": {
        "id": "iEaLSR7CFJW5"
      },
      "id": "iEaLSR7CFJW5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "028b0675-48ca-4ee6-9989-bd7752f65127",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "e545fac30f34484cb3374d6b91a59b36",
            "aa854f1cd2fc49549eeab4c5f8968b61",
            "a4bff91b0d924fd5904eb45f8de1a839",
            "352d45488e954578b5c323f15759dbf3",
            "66a415d0020b4d5e80f6ed53df49c504",
            "9004c5fa23214560b361482e788e3987",
            "1a4f896f7bf941d6bf084ab4d9a3bbc7",
            "980b6e4010be458f86c829bec32aa120",
            "90cedad7e0494ac3b34f48d4df966135",
            "aac9771f0e4843fd9dd64086fc5eeede",
            "4a081ade2c1441ffbc49ce84e7dc209d",
            "9b8b48e90d8a43d4a635c716573d1b63",
            "685853f6e7854ae187e0ca4034093fb9",
            "7e4da07d04c845689d8675cc2be51530",
            "805fdc44e5bf4b2a92eada0b665553d3",
            "fc50846e8d094dca88482de3c379cd1e"
          ]
        },
        "id": "028b0675-48ca-4ee6-9989-bd7752f65127",
        "outputId": "49dd6e4e-ede0-4d6f-ab16-b160c20d20c8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e545fac30f34484cb3374d6b91a59b36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/883 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa854f1cd2fc49549eeab4c5f8968b61",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/12.1k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4bff91b0d924fd5904eb45f8de1a839",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "352d45488e954578b5c323f15759dbf3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66a415d0020b4d5e80f6ed53df49c504",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/4.10G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9004c5fa23214560b361482e788e3987",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a4f896f7bf941d6bf084ab4d9a3bbc7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/121 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "980b6e4010be458f86c829bec32aa120",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90cedad7e0494ac3b34f48d4df966135",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aac9771f0e4843fd9dd64086fc5eeede",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-08-25 15:22:29 INFO autoround.py L209: using torch.float16 for quantization tuning\n",
            "2024-08-25 15:22:32,899 INFO utils.py L145: Note: detected 96 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
            "2024-08-25 15:22:32,900 INFO utils.py L148: Note: NumExpr detected 96 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 16.\n",
            "2024-08-25 15:22:32,902 INFO utils.py L161: NumExpr defaulting to 16 threads.\n",
            "2024-08-25 15:22:33,044 INFO config.py L59: PyTorch version 2.1.0+cu118 available.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a081ade2c1441ffbc49ce84e7dc209d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/373 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b8b48e90d8a43d4a635c716573d1b63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/921 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "685853f6e7854ae187e0ca4034093fb9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/33.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e4da07d04c845689d8675cc2be51530",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "805fdc44e5bf4b2a92eada0b665553d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc50846e8d094dca88482de3c379cd1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n",
            "2024-08-25 15:23:08 INFO autoround.py L1039: quantizing 1/16, model.layers.0\n",
            "The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "2024-08-25 15:24:24 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000007 -> iter 191: 0.000002\n",
            "2024-08-25 15:24:25 INFO autoround.py L1039: quantizing 2/16, model.layers.1\n",
            "2024-08-25 15:25:40 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000103 -> iter 25: 0.000072\n",
            "2024-08-25 15:25:41 INFO autoround.py L1039: quantizing 3/16, model.layers.2\n",
            "2024-08-25 15:26:57 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000098 -> iter 196: 0.000055\n",
            "2024-08-25 15:26:58 INFO autoround.py L1039: quantizing 4/16, model.layers.3\n",
            "2024-08-25 15:28:14 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000100 -> iter 197: 0.000054\n",
            "2024-08-25 15:28:14 INFO autoround.py L1039: quantizing 5/16, model.layers.4\n",
            "2024-08-25 15:29:30 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000117 -> iter 171: 0.000059\n",
            "2024-08-25 15:29:31 INFO autoround.py L1039: quantizing 6/16, model.layers.5\n",
            "2024-08-25 15:30:47 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000144 -> iter 178: 0.000076\n",
            "2024-08-25 15:30:47 INFO autoround.py L1039: quantizing 7/16, model.layers.6\n",
            "2024-08-25 15:32:03 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000180 -> iter 196: 0.000091\n",
            "2024-08-25 15:32:04 INFO autoround.py L1039: quantizing 8/16, model.layers.7\n",
            "2024-08-25 15:33:20 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000205 -> iter 187: 0.000113\n",
            "2024-08-25 15:33:21 INFO autoround.py L1039: quantizing 9/16, model.layers.8\n",
            "2024-08-25 15:34:37 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000232 -> iter 195: 0.000120\n",
            "2024-08-25 15:34:38 INFO autoround.py L1039: quantizing 10/16, model.layers.9\n",
            "2024-08-25 15:35:53 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000254 -> iter 199: 0.000134\n",
            "2024-08-25 15:35:54 INFO autoround.py L1039: quantizing 11/16, model.layers.10\n",
            "2024-08-25 15:37:10 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000278 -> iter 189: 0.000144\n",
            "2024-08-25 15:37:11 INFO autoround.py L1039: quantizing 12/16, model.layers.11\n",
            "2024-08-25 15:38:27 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000287 -> iter 151: 0.000156\n",
            "2024-08-25 15:38:28 INFO autoround.py L1039: quantizing 13/16, model.layers.12\n",
            "2024-08-25 15:39:44 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000345 -> iter 169: 0.000172\n",
            "2024-08-25 15:39:44 INFO autoround.py L1039: quantizing 14/16, model.layers.13\n",
            "2024-08-25 15:41:00 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.000507 -> iter 194: 0.000250\n",
            "2024-08-25 15:41:01 INFO autoround.py L1039: quantizing 15/16, model.layers.14\n",
            "2024-08-25 15:42:17 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.001154 -> iter 198: 0.000554\n",
            "2024-08-25 15:42:18 INFO autoround.py L1039: quantizing 16/16, model.layers.15\n",
            "2024-08-25 15:43:34 INFO autoround.py L966: quantized 7/7 layers in the block, loss iter 0: 0.010036 -> iter 176: 0.003537\n",
            "2024-08-25 15:43:35 INFO autoround.py L288: quantization tuning time 1265.783484697342\n",
            "2024-08-25 15:43:35 INFO autoround.py L304: Summary: quantized 112/113 in the model,  ['lm_head'] have not been quantized\n",
            "2024-08-25 15:43:35 INFO export.py L112: Saving quantized model to autogptq format, this may take a while...\n",
            "2024-08-25 15:43:35 INFO export.py L152: packing model.layers.0.self_attn.q_proj\n",
            "2024-08-25 15:43:36 INFO export.py L152: packing model.layers.0.self_attn.k_proj\n",
            "2024-08-25 15:43:36 INFO export.py L152: packing model.layers.0.self_attn.v_proj\n",
            "2024-08-25 15:43:36 INFO export.py L152: packing model.layers.0.self_attn.o_proj\n",
            "2024-08-25 15:43:37 INFO export.py L152: packing model.layers.0.mlp.gate_proj\n",
            "2024-08-25 15:43:40 INFO export.py L152: packing model.layers.0.mlp.up_proj\n",
            "2024-08-25 15:43:42 INFO export.py L152: packing model.layers.0.mlp.down_proj\n",
            "2024-08-25 15:43:45 INFO export.py L152: packing model.layers.1.self_attn.q_proj\n",
            "2024-08-25 15:43:45 INFO export.py L152: packing model.layers.1.self_attn.k_proj\n",
            "2024-08-25 15:43:46 INFO export.py L152: packing model.layers.1.self_attn.v_proj\n",
            "2024-08-25 15:43:46 INFO export.py L152: packing model.layers.1.self_attn.o_proj\n",
            "2024-08-25 15:43:46 INFO export.py L152: packing model.layers.1.mlp.gate_proj\n",
            "2024-08-25 15:43:49 INFO export.py L152: packing model.layers.1.mlp.up_proj\n",
            "2024-08-25 15:43:51 INFO export.py L152: packing model.layers.1.mlp.down_proj\n",
            "2024-08-25 15:43:53 INFO export.py L152: packing model.layers.2.self_attn.q_proj\n",
            "2024-08-25 15:43:54 INFO export.py L152: packing model.layers.2.self_attn.k_proj\n",
            "2024-08-25 15:43:54 INFO export.py L152: packing model.layers.2.self_attn.v_proj\n",
            "2024-08-25 15:43:54 INFO export.py L152: packing model.layers.2.self_attn.o_proj\n",
            "2024-08-25 15:43:55 INFO export.py L152: packing model.layers.2.mlp.gate_proj\n",
            "2024-08-25 15:43:57 INFO export.py L152: packing model.layers.2.mlp.up_proj\n",
            "2024-08-25 15:43:59 INFO export.py L152: packing model.layers.2.mlp.down_proj\n",
            "2024-08-25 15:44:01 INFO export.py L152: packing model.layers.3.self_attn.q_proj\n",
            "2024-08-25 15:44:02 INFO export.py L152: packing model.layers.3.self_attn.k_proj\n",
            "2024-08-25 15:44:02 INFO export.py L152: packing model.layers.3.self_attn.v_proj\n",
            "2024-08-25 15:44:03 INFO export.py L152: packing model.layers.3.self_attn.o_proj\n",
            "2024-08-25 15:44:03 INFO export.py L152: packing model.layers.3.mlp.gate_proj\n",
            "2024-08-25 15:44:05 INFO export.py L152: packing model.layers.3.mlp.up_proj\n",
            "2024-08-25 15:44:08 INFO export.py L152: packing model.layers.3.mlp.down_proj\n",
            "2024-08-25 15:44:10 INFO export.py L152: packing model.layers.4.self_attn.q_proj\n",
            "2024-08-25 15:44:10 INFO export.py L152: packing model.layers.4.self_attn.k_proj\n",
            "2024-08-25 15:44:10 INFO export.py L152: packing model.layers.4.self_attn.v_proj\n",
            "2024-08-25 15:44:11 INFO export.py L152: packing model.layers.4.self_attn.o_proj\n",
            "2024-08-25 15:44:11 INFO export.py L152: packing model.layers.4.mlp.gate_proj\n",
            "2024-08-25 15:44:13 INFO export.py L152: packing model.layers.4.mlp.up_proj\n",
            "2024-08-25 15:44:16 INFO export.py L152: packing model.layers.4.mlp.down_proj\n",
            "2024-08-25 15:44:18 INFO export.py L152: packing model.layers.5.self_attn.q_proj\n",
            "2024-08-25 15:44:19 INFO export.py L152: packing model.layers.5.self_attn.k_proj\n",
            "2024-08-25 15:44:19 INFO export.py L152: packing model.layers.5.self_attn.v_proj\n",
            "2024-08-25 15:44:19 INFO export.py L152: packing model.layers.5.self_attn.o_proj\n",
            "2024-08-25 15:44:20 INFO export.py L152: packing model.layers.5.mlp.gate_proj\n",
            "2024-08-25 15:44:22 INFO export.py L152: packing model.layers.5.mlp.up_proj\n",
            "2024-08-25 15:44:24 INFO export.py L152: packing model.layers.5.mlp.down_proj\n",
            "2024-08-25 15:44:27 INFO export.py L152: packing model.layers.6.self_attn.q_proj\n",
            "2024-08-25 15:44:27 INFO export.py L152: packing model.layers.6.self_attn.k_proj\n",
            "2024-08-25 15:44:27 INFO export.py L152: packing model.layers.6.self_attn.v_proj\n",
            "2024-08-25 15:44:28 INFO export.py L152: packing model.layers.6.self_attn.o_proj\n",
            "2024-08-25 15:44:28 INFO export.py L152: packing model.layers.6.mlp.gate_proj\n",
            "2024-08-25 15:44:31 INFO export.py L152: packing model.layers.6.mlp.up_proj\n",
            "2024-08-25 15:44:33 INFO export.py L152: packing model.layers.6.mlp.down_proj\n",
            "2024-08-25 15:44:35 INFO export.py L152: packing model.layers.7.self_attn.q_proj\n",
            "2024-08-25 15:44:36 INFO export.py L152: packing model.layers.7.self_attn.k_proj\n",
            "2024-08-25 15:44:36 INFO export.py L152: packing model.layers.7.self_attn.v_proj\n",
            "2024-08-25 15:44:36 INFO export.py L152: packing model.layers.7.self_attn.o_proj\n",
            "2024-08-25 15:44:37 INFO export.py L152: packing model.layers.7.mlp.gate_proj\n",
            "2024-08-25 15:44:39 INFO export.py L152: packing model.layers.7.mlp.up_proj\n",
            "2024-08-25 15:44:42 INFO export.py L152: packing model.layers.7.mlp.down_proj\n",
            "2024-08-25 15:44:44 INFO export.py L152: packing model.layers.8.self_attn.q_proj\n",
            "2024-08-25 15:44:44 INFO export.py L152: packing model.layers.8.self_attn.k_proj\n",
            "2024-08-25 15:44:45 INFO export.py L152: packing model.layers.8.self_attn.v_proj\n",
            "2024-08-25 15:44:45 INFO export.py L152: packing model.layers.8.self_attn.o_proj\n",
            "2024-08-25 15:44:45 INFO export.py L152: packing model.layers.8.mlp.gate_proj\n",
            "2024-08-25 15:44:48 INFO export.py L152: packing model.layers.8.mlp.up_proj\n",
            "2024-08-25 15:44:50 INFO export.py L152: packing model.layers.8.mlp.down_proj\n",
            "2024-08-25 15:44:52 INFO export.py L152: packing model.layers.9.self_attn.q_proj\n",
            "2024-08-25 15:44:53 INFO export.py L152: packing model.layers.9.self_attn.k_proj\n",
            "2024-08-25 15:44:53 INFO export.py L152: packing model.layers.9.self_attn.v_proj\n",
            "2024-08-25 15:44:53 INFO export.py L152: packing model.layers.9.self_attn.o_proj\n",
            "2024-08-25 15:44:54 INFO export.py L152: packing model.layers.9.mlp.gate_proj\n",
            "2024-08-25 15:44:56 INFO export.py L152: packing model.layers.9.mlp.up_proj\n",
            "2024-08-25 15:44:58 INFO export.py L152: packing model.layers.9.mlp.down_proj\n",
            "2024-08-25 15:45:00 INFO export.py L152: packing model.layers.10.self_attn.q_proj\n",
            "2024-08-25 15:45:01 INFO export.py L152: packing model.layers.10.self_attn.k_proj\n",
            "2024-08-25 15:45:01 INFO export.py L152: packing model.layers.10.self_attn.v_proj\n",
            "2024-08-25 15:45:01 INFO export.py L152: packing model.layers.10.self_attn.o_proj\n",
            "2024-08-25 15:45:02 INFO export.py L152: packing model.layers.10.mlp.gate_proj\n",
            "2024-08-25 15:45:04 INFO export.py L152: packing model.layers.10.mlp.up_proj\n",
            "2024-08-25 15:45:06 INFO export.py L152: packing model.layers.10.mlp.down_proj\n",
            "2024-08-25 15:45:09 INFO export.py L152: packing model.layers.11.self_attn.q_proj\n",
            "2024-08-25 15:45:09 INFO export.py L152: packing model.layers.11.self_attn.k_proj\n",
            "2024-08-25 15:45:09 INFO export.py L152: packing model.layers.11.self_attn.v_proj\n",
            "2024-08-25 15:45:10 INFO export.py L152: packing model.layers.11.self_attn.o_proj\n",
            "2024-08-25 15:45:10 INFO export.py L152: packing model.layers.11.mlp.gate_proj\n",
            "2024-08-25 15:45:12 INFO export.py L152: packing model.layers.11.mlp.up_proj\n",
            "2024-08-25 15:45:15 INFO export.py L152: packing model.layers.11.mlp.down_proj\n",
            "2024-08-25 15:45:17 INFO export.py L152: packing model.layers.12.self_attn.q_proj\n",
            "2024-08-25 15:45:17 INFO export.py L152: packing model.layers.12.self_attn.k_proj\n",
            "2024-08-25 15:45:18 INFO export.py L152: packing model.layers.12.self_attn.v_proj\n",
            "2024-08-25 15:45:18 INFO export.py L152: packing model.layers.12.self_attn.o_proj\n",
            "2024-08-25 15:45:19 INFO export.py L152: packing model.layers.12.mlp.gate_proj\n",
            "2024-08-25 15:45:21 INFO export.py L152: packing model.layers.12.mlp.up_proj\n",
            "2024-08-25 15:45:23 INFO export.py L152: packing model.layers.12.mlp.down_proj\n",
            "2024-08-25 15:45:25 INFO export.py L152: packing model.layers.13.self_attn.q_proj\n",
            "2024-08-25 15:45:26 INFO export.py L152: packing model.layers.13.self_attn.k_proj\n",
            "2024-08-25 15:45:26 INFO export.py L152: packing model.layers.13.self_attn.v_proj\n",
            "2024-08-25 15:45:26 INFO export.py L152: packing model.layers.13.self_attn.o_proj\n",
            "2024-08-25 15:45:27 INFO export.py L152: packing model.layers.13.mlp.gate_proj\n",
            "2024-08-25 15:45:29 INFO export.py L152: packing model.layers.13.mlp.up_proj\n",
            "2024-08-25 15:45:31 INFO export.py L152: packing model.layers.13.mlp.down_proj\n",
            "2024-08-25 15:45:33 INFO export.py L152: packing model.layers.14.self_attn.q_proj\n",
            "2024-08-25 15:45:34 INFO export.py L152: packing model.layers.14.self_attn.k_proj\n",
            "2024-08-25 15:45:34 INFO export.py L152: packing model.layers.14.self_attn.v_proj\n",
            "2024-08-25 15:45:34 INFO export.py L152: packing model.layers.14.self_attn.o_proj\n",
            "2024-08-25 15:45:35 INFO export.py L152: packing model.layers.14.mlp.gate_proj\n",
            "2024-08-25 15:45:37 INFO export.py L152: packing model.layers.14.mlp.up_proj\n",
            "2024-08-25 15:45:39 INFO export.py L152: packing model.layers.14.mlp.down_proj\n",
            "2024-08-25 15:45:41 INFO export.py L152: packing model.layers.15.self_attn.q_proj\n",
            "2024-08-25 15:45:42 INFO export.py L152: packing model.layers.15.self_attn.k_proj\n",
            "2024-08-25 15:45:42 INFO export.py L152: packing model.layers.15.self_attn.v_proj\n",
            "2024-08-25 15:45:43 INFO export.py L152: packing model.layers.15.self_attn.o_proj\n",
            "2024-08-25 15:45:43 INFO export.py L152: packing model.layers.15.mlp.gate_proj\n",
            "2024-08-25 15:45:45 INFO export.py L152: packing model.layers.15.mlp.up_proj\n",
            "2024-08-25 15:45:48 INFO export.py L152: packing model.layers.15.mlp.down_proj\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model_name = \"nvidia/Llama-3.1-Minitron-4B-Depth-Base\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "from auto_round import AutoRound\n",
        "\n",
        "bits, group_size, sym = 4, 128, False\n",
        "autoround = AutoRound(model, tokenizer, bits=bits, group_size=group_size, batch_size=2, seqlen=512, sym=sym, gradient_accumulate_steps=4, device='cuda')\n",
        "autoround.quantize()\n",
        "output_dir = \"./AutoRound/Llama-3.1-Minitron-4B-Depth-Base-AutoRound-GPTQ-asym-4bit/\"\n",
        "autoround.save_quantized(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation"
      ],
      "metadata": {
        "id": "WgMIEPL8FRei"
      },
      "id": "WgMIEPL8FRei"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to install the Evaluation Harness:"
      ],
      "metadata": {
        "id": "uC14dme9FTib"
      },
      "id": "uC14dme9FTib"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f1ceaa7-bf21-432f-b3ee-9b4766dc2ca9",
      "metadata": {
        "id": "3f1ceaa7-bf21-432f-b3ee-9b4766dc2ca9",
        "outputId": "3a21b644-c44e-413f-d7db-9b231624d9f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/EleutherAI/lm-evaluation-harness.git\n",
            "  Cloning https://github.com/EleutherAI/lm-evaluation-harness.git to /tmp/pip-req-build-feqo38wu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/EleutherAI/lm-evaluation-harness.git /tmp/pip-req-build-feqo38wu\n",
            "  Resolved https://github.com/EleutherAI/lm-evaluation-harness.git to commit aab42ba836b4af28cc1c5c1e697ea334c6ea7ced\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.3) (0.33.0)\n",
            "Collecting evaluate (from lm_eval==0.4.3)\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.3) (2.21.0)\n",
            "Collecting jsonlines (from lm_eval==0.4.3)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting numexpr (from lm_eval==0.4.3)\n",
            "  Downloading numexpr-2.10.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.3) (0.12.0)\n",
            "Collecting pybind11>=2.6.2 (from lm_eval==0.4.3)\n",
            "  Downloading pybind11-2.13.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pytablewriter (from lm_eval==0.4.3)\n",
            "  Downloading pytablewriter-1.2.0-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting rouge-score>=0.0.4 (from lm_eval==0.4.3)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting sacrebleu>=1.5.0 (from lm_eval==0.4.3)\n",
            "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.3) (1.5.1)\n",
            "Collecting sqlitedict (from lm_eval==0.4.3)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.3) (2.1.0+cu118)\n",
            "Collecting tqdm-multiprocess (from lm_eval==0.4.3)\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.3) (4.43.4)\n",
            "Collecting zstandard (from lm_eval==0.4.3)\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.3) (0.3.8)\n",
            "Collecting word2number (from lm_eval==0.4.3)\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from lm_eval==0.4.3) (8.10.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (1.24.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (5.9.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (0.24.6)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (0.4.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.3) (3.9.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.3) (17.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.3) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.3) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.3) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.3) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.3) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.16.0->lm_eval==0.4.3) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.3) (3.10.5)\n",
            "Collecting absl-py (from rouge-score>=0.0.4->lm_eval==0.4.3)\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting nltk (from rouge-score>=0.0.4->lm_eval==0.4.3)\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3/dist-packages (from rouge-score>=0.0.4->lm_eval==0.4.3) (1.16.0)\n",
            "Collecting portalocker (from sacrebleu>=1.5.0->lm_eval==0.4.3)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.3) (2024.7.24)\n",
            "Collecting tabulate>=0.8.9 (from sacrebleu>=1.5.0->lm_eval==0.4.3)\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting colorama (from sacrebleu>=1.5.0->lm_eval==0.4.3)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.3) (4.9.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.4.3) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.4.3) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.4.3) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.3) (4.4.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.3) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.3) (3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.3) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.3) (2.1.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.1->lm_eval==0.4.3) (0.19.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->lm_eval==0.4.3) (23.1.0)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval==0.4.3) (68.2.2)\n",
            "Collecting DataProperty<2,>=1.0.1 (from pytablewriter->lm_eval==0.4.3)\n",
            "  Downloading DataProperty-1.0.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval==0.4.3)\n",
            "  Downloading mbstrdecoder-1.1.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval==0.4.3)\n",
            "  Downloading pathvalidate-3.2.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval==0.4.3)\n",
            "  Downloading tabledata-1.3.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval==0.4.3)\n",
            "  Downloading tcolorpy-0.1.6-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.3)\n",
            "  Downloading typepy-1.3.2-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (4.0.3)\n",
            "Collecting chardet<6,>=3.0.4 (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.4.3)\n",
            "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==0.4.3) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==0.4.3) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==0.4.3) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm_eval==0.4.3) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.3) (2024.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->lm_eval==0.4.3) (2.1.2)\n",
            "Collecting click (from nltk->rouge-score>=0.0.4->lm_eval==0.4.3)\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->lm_eval==0.4.3) (2024.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8->lm_eval==0.4.3) (1.3.0)\n",
            "Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.5-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.0/241.0 kB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading numexpr-2.10.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (405 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.0/405.0 kB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m131.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
            "Downloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
            "Downloading pathvalidate-3.2.1-py3-none-any.whl (23 kB)\n",
            "Downloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
            "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Downloading tcolorpy-0.1.6-py3-none-any.whl (8.1 kB)\n",
            "Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n",
            "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m120.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: lm_eval, rouge-score, sqlitedict, word2number\n",
            "  Building wheel for lm_eval (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for lm_eval: filename=lm_eval-0.4.3-py3-none-any.whl size=2000624 sha256=c140a50267ded149ae2e89008a28c6b48569c2aae5996e5e1ee1a2ab9c231247\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z2ihkk3h/wheels/ff/d5/f4/949f2b285369fc332f8dbba43f220ebd88387ee2f2c0c1174f\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=04d8eff1003db7b3a9d761b0d2cffe6b66e9187644911a2182827b8e2e2a8b44\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=6dd9f0683c23a8a6567b91f7d0bfb9c44a53f416a8e63d3d4ad557afa2f1dcba\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=b034d06429cf03c260c8702a8b53b90d77b80920e31d22f4dbd28f312aa2e4d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n",
            "Successfully built lm_eval rouge-score sqlitedict word2number\n",
            "Installing collected packages: word2number, sqlitedict, zstandard, tcolorpy, tabulate, pybind11, portalocker, pathvalidate, numexpr, jsonlines, colorama, click, chardet, absl-py, tqdm-multiprocess, sacrebleu, nltk, mbstrdecoder, typepy, rouge-score, evaluate, DataProperty, tabledata, pytablewriter, lm_eval\n",
            "Successfully installed DataProperty-1.0.1 absl-py-2.1.0 chardet-5.2.0 click-8.1.7 colorama-0.4.6 evaluate-0.4.2 jsonlines-4.0.0 lm_eval-0.4.3 mbstrdecoder-1.1.3 nltk-3.9.1 numexpr-2.10.1 pathvalidate-3.2.1 portalocker-2.10.1 pybind11-2.13.5 pytablewriter-1.2.0 rouge-score-0.1.2 sacrebleu-2.4.3 sqlitedict-2.1.0 tabledata-1.3.3 tabulate-0.9.0 tcolorpy-0.1.6 tqdm-multiprocess-0.0.11 typepy-1.3.2 word2number-1.1 zstandard-0.23.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/EleutherAI/lm-evaluation-harness.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###nvidia/Mistral-NeMo-Minitron-8B-Base"
      ],
      "metadata": {
        "id": "yzE2hB8XFdJy"
      },
      "id": "yzE2hB8XFdJy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2966f3d1-c341-47b0-b37f-7f1e50363610",
      "metadata": {
        "id": "2966f3d1-c341-47b0-b37f-7f1e50363610",
        "outputId": "010eb009-efc5-4dfb-e245-13ba9f7fef44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
            "Running loglikelihood requests: 100%|██| 174850/174850 [17:47<00:00, 163.80it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-23:15:04:45,837 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=nvidia/Mistral-NeMo-Minitron-8B-Base), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.5435|±  |0.0146|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.5742|±  |0.0144|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.3398|±  |0.0043|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.6565|±  |0.0037|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5996|±  |0.0065|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.4206|±  |0.0442|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7818|±  |0.0323|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.8431|±  |0.0255|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.8776|±  |0.0213|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.8017|±  |0.0364|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.7963|±  |0.0389|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7853|±  |0.0323|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.7283|±  |0.0239|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2726|±  |0.0149|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.7524|±  |0.0245|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.7716|±  |0.0234|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.5385|±  |0.0127|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.8304|±  |0.0288|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.7329|±  |0.0076|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.6700|±  |0.0473|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.7283|±  |0.0274|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.6590|±  |0.0361|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.3700|±  |0.0485|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.7489|±  |0.0291|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.7961|±  |0.0399|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8846|±  |0.0209|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.7400|±  |0.0441|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.8455|±  |0.0129|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.7810|±  |0.0237|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.5213|±  |0.0298|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.7316|±  |0.0269|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5361|±  |0.0388|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.7644|±  |0.0075|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.4825|±  |0.0470|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.8384|±  |0.0262|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8808|±  |0.0234|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.6718|±  |0.0238|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.7185|±  |0.0292|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.8587|±  |0.0149|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.7863|±  |0.0360|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.7092|±  |0.0184|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6636|±  |0.0453|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.7673|±  |0.0270|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.8408|±  |0.0259|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.9300|±  |0.0256|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5611|±  |0.0084|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3300|±  |0.0473|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.6296|±  |0.0417|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.7566|±  |0.0349|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.7778|±  |0.0348|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4800|±  |0.0502|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.4700|±  |0.0502|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.3900|±  |0.0490|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.4118|±  |0.0490|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.7300|±  |0.0446|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.6213|±  |0.0317|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.5655|±  |0.0413|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4444|±  |0.0256|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.8226|±  |0.0217|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.5567|±  |0.0350|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.7000|±  |0.0461|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3556|±  |0.0292|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.4768|±  |0.0408|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.5926|±  |0.0335|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.4018|±  |0.0465|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.6565|±  |0.0037|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5996|±  |0.0065|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.7329|±  |0.0076|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.7644|±  |0.0075|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5611|±  |0.0084|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=nvidia/Mistral-NeMo-Minitron-8B-Base --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a2d6391-91ff-4dfd-9e38-d022833f657c",
      "metadata": {
        "id": "6a2d6391-91ff-4dfd-9e38-d022833f657c",
        "outputId": "33c59d46-5118-43ab-ec51-63a36a80fbb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-23:19:02:59,002 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-23:19:02:59,115 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-23:19:03:13,340 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-23:19:03:13,342 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-23:19:03:13,342 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'nvidia/Mistral-NeMo-Minitron-8B-Base', 'load_in_8bit': True}\n",
            "2024-08-23:19:03:13,572 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-23:19:03:13,572 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "2024-08-23:19:03:14,025 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:30<00:00,  7.69s/it]\n",
            "2024-08-23:19:03:46,186 WARNING  [big_modeling.py:451] You shouldn't move a model that is dispatched using accelerate hooks.\n",
            "2024-08-23:19:04:17,343 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-23:19:04:17,343 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,343 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-23:19:04:17,343 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,343 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-23:19:04:17,343 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,343 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-23:19:04:17,343 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,343 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-23:19:04:17,343 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,343 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-23:19:04:17,343 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,343 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-23:19:04:17,343 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,343 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-23:19:04:17,343 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,344 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-23:19:04:17,344 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,344 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-23:19:04:17,344 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,344 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-23:19:04:17,344 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,344 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-23:19:04:17,344 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,344 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-23:19:04:17,344 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,344 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-23:19:04:17,344 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,344 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-23:19:04:17,344 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,344 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-23:19:04:17,344 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,344 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-23:19:04:17,344 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,344 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-23:19:04:17,344 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,344 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-23:19:04:17,344 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,344 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-23:19:04:17,344 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,344 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-23:19:04:17,345 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,345 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-23:19:04:17,345 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,345 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-23:19:04:17,345 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,345 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-23:19:04:17,345 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,345 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-23:19:04:17,345 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,345 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-23:19:04:17,345 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,345 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-23:19:04:17,345 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,345 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-23:19:04:17,345 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,345 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-23:19:04:17,345 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,345 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-23:19:04:17,345 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,345 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-23:19:04:17,345 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,345 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-23:19:04:17,345 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,345 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-23:19:04:17,346 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,346 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-23:19:04:17,346 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,346 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-23:19:04:17,346 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,346 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-23:19:04:17,346 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,346 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-23:19:04:17,346 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,346 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-23:19:04:17,346 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,346 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-23:19:04:17,346 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,346 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-23:19:04:17,346 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,346 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-23:19:04:17,346 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,346 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-23:19:04:17,346 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,346 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-23:19:04:17,346 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,346 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-23:19:04:17,347 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,347 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-23:19:04:17,347 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,347 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-23:19:04:17,347 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,347 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-23:19:04:17,347 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,347 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-23:19:04:17,347 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,347 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-23:19:04:17,347 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,347 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-23:19:04:17,347 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,347 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-23:19:04:17,347 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,347 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-23:19:04:17,347 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,347 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-23:19:04:17,347 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,347 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-23:19:04:17,347 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,347 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-23:19:04:17,347 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,347 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-23:19:04:17,348 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,348 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-23:19:04:17,348 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,348 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-23:19:04:17,348 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,348 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-23:19:04:17,348 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:04:17,348 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-23:19:04:17,357 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 574.30it/s]\n",
            "2024-08-23:19:04:17,536 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 577.98it/s]\n",
            "2024-08-23:19:04:17,776 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 577.40it/s]\n",
            "2024-08-23:19:04:18,047 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 577.89it/s]\n",
            "2024-08-23:19:04:18,303 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 582.63it/s]\n",
            "2024-08-23:19:04:18,480 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 573.53it/s]\n",
            "2024-08-23:19:04:18,659 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 577.10it/s]\n",
            "2024-08-23:19:04:18,838 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 566.61it/s]\n",
            "2024-08-23:19:04:19,023 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 578.09it/s]\n",
            "2024-08-23:19:04:19,201 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 572.78it/s]\n",
            "2024-08-23:19:04:19,623 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 579.76it/s]\n",
            "2024-08-23:19:04:19,880 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 606.54it/s]\n",
            "2024-08-23:19:04:20,521 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 704.53it/s]\n",
            "2024-08-23:19:04:20,973 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 706.10it/s]\n",
            "2024-08-23:19:04:21,269 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 697.17it/s]\n",
            "2024-08-23:19:04:21,417 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 703.49it/s]\n",
            "2024-08-23:19:04:21,811 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 694.33it/s]\n",
            "2024-08-23:19:04:22,035 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 688.21it/s]\n",
            "2024-08-23:19:04:22,358 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 697.77it/s]\n",
            "2024-08-23:19:04:22,523 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 702.00it/s]\n",
            "2024-08-23:19:04:22,670 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 696.04it/s]\n",
            "2024-08-23:19:04:23,061 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 700.84it/s]\n",
            "2024-08-23:19:04:23,315 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 701.89it/s]\n",
            "2024-08-23:19:04:23,462 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 704.48it/s]\n",
            "2024-08-23:19:04:23,787 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 699.18it/s]\n",
            "2024-08-23:19:04:23,939 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 700.12it/s]\n",
            "2024-08-23:19:04:24,282 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 698.36it/s]\n",
            "2024-08-23:19:04:24,430 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 699.75it/s]\n",
            "2024-08-23:19:04:25,730 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 705.37it/s]\n",
            "2024-08-23:19:04:26,176 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 703.33it/s]\n",
            "2024-08-23:19:04:26,588 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 695.73it/s]\n",
            "2024-08-23:19:04:26,990 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 704.13it/s]\n",
            "2024-08-23:19:04:27,233 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 700.01it/s]\n",
            "2024-08-23:19:04:27,400 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 698.24it/s]\n",
            "2024-08-23:19:04:27,692 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 700.07it/s]\n",
            "2024-08-23:19:04:27,975 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 701.97it/s]\n",
            "2024-08-23:19:04:28,546 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 696.01it/s]\n",
            "2024-08-23:19:04:28,898 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 703.90it/s]\n",
            "2024-08-23:19:04:29,693 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 697.37it/s]\n",
            "2024-08-23:19:04:29,886 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 699.70it/s]\n",
            "2024-08-23:19:04:30,785 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 684.06it/s]\n",
            "2024-08-23:19:04:30,951 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 695.07it/s]\n",
            "2024-08-23:19:04:31,313 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 700.92it/s]\n",
            "2024-08-23:19:04:31,608 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 699.84it/s]\n",
            "2024-08-23:19:04:31,755 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 702.58it/s]\n",
            "2024-08-23:19:04:31,940 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 699.53it/s]\n",
            "2024-08-23:19:04:32,183 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 692.00it/s]\n",
            "2024-08-23:19:04:32,487 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 696.92it/s]\n",
            "2024-08-23:19:04:32,837 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 683.76it/s]\n",
            "2024-08-23:19:04:33,019 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 699.48it/s]\n",
            "2024-08-23:19:04:33,178 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 700.57it/s]\n",
            "2024-08-23:19:04:33,418 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 699.95it/s]\n",
            "2024-08-23:19:04:33,926 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 612.05it/s]\n",
            "2024-08-23:19:04:35,422 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 706.23it/s]\n",
            "2024-08-23:19:04:35,875 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 705.04it/s]\n",
            "2024-08-23:19:04:36,348 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 702.87it/s]\n",
            "2024-08-23:19:04:38,591 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 707.45it/s]\n",
            "2024-08-23:19:04:38,839 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 16504.60it/s]\n",
            "2024-08-23:19:04:40,383 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1383.96it/s]\n",
            "2024-08-23:19:04:41,289 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "Running loglikelihood requests: 100%|███| 174850/174850 [40:33<00:00, 71.84it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-23:19:47:09,733 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=nvidia/Mistral-NeMo-Minitron-8B-Base,load_in_8bit=True), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.5444|±  |0.0146|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.5742|±  |0.0144|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.3393|±  |0.0043|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.6564|±  |0.0037|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.6002|±  |0.0065|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.4286|±  |0.0443|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7576|±  |0.0335|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.8480|±  |0.0252|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.8819|±  |0.0210|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.7934|±  |0.0370|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.7870|±  |0.0396|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7914|±  |0.0319|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.7312|±  |0.0239|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2804|±  |0.0150|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.7524|±  |0.0245|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.7747|±  |0.0232|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.5346|±  |0.0127|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.8421|±  |0.0280|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.7293|±  |0.0076|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.6800|±  |0.0469|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.7321|±  |0.0273|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.6647|±  |0.0360|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.3500|±  |0.0479|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.7444|±  |0.0293|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.8058|±  |0.0392|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8846|±  |0.0209|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.7600|±  |0.0429|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.8467|±  |0.0129|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.7712|±  |0.0241|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.5106|±  |0.0298|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.7243|±  |0.0271|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.4940|±  |0.0389|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.7647|±  |0.0075|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.4737|±  |0.0470|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.8434|±  |0.0259|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8860|±  |0.0229|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.6718|±  |0.0238|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.7059|±  |0.0296|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.8569|±  |0.0150|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.7863|±  |0.0360|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.7092|±  |0.0184|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6818|±  |0.0446|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.7714|±  |0.0269|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.8458|±  |0.0255|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.9300|±  |0.0256|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5626|±  |0.0084|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3400|±  |0.0476|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.6444|±  |0.0414|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.7434|±  |0.0355|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.7778|±  |0.0348|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4900|±  |0.0502|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.4500|±  |0.0500|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.3900|±  |0.0490|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.4216|±  |0.0491|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.7600|±  |0.0429|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.6213|±  |0.0317|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.6000|±  |0.0408|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4392|±  |0.0256|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.8323|±  |0.0213|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.5517|±  |0.0350|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.7100|±  |0.0456|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3593|±  |0.0293|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.4570|±  |0.0407|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.5833|±  |0.0336|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.3929|±  |0.0464|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.6564|±  |0.0037|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.6002|±  |0.0065|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.7293|±  |0.0076|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.7647|±  |0.0075|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5626|±  |0.0084|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=nvidia/Mistral-NeMo-Minitron-8B-Base,load_in_8bit=True --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9a9bfa8-a76e-4af4-8da0-9487e2267fb3",
      "metadata": {
        "id": "b9a9bfa8-a76e-4af4-8da0-9487e2267fb3",
        "outputId": "a4671ad3-c43c-4b84-974f-6d4214935fb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-24:10:23:07,557 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-24:10:23:07,667 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-24:10:23:19,848 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-24:10:23:19,850 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-24:10:23:19,850 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'nvidia/Mistral-NeMo-Minitron-8B-Base', 'load_in_4bit': True}\n",
            "2024-08-24:10:23:20,079 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-24:10:23:20,079 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "2024-08-24:10:23:20,531 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:04<00:00,  1.15s/it]\n",
            "2024-08-24:10:23:26,507 WARNING  [big_modeling.py:451] You shouldn't move a model that is dispatched using accelerate hooks.\n",
            "2024-08-24:10:23:56,802 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-24:10:23:56,802 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,802 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-24:10:23:56,802 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,803 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-24:10:23:56,803 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,803 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-24:10:23:56,803 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,803 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-24:10:23:56,803 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,803 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-24:10:23:56,803 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,803 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-24:10:23:56,803 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,803 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-24:10:23:56,803 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,803 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-24:10:23:56,803 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,803 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-24:10:23:56,803 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,803 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-24:10:23:56,803 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,803 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-24:10:23:56,803 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,803 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-24:10:23:56,803 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,803 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-24:10:23:56,803 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,803 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-24:10:23:56,803 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,804 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-24:10:23:56,804 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,804 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-24:10:23:56,804 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,804 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-24:10:23:56,804 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,804 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-24:10:23:56,804 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,804 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-24:10:23:56,804 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,804 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-24:10:23:56,804 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,804 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-24:10:23:56,804 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,804 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-24:10:23:56,804 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,804 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-24:10:23:56,804 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,804 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-24:10:23:56,804 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,804 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-24:10:23:56,804 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,804 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-24:10:23:56,804 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,804 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-24:10:23:56,804 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,805 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-24:10:23:56,805 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,805 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-24:10:23:56,805 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,805 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-24:10:23:56,805 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,805 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-24:10:23:56,805 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,805 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-24:10:23:56,805 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,805 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-24:10:23:56,805 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,805 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-24:10:23:56,805 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,805 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-24:10:23:56,805 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,805 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-24:10:23:56,805 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,805 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-24:10:23:56,805 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,805 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-24:10:23:56,805 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,805 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-24:10:23:56,805 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,805 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-24:10:23:56,805 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,806 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-24:10:23:56,806 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,806 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-24:10:23:56,806 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,806 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-24:10:23:56,806 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,806 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-24:10:23:56,806 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,806 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-24:10:23:56,806 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,806 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-24:10:23:56,806 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,806 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-24:10:23:56,806 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,806 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-24:10:23:56,806 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,806 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-24:10:23:56,806 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,806 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-24:10:23:56,806 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,806 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-24:10:23:56,806 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,806 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-24:10:23:56,806 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,806 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-24:10:23:56,807 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,807 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-24:10:23:56,807 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,807 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-24:10:23:56,807 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,807 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-24:10:23:56,807 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,807 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-24:10:23:56,807 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,807 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-24:10:23:56,807 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:23:56,807 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-24:10:23:56,817 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 525.62it/s]\n",
            "2024-08-24:10:23:57,013 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 522.73it/s]\n",
            "2024-08-24:10:23:57,279 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 532.57it/s]\n",
            "2024-08-24:10:23:57,572 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 526.60it/s]\n",
            "2024-08-24:10:23:57,853 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 533.99it/s]\n",
            "2024-08-24:10:23:58,047 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 531.34it/s]\n",
            "2024-08-24:10:23:58,240 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 561.56it/s]\n",
            "2024-08-24:10:23:58,424 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 571.90it/s]\n",
            "2024-08-24:10:23:58,607 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 566.73it/s]\n",
            "2024-08-24:10:23:58,789 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 570.39it/s]\n",
            "2024-08-24:10:23:59,212 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 572.28it/s]\n",
            "2024-08-24:10:23:59,473 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 626.28it/s]\n",
            "2024-08-24:10:24:00,094 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 694.95it/s]\n",
            "2024-08-24:10:24:00,552 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 700.93it/s]\n",
            "2024-08-24:10:24:00,851 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 693.81it/s]\n",
            "2024-08-24:10:24:00,999 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 697.80it/s]\n",
            "2024-08-24:10:24:01,396 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 693.99it/s]\n",
            "2024-08-24:10:24:01,620 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 694.33it/s]\n",
            "2024-08-24:10:24:01,940 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 692.86it/s]\n",
            "2024-08-24:10:24:02,107 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 693.02it/s]\n",
            "2024-08-24:10:24:02,255 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 693.93it/s]\n",
            "2024-08-24:10:24:02,648 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 692.83it/s]\n",
            "2024-08-24:10:24:02,905 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 692.59it/s]\n",
            "2024-08-24:10:24:03,053 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 693.01it/s]\n",
            "2024-08-24:10:24:03,384 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 691.22it/s]\n",
            "2024-08-24:10:24:03,537 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 688.62it/s]\n",
            "2024-08-24:10:24:03,886 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 690.16it/s]\n",
            "2024-08-24:10:24:04,035 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 694.13it/s]\n",
            "2024-08-24:10:24:05,348 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 691.61it/s]\n",
            "2024-08-24:10:24:05,803 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 691.48it/s]\n",
            "2024-08-24:10:24:06,223 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 690.16it/s]\n",
            "2024-08-24:10:24:06,628 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 693.51it/s]\n",
            "2024-08-24:10:24:06,874 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 705.76it/s]\n",
            "2024-08-24:10:24:07,041 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 703.50it/s]\n",
            "2024-08-24:10:24:07,330 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 696.20it/s]\n",
            "2024-08-24:10:24:07,615 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 701.24it/s]\n",
            "2024-08-24:10:24:08,187 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 698.61it/s]\n",
            "2024-08-24:10:24:08,537 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 700.18it/s]\n",
            "2024-08-24:10:24:09,336 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 685.34it/s]\n",
            "2024-08-24:10:24:09,533 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 677.98it/s]\n",
            "2024-08-24:10:24:10,460 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 576.56it/s]\n",
            "2024-08-24:10:24:10,657 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 580.31it/s]\n",
            "2024-08-24:10:24:11,091 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 579.35it/s]\n",
            "2024-08-24:10:24:11,448 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 579.28it/s]\n",
            "2024-08-24:10:24:11,625 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 578.21it/s]\n",
            "2024-08-24:10:24:11,850 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 575.73it/s]\n",
            "2024-08-24:10:24:12,145 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 607.86it/s]\n",
            "2024-08-24:10:24:12,491 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 697.02it/s]\n",
            "2024-08-24:10:24:12,841 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 694.51it/s]\n",
            "2024-08-24:10:24:13,020 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 696.87it/s]\n",
            "2024-08-24:10:24:13,180 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 704.66it/s]\n",
            "2024-08-24:10:24:13,418 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 704.28it/s]\n",
            "2024-08-24:10:24:13,923 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 615.62it/s]\n",
            "2024-08-24:10:24:15,411 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 700.87it/s]\n",
            "2024-08-24:10:24:15,868 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 702.86it/s]\n",
            "2024-08-24:10:24:16,342 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 700.02it/s]\n",
            "2024-08-24:10:24:18,594 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 702.23it/s]\n",
            "2024-08-24:10:24:18,845 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 15891.69it/s]\n",
            "2024-08-24:10:24:20,420 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1384.26it/s]\n",
            "2024-08-24:10:24:21,324 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
            "Running loglikelihood requests: 100%|██| 174850/174850 [21:55<00:00, 132.96it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-24:10:48:11,809 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=nvidia/Mistral-NeMo-Minitron-8B-Base,load_in_4bit=True), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.5102|±  |0.0146|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.5495|±  |0.0145|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.2960|±  |0.0042|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.6237|±  |0.0038|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5739|±  |0.0067|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.3968|±  |0.0438|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7576|±  |0.0335|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.7990|±  |0.0281|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.8186|±  |0.0251|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.7273|±  |0.0407|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.7593|±  |0.0413|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7853|±  |0.0323|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.6763|±  |0.0252|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2983|±  |0.0153|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.7331|±  |0.0251|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.7377|±  |0.0245|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4967|±  |0.0128|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.8187|±  |0.0295|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.6991|±  |0.0079|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.6800|±  |0.0469|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.6981|±  |0.0283|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.6012|±  |0.0373|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.4000|±  |0.0492|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.7309|±  |0.0298|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.7379|±  |0.0435|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8333|±  |0.0244|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.7200|±  |0.0451|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.8301|±  |0.0134|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.7092|±  |0.0260|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.4787|±  |0.0298|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.6728|±  |0.0285|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5060|±  |0.0389|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.7221|±  |0.0079|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.4211|±  |0.0464|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.7879|±  |0.0291|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8756|±  |0.0238|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.6359|±  |0.0244|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.6429|±  |0.0311|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.8202|±  |0.0165|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.7481|±  |0.0381|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.6618|±  |0.0191|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6636|±  |0.0453|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.7347|±  |0.0283|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.8010|±  |0.0282|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.8400|±  |0.0368|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5278|±  |0.0085|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3200|±  |0.0469|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.5778|±  |0.0427|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.7171|±  |0.0367|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.7500|±  |0.0362|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4400|±  |0.0499|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.4300|±  |0.0498|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.4000|±  |0.0492|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.4020|±  |0.0488|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.7300|±  |0.0446|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5830|±  |0.0322|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.5862|±  |0.0410|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4101|±  |0.0253|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7516|±  |0.0246|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.4680|±  |0.0351|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.6600|±  |0.0476|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3444|±  |0.0290|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.4503|±  |0.0406|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.5648|±  |0.0338|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.3750|±  |0.0460|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.6237|±  |0.0038|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5739|±  |0.0067|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.6991|±  |0.0079|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.7221|±  |0.0079|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5278|±  |0.0085|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=nvidia/Mistral-NeMo-Minitron-8B-Base,load_in_4bit=True --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "553916b8-a399-40f9-80ce-ba9bd6aa0228",
      "metadata": {
        "id": "553916b8-a399-40f9-80ce-ba9bd6aa0228",
        "outputId": "ec71b779-17e4-4b00-a26a-05d9d499533c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-23:18:02:20,361 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-23:18:02:20,461 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-23:18:02:34,470 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-23:18:02:34,472 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-23:18:02:34,472 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'kaitchup/Mistral-NeMo-Minitron-8B-Base-AutoRound-GPTQ-sym-4bit'}\n",
            "2024-08-23:18:02:34,723 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-23:18:02:34,723 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "config.json: 100%|█████████████████████████| 1.33k/1.33k [00:00<00:00, 8.23MB/s]\n",
            "tokenizer_config.json: 100%|█████████████████| 177k/177k [00:00<00:00, 14.6MB/s]\n",
            "tokenizer.json: 100%|██████████████████████| 9.26M/9.26M [00:00<00:00, 16.6MB/s]\n",
            "special_tokens_map.json: 100%|█████████████████| 414/414 [00:00<00:00, 4.00MB/s]\n",
            "2024-08-23:18:02:36,280 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "2024-08-23:18:02:37,236 WARNING  [qlinear_cuda.py:18] CUDA extension not installed.\n",
            "2024-08-23:18:02:37,237 WARNING  [qlinear_cuda_old.py:17] CUDA extension not installed.\n",
            "model.safetensors.index.json: 100%|█████████| 98.1k/98.1k [00:00<00:00, 136MB/s]\n",
            "Downloading shards:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0%|             | 0.00/4.89G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0%|    | 21.0M/4.89G [00:00<02:23, 33.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1%|    | 31.5M/4.89G [00:00<01:56, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1%|    | 41.9M/4.89G [00:00<01:49, 44.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1%|    | 52.4M/4.89G [00:01<02:53, 28.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1%|    | 73.4M/4.89G [00:02<02:32, 31.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2%|    | 83.9M/4.89G [00:02<03:03, 26.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2%|     | 105M/4.89G [00:03<03:12, 24.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2%|     | 115M/4.89G [00:04<03:26, 23.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3%|▏    | 126M/4.89G [00:05<04:09, 19.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3%|▏    | 136M/4.89G [00:05<03:21, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3%|▏    | 147M/4.89G [00:05<03:19, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3%|▏    | 157M/4.89G [00:06<03:21, 23.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3%|▏    | 168M/4.89G [00:06<03:04, 25.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4%|▏    | 178M/4.89G [00:06<02:34, 30.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4%|▏    | 189M/4.89G [00:06<02:20, 33.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4%|▏    | 199M/4.89G [00:06<01:52, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4%|▏    | 210M/4.89G [00:07<02:07, 36.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5%|▏    | 231M/4.89G [00:07<01:33, 49.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5%|▏    | 241M/4.89G [00:08<02:02, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5%|▎    | 262M/4.89G [00:08<01:55, 40.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6%|▎    | 273M/4.89G [00:08<01:59, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6%|▎    | 294M/4.89G [00:09<01:48, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6%|▎    | 304M/4.89G [00:09<02:03, 37.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6%|▎    | 315M/4.89G [00:10<02:47, 27.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7%|▎    | 325M/4.89G [00:10<03:09, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7%|▎    | 336M/4.89G [00:11<03:02, 25.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7%|▎    | 346M/4.89G [00:11<02:37, 28.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7%|▎    | 357M/4.89G [00:11<02:35, 29.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8%|▍    | 377M/4.89G [00:12<01:52, 40.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8%|▍    | 388M/4.89G [00:12<02:08, 35.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8%|▍    | 409M/4.89G [00:13<02:12, 33.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9%|▍    | 419M/4.89G [00:13<02:15, 33.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9%|▍    | 440M/4.89G [00:13<01:49, 40.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9%|▍    | 451M/4.89G [00:14<01:42, 43.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10%|▍    | 472M/4.89G [00:14<01:30, 48.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10%|▍    | 482M/4.89G [00:14<01:35, 46.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10%|▌    | 503M/4.89G [00:15<01:31, 48.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10%|▌    | 514M/4.89G [00:15<01:47, 40.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11%|▌    | 535M/4.89G [00:15<01:34, 46.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11%|▌    | 545M/4.89G [00:16<01:39, 43.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12%|▌    | 566M/4.89G [00:16<01:30, 47.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12%|▌    | 577M/4.89G [00:17<01:50, 39.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12%|▌    | 598M/4.89G [00:17<01:21, 52.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12%|▌    | 608M/4.89G [00:17<01:17, 55.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13%|▋    | 629M/4.89G [00:17<01:10, 60.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13%|▋    | 640M/4.89G [00:17<01:25, 49.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13%|▋    | 650M/4.89G [00:18<01:26, 48.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13%|▋    | 661M/4.89G [00:18<01:32, 45.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14%|▋    | 671M/4.89G [00:18<01:19, 53.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14%|▋    | 682M/4.89G [00:18<01:29, 47.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14%|▋    | 692M/4.89G [00:19<01:48, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15%|▋    | 713M/4.89G [00:20<02:08, 32.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15%|▋    | 724M/4.89G [00:20<02:14, 31.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15%|▊    | 744M/4.89G [00:20<01:48, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15%|▊    | 755M/4.89G [00:21<01:53, 36.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16%|▊    | 776M/4.89G [00:21<01:49, 37.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16%|▊    | 786M/4.89G [00:22<01:55, 35.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16%|▊    | 807M/4.89G [00:22<01:26, 47.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17%|▊    | 818M/4.89G [00:22<01:29, 45.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17%|▊    | 839M/4.89G [00:22<01:15, 53.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17%|▊    | 849M/4.89G [00:23<01:27, 46.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18%|▉    | 870M/4.89G [00:23<01:22, 49.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18%|▉    | 881M/4.89G [00:23<01:28, 45.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18%|▉    | 902M/4.89G [00:24<01:22, 48.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19%|▉    | 912M/4.89G [00:24<01:30, 44.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19%|▉    | 933M/4.89G [00:25<01:33, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19%|▉    | 944M/4.89G [00:25<01:31, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19%|▉    | 954M/4.89G [00:25<01:32, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20%|▉    | 965M/4.89G [00:26<02:07, 30.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20%|▉    | 975M/4.89G [00:26<01:45, 37.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20%|█    | 986M/4.89G [00:26<01:47, 36.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20%|█    | 996M/4.89G [00:26<01:47, 36.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21%|▊   | 1.02G/4.89G [00:27<01:31, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21%|▊   | 1.03G/4.89G [00:27<01:37, 39.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21%|▊   | 1.05G/4.89G [00:27<01:26, 44.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22%|▊   | 1.06G/4.89G [00:28<01:42, 37.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22%|▉   | 1.08G/4.89G [00:28<01:38, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22%|▉   | 1.09G/4.89G [00:29<01:31, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23%|▉   | 1.11G/4.89G [00:29<01:26, 43.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23%|▉   | 1.12G/4.89G [00:29<01:44, 36.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23%|▉   | 1.14G/4.89G [00:30<01:36, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24%|▉   | 1.15G/4.89G [00:31<02:12, 28.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24%|▉   | 1.16G/4.89G [00:31<02:03, 30.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24%|▉   | 1.17G/4.89G [00:31<01:58, 31.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24%|▉   | 1.18G/4.89G [00:31<01:42, 36.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24%|▉   | 1.20G/4.89G [00:32<01:40, 36.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25%|▉   | 1.21G/4.89G [00:32<01:46, 34.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25%|▉   | 1.22G/4.89G [00:32<01:49, 33.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25%|█   | 1.24G/4.89G [00:33<01:38, 37.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26%|█   | 1.26G/4.89G [00:33<01:18, 46.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26%|█   | 1.27G/4.89G [00:34<01:50, 32.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26%|█   | 1.29G/4.89G [00:35<02:05, 28.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27%|█   | 1.30G/4.89G [00:35<02:09, 27.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27%|█   | 1.32G/4.89G [00:36<01:46, 33.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27%|█   | 1.33G/4.89G [00:36<01:47, 33.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28%|█   | 1.35G/4.89G [00:36<01:40, 35.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28%|█   | 1.36G/4.89G [00:37<02:01, 29.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28%|█   | 1.37G/4.89G [00:37<01:47, 32.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28%|█▏  | 1.38G/4.89G [00:38<01:57, 29.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28%|█▏  | 1.39G/4.89G [00:38<01:50, 31.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29%|█▏  | 1.42G/4.89G [00:38<01:24, 41.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29%|█▏  | 1.43G/4.89G [00:39<01:32, 37.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30%|█▏  | 1.45G/4.89G [00:39<01:13, 46.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30%|█▏  | 1.46G/4.89G [00:39<01:43, 33.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30%|█▏  | 1.48G/4.89G [00:40<01:38, 34.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30%|█▏  | 1.49G/4.89G [00:41<01:53, 30.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31%|█▏  | 1.50G/4.89G [00:41<01:50, 30.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31%|█▏  | 1.51G/4.89G [00:41<01:59, 28.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31%|█▏  | 1.52G/4.89G [00:42<02:11, 25.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31%|█▎  | 1.54G/4.89G [00:42<01:26, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32%|█▎  | 1.55G/4.89G [00:42<01:14, 44.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32%|█▎  | 1.56G/4.89G [00:42<01:04, 51.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32%|█▎  | 1.57G/4.89G [00:43<01:21, 40.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33%|█▎  | 1.59G/4.89G [00:43<01:12, 45.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33%|█▎  | 1.60G/4.89G [00:43<01:11, 46.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33%|█▎  | 1.63G/4.89G [00:44<01:26, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33%|█▎  | 1.64G/4.89G [00:44<01:26, 37.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34%|█▎  | 1.65G/4.89G [00:44<01:16, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34%|█▎  | 1.66G/4.89G [00:45<01:55, 28.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34%|█▎  | 1.67G/4.89G [00:46<02:09, 24.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34%|█▍  | 1.69G/4.89G [00:46<01:35, 33.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35%|█▍  | 1.70G/4.89G [00:46<01:28, 35.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35%|█▍  | 1.72G/4.89G [00:47<01:13, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35%|█▍  | 1.73G/4.89G [00:47<01:22, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36%|█▍  | 1.74G/4.89G [00:47<01:23, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36%|█▍  | 1.75G/4.89G [00:47<01:18, 39.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36%|█▍  | 1.76G/4.89G [00:48<01:23, 37.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36%|█▍  | 1.78G/4.89G [00:48<01:18, 39.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37%|█▍  | 1.79G/4.89G [00:49<01:23, 37.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37%|█▍  | 1.80G/4.89G [00:49<01:11, 43.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37%|█▍  | 1.81G/4.89G [00:49<01:04, 47.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37%|█▍  | 1.82G/4.89G [00:49<01:27, 35.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38%|█▌  | 1.85G/4.89G [00:50<01:12, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38%|█▌  | 1.87G/4.89G [00:50<01:05, 46.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38%|█▌  | 1.88G/4.89G [00:50<01:07, 44.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39%|█▌  | 1.90G/4.89G [00:51<00:53, 56.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39%|█▌  | 1.91G/4.89G [00:51<01:05, 45.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39%|█▌  | 1.93G/4.89G [00:51<00:58, 50.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40%|█▌  | 1.94G/4.89G [00:52<01:00, 49.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40%|█▌  | 1.96G/4.89G [00:52<00:44, 65.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40%|█▌  | 1.97G/4.89G [00:52<00:52, 55.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40%|█▌  | 1.98G/4.89G [00:52<01:02, 46.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41%|█▋  | 1.99G/4.89G [00:53<01:01, 47.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41%|█▋  | 2.00G/4.89G [00:53<01:03, 45.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41%|█▋  | 2.02G/4.89G [00:53<01:03, 44.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42%|█▋  | 2.03G/4.89G [00:53<00:56, 50.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42%|█▋  | 2.06G/4.89G [00:54<00:59, 47.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42%|█▋  | 2.07G/4.89G [00:54<01:13, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43%|█▋  | 2.09G/4.89G [00:55<01:06, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43%|█▋  | 2.10G/4.89G [00:55<01:17, 36.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43%|█▋  | 2.12G/4.89G [00:56<01:17, 35.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43%|█▋  | 2.13G/4.89G [00:56<01:35, 29.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44%|█▊  | 2.15G/4.89G [00:57<01:19, 34.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44%|█▊  | 2.16G/4.89G [00:57<01:24, 32.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45%|█▊  | 2.18G/4.89G [00:58<01:05, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45%|█▊  | 2.19G/4.89G [00:58<00:58, 46.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45%|█▊  | 2.20G/4.89G [00:58<00:53, 50.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45%|█▊  | 2.21G/4.89G [00:58<01:03, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46%|█▊  | 2.23G/4.89G [00:58<00:50, 52.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46%|█▊  | 2.24G/4.89G [00:59<00:49, 54.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46%|█▊  | 2.26G/4.89G [00:59<00:59, 44.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46%|█▊  | 2.28G/4.89G [00:59<00:56, 46.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47%|█▊  | 2.29G/4.89G [01:00<00:52, 49.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47%|█▉  | 2.30G/4.89G [01:00<00:54, 47.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47%|█▉  | 2.31G/4.89G [01:00<01:03, 40.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48%|█▉  | 2.33G/4.89G [01:01<00:54, 47.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48%|█▉  | 2.34G/4.89G [01:01<01:26, 29.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48%|█▉  | 2.36G/4.89G [01:02<01:29, 28.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48%|█▉  | 2.37G/4.89G [01:03<01:42, 24.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49%|█▉  | 2.38G/4.89G [01:03<01:33, 27.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49%|█▉  | 2.39G/4.89G [01:03<01:21, 30.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49%|█▉  | 2.40G/4.89G [01:04<01:17, 32.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49%|█▉  | 2.42G/4.89G [01:04<01:04, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50%|█▉  | 2.43G/4.89G [01:04<01:08, 36.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50%|██  | 2.45G/4.89G [01:05<01:16, 31.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50%|██  | 2.46G/4.89G [01:05<01:14, 32.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51%|██  | 2.49G/4.89G [01:06<01:13, 32.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51%|██  | 2.50G/4.89G [01:06<01:11, 33.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51%|██  | 2.51G/4.89G [01:06<01:07, 35.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51%|██  | 2.52G/4.89G [01:07<01:08, 34.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52%|██  | 2.54G/4.89G [01:07<00:47, 49.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52%|██  | 2.55G/4.89G [01:07<00:46, 50.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52%|██  | 2.57G/4.89G [01:07<00:38, 60.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53%|██  | 2.58G/4.89G [01:08<00:41, 56.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53%|██▏ | 2.60G/4.89G [01:08<00:48, 47.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53%|██▏ | 2.61G/4.89G [01:09<00:51, 44.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54%|██▏ | 2.63G/4.89G [01:09<00:43, 52.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54%|██▏ | 2.64G/4.89G [01:09<00:44, 50.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54%|██▏ | 2.66G/4.89G [01:09<00:45, 49.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55%|██▏ | 2.67G/4.89G [01:10<00:48, 45.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55%|██▏ | 2.69G/4.89G [01:10<00:43, 51.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55%|██▏ | 2.71G/4.89G [01:10<00:44, 48.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56%|██▏ | 2.73G/4.89G [01:11<00:52, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56%|██▏ | 2.74G/4.89G [01:11<00:54, 39.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56%|██▏ | 2.75G/4.89G [01:11<00:50, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56%|██▎ | 2.76G/4.89G [01:12<00:51, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57%|██▎ | 2.77G/4.89G [01:12<01:03, 33.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57%|██▎ | 2.79G/4.89G [01:12<00:44, 46.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57%|██▎ | 2.81G/4.89G [01:13<00:42, 49.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58%|██▎ | 2.82G/4.89G [01:13<00:44, 46.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58%|██▎ | 2.84G/4.89G [01:14<00:43, 46.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58%|██▎ | 2.85G/4.89G [01:14<00:49, 40.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59%|██▎ | 2.87G/4.89G [01:14<00:45, 44.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59%|██▎ | 2.88G/4.89G [01:15<01:02, 32.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59%|██▎ | 2.89G/4.89G [01:15<00:51, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59%|██▎ | 2.90G/4.89G [01:15<00:50, 39.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60%|██▍ | 2.92G/4.89G [01:16<01:00, 32.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60%|██▍ | 2.94G/4.89G [01:16<00:53, 36.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60%|██▍ | 2.95G/4.89G [01:17<00:53, 36.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61%|██▍ | 2.97G/4.89G [01:17<00:58, 33.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61%|██▍ | 2.98G/4.89G [01:18<01:06, 28.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61%|██▍ | 3.00G/4.89G [01:18<00:52, 36.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61%|██▍ | 3.01G/4.89G [01:18<00:49, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62%|██▍ | 3.03G/4.89G [01:19<00:37, 49.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62%|██▍ | 3.04G/4.89G [01:19<00:44, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62%|██▍ | 3.05G/4.89G [01:20<00:58, 31.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63%|██▌ | 3.06G/4.89G [01:20<00:53, 34.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63%|██▌ | 3.07G/4.89G [01:20<00:56, 32.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63%|██▌ | 3.09G/4.89G [01:21<00:45, 39.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63%|██▌ | 3.10G/4.89G [01:21<00:42, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64%|██▌ | 3.11G/4.89G [01:21<00:43, 40.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64%|██▌ | 3.12G/4.89G [01:21<00:47, 37.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64%|██▌ | 3.15G/4.89G [01:22<00:33, 51.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64%|██▌ | 3.16G/4.89G [01:22<00:43, 39.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65%|██▌ | 3.18G/4.89G [01:22<00:38, 44.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65%|██▌ | 3.19G/4.89G [01:23<00:41, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66%|██▌ | 3.21G/4.89G [01:23<00:33, 50.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66%|██▋ | 3.22G/4.89G [01:23<00:34, 48.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66%|██▋ | 3.24G/4.89G [01:24<00:38, 43.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66%|██▋ | 3.25G/4.89G [01:24<00:46, 35.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67%|██▋ | 3.26G/4.89G [01:25<00:49, 32.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67%|██▋ | 3.27G/4.89G [01:25<00:48, 33.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67%|██▋ | 3.28G/4.89G [01:25<00:47, 34.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67%|██▋ | 3.30G/4.89G [01:26<00:51, 31.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68%|██▋ | 3.31G/4.89G [01:26<00:49, 32.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68%|██▋ | 3.33G/4.89G [01:27<00:41, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68%|██▋ | 3.34G/4.89G [01:27<00:39, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69%|██▋ | 3.36G/4.89G [01:27<00:35, 43.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69%|██▊ | 3.37G/4.89G [01:27<00:38, 39.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69%|██▊ | 3.38G/4.89G [01:28<00:34, 43.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69%|██▊ | 3.40G/4.89G [01:28<00:27, 55.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70%|██▊ | 3.41G/4.89G [01:28<00:27, 53.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70%|██▊ | 3.42G/4.89G [01:28<00:29, 49.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70%|██▊ | 3.43G/4.89G [01:29<00:40, 35.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70%|██▊ | 3.45G/4.89G [01:29<00:31, 45.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71%|██▊ | 3.46G/4.89G [01:29<00:32, 44.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71%|██▊ | 3.47G/4.89G [01:30<00:27, 51.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71%|██▊ | 3.48G/4.89G [01:30<00:31, 44.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71%|██▊ | 3.49G/4.89G [01:30<00:35, 39.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72%|██▊ | 3.50G/4.89G [01:30<00:31, 44.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72%|██▊ | 3.51G/4.89G [01:31<00:29, 46.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72%|██▉ | 3.52G/4.89G [01:31<00:32, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72%|██▉ | 3.54G/4.89G [01:31<00:27, 49.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73%|██▉ | 3.55G/4.89G [01:32<00:31, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73%|██▉ | 3.58G/4.89G [01:32<00:31, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73%|██▉ | 3.59G/4.89G [01:32<00:29, 44.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74%|██▉ | 3.61G/4.89G [01:33<00:27, 47.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74%|██▉ | 3.62G/4.89G [01:33<00:28, 44.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74%|██▉ | 3.64G/4.89G [01:33<00:27, 45.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75%|██▉ | 3.65G/4.89G [01:34<00:26, 46.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75%|██▉ | 3.67G/4.89G [01:34<00:25, 47.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75%|███ | 3.68G/4.89G [01:34<00:26, 45.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76%|███ | 3.70G/4.89G [01:35<00:25, 46.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76%|███ | 3.71G/4.89G [01:35<00:26, 44.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76%|███ | 3.72G/4.89G [01:35<00:25, 46.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76%|███ | 3.73G/4.89G [01:36<00:27, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77%|███ | 3.75G/4.89G [01:36<00:20, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77%|███ | 3.76G/4.89G [01:36<00:25, 44.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77%|███ | 3.79G/4.89G [01:37<00:26, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78%|███ | 3.80G/4.89G [01:37<00:27, 40.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78%|███ | 3.81G/4.89G [01:37<00:24, 43.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78%|███ | 3.82G/4.89G [01:37<00:22, 46.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78%|███▏| 3.83G/4.89G [01:38<00:24, 44.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79%|███▏| 3.85G/4.89G [01:38<00:20, 50.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79%|███▏| 3.86G/4.89G [01:38<00:20, 50.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79%|███▏| 3.88G/4.89G [01:39<00:21, 48.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79%|███▏| 3.89G/4.89G [01:39<00:22, 44.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80%|███▏| 3.91G/4.89G [01:39<00:20, 49.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80%|███▏| 3.92G/4.89G [01:40<00:26, 36.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81%|███▏| 3.94G/4.89G [01:40<00:22, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81%|███▏| 3.95G/4.89G [01:41<00:24, 39.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81%|███▏| 3.96G/4.89G [01:41<00:20, 45.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81%|███▏| 3.97G/4.89G [01:41<00:25, 36.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81%|███▎| 3.98G/4.89G [01:41<00:25, 35.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82%|███▎| 4.01G/4.89G [01:42<00:21, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82%|███▎| 4.02G/4.89G [01:42<00:27, 32.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82%|███▎| 4.04G/4.89G [01:43<00:19, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83%|███▎| 4.05G/4.89G [01:43<00:18, 44.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83%|███▎| 4.06G/4.89G [01:43<00:18, 45.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83%|███▎| 4.07G/4.89G [01:44<00:27, 30.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84%|███▎| 4.09G/4.89G [01:44<00:21, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84%|███▎| 4.10G/4.89G [01:45<00:23, 33.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84%|███▎| 4.12G/4.89G [01:45<00:19, 39.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84%|███▍| 4.13G/4.89G [01:45<00:22, 34.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85%|███▍| 4.15G/4.89G [01:46<00:19, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85%|███▍| 4.16G/4.89G [01:46<00:19, 37.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85%|███▍| 4.18G/4.89G [01:47<00:17, 41.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86%|███▍| 4.19G/4.89G [01:47<00:16, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86%|███▍| 4.22G/4.89G [01:47<00:14, 47.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86%|███▍| 4.23G/4.89G [01:48<00:17, 37.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87%|███▍| 4.25G/4.89G [01:48<00:14, 44.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87%|███▍| 4.26G/4.89G [01:48<00:16, 39.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87%|███▍| 4.27G/4.89G [01:48<00:13, 45.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87%|███▍| 4.28G/4.89G [01:49<00:16, 36.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88%|███▌| 4.29G/4.89G [01:49<00:15, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88%|███▌| 4.31G/4.89G [01:49<00:12, 46.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88%|███▌| 4.32G/4.89G [01:50<00:15, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88%|███▌| 4.33G/4.89G [01:50<00:14, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89%|███▌| 4.34G/4.89G [01:51<00:18, 29.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89%|███▌| 4.35G/4.89G [01:51<00:15, 34.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89%|███▌| 4.36G/4.89G [01:51<00:16, 31.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89%|███▌| 4.37G/4.89G [01:52<00:16, 32.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90%|███▌| 4.39G/4.89G [01:52<00:14, 34.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90%|███▌| 4.40G/4.89G [01:52<00:13, 35.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90%|███▌| 4.42G/4.89G [01:53<00:10, 46.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91%|███▋| 4.44G/4.89G [01:53<00:09, 46.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91%|███▋| 4.46G/4.89G [01:53<00:08, 54.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91%|███▋| 4.47G/4.89G [01:54<00:09, 47.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92%|███▋| 4.49G/4.89G [01:54<00:08, 48.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92%|███▋| 4.50G/4.89G [01:54<00:10, 39.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92%|███▋| 4.52G/4.89G [01:55<00:07, 49.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93%|███▋| 4.53G/4.89G [01:55<00:07, 50.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93%|███▋| 4.55G/4.89G [01:55<00:05, 57.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93%|███▋| 4.56G/4.89G [01:55<00:05, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94%|███▋| 4.58G/4.89G [01:56<00:05, 60.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94%|███▊| 4.59G/4.89G [01:56<00:05, 51.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94%|███▊| 4.60G/4.89G [01:56<00:06, 48.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94%|███▊| 4.61G/4.89G [01:57<00:06, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94%|███▊| 4.62G/4.89G [01:57<00:07, 35.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95%|███▊| 4.65G/4.89G [01:57<00:05, 48.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95%|███▊| 4.66G/4.89G [01:57<00:05, 47.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95%|███▊| 4.67G/4.89G [01:58<00:05, 45.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96%|███▊| 4.68G/4.89G [01:58<00:05, 37.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96%|███▊| 4.70G/4.89G [01:59<00:04, 40.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96%|███▊| 4.71G/4.89G [01:59<00:04, 40.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97%|███▊| 4.73G/4.89G [01:59<00:03, 53.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97%|███▊| 4.74G/4.89G [01:59<00:02, 51.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97%|███▉| 4.76G/4.89G [01:59<00:02, 61.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97%|███▉| 4.77G/4.89G [02:00<00:02, 50.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98%|███▉| 4.79G/4.89G [02:00<00:02, 47.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98%|███▉| 4.80G/4.89G [02:00<00:01, 49.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99%|███▉| 4.82G/4.89G [02:01<00:01, 60.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99%|███▉| 4.83G/4.89G [02:01<00:01, 45.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99%|███▉| 4.84G/4.89G [02:01<00:01, 48.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99%|███▉| 4.85G/4.89G [02:02<00:00, 40.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99%|███▉| 4.87G/4.89G [02:02<00:00, 35.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100%|███▉| 4.88G/4.89G [02:02<00:00, 37.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100%|███▉| 4.89G/4.89G [02:03<00:00, 37.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100%|████| 4.89G/4.89G [02:03<00:00, 39.7MB/s]\u001b[A\n",
            "Downloading shards:  50%|████████████            | 1/2 [02:03<02:03, 123.54s/it]\n",
            "model-00002-of-00002.safetensors:   0%|             | 0.00/1.07G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1%|    | 10.5M/1.07G [00:00<00:22, 47.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2%|    | 21.0M/1.07G [00:00<00:32, 32.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3%|    | 31.5M/1.07G [00:00<00:34, 30.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4%|▏   | 41.9M/1.07G [00:01<00:35, 29.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5%|▏   | 52.4M/1.07G [00:01<00:37, 27.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7%|▎   | 73.4M/1.07G [00:02<00:34, 29.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8%|▎   | 83.9M/1.07G [00:02<00:34, 28.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10%|▍    | 105M/1.07G [00:03<00:24, 38.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11%|▌    | 115M/1.07G [00:03<00:27, 35.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13%|▋    | 136M/1.07G [00:03<00:20, 44.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14%|▋    | 147M/1.07G [00:04<00:24, 37.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16%|▊    | 168M/1.07G [00:04<00:20, 45.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17%|▊    | 178M/1.07G [00:04<00:22, 39.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19%|▉    | 199M/1.07G [00:05<00:20, 42.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20%|▉    | 210M/1.07G [00:05<00:22, 38.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21%|█    | 231M/1.07G [00:06<00:19, 42.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22%|█    | 241M/1.07G [00:06<00:23, 35.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24%|█▏   | 262M/1.07G [00:07<00:20, 40.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25%|█▎   | 273M/1.07G [00:07<00:27, 28.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27%|█▎   | 294M/1.07G [00:08<00:23, 33.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28%|█▍   | 304M/1.07G [00:08<00:22, 33.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30%|█▌   | 325M/1.07G [00:08<00:18, 39.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31%|█▌   | 336M/1.07G [00:09<00:17, 42.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32%|█▌   | 346M/1.07G [00:09<00:17, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33%|█▋   | 357M/1.07G [00:09<00:19, 37.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35%|█▊   | 377M/1.07G [00:09<00:13, 51.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36%|█▊   | 388M/1.07G [00:10<00:16, 42.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38%|█▉   | 409M/1.07G [00:10<00:16, 40.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39%|█▉   | 419M/1.07G [00:11<00:19, 33.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41%|██   | 440M/1.07G [00:11<00:14, 44.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42%|██   | 451M/1.07G [00:11<00:13, 45.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43%|██▏  | 461M/1.07G [00:11<00:12, 50.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44%|██▏  | 472M/1.07G [00:12<00:11, 52.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45%|██▏  | 482M/1.07G [00:12<00:11, 51.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47%|██▎  | 503M/1.07G [00:12<00:12, 45.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48%|██▍  | 514M/1.07G [00:13<00:14, 38.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50%|██▍  | 535M/1.07G [00:13<00:12, 41.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51%|██▌  | 545M/1.07G [00:14<00:13, 38.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53%|██▋  | 566M/1.07G [00:14<00:11, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54%|██▋  | 577M/1.07G [00:14<00:13, 38.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55%|██▋  | 587M/1.07G [00:15<00:11, 41.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56%|██▊  | 598M/1.07G [00:15<00:13, 35.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57%|██▊  | 608M/1.07G [00:15<00:12, 36.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59%|██▉  | 629M/1.07G [00:16<00:10, 41.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60%|██▉  | 640M/1.07G [00:16<00:12, 35.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61%|███  | 650M/1.07G [00:16<00:10, 40.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62%|███  | 661M/1.07G [00:17<00:11, 36.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63%|███▏ | 682M/1.07G [00:17<00:10, 37.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64%|███▏ | 692M/1.07G [00:17<00:10, 36.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66%|███▎ | 713M/1.07G [00:18<00:07, 47.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67%|███▎ | 724M/1.07G [00:18<00:07, 46.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69%|███▍ | 744M/1.07G [00:18<00:05, 59.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70%|███▌ | 755M/1.07G [00:19<00:07, 42.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72%|███▌ | 776M/1.07G [00:19<00:07, 41.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73%|███▋ | 786M/1.07G [00:20<00:07, 38.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74%|███▋ | 797M/1.07G [00:20<00:06, 42.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75%|███▊ | 807M/1.07G [00:20<00:06, 40.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76%|███▊ | 818M/1.07G [00:20<00:07, 33.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78%|███▉ | 839M/1.07G [00:21<00:06, 38.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79%|███▉ | 849M/1.07G [00:21<00:06, 32.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81%|████ | 870M/1.07G [00:22<00:04, 44.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82%|████ | 881M/1.07G [00:22<00:04, 39.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84%|████▏| 902M/1.07G [00:23<00:04, 36.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85%|████▏| 912M/1.07G [00:23<00:05, 31.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87%|████▎| 933M/1.07G [00:24<00:04, 28.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89%|████▍| 954M/1.07G [00:24<00:03, 35.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90%|████▍| 965M/1.07G [00:25<00:02, 36.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92%|████▌| 986M/1.07G [00:25<00:01, 44.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93%|████▋| 996M/1.07G [00:25<00:01, 47.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95%|███▊| 1.02G/1.07G [00:25<00:01, 48.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96%|███▊| 1.03G/1.07G [00:26<00:01, 36.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98%|███▉| 1.05G/1.07G [00:26<00:00, 39.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99%|███▉| 1.06G/1.07G [00:27<00:00, 37.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100%|████| 1.07G/1.07G [00:27<00:00, 38.9MB/s]\u001b[A\n",
            "Downloading shards: 100%|█████████████████████████| 2/2 [02:31<00:00, 75.69s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4674: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.06s/it]\n",
            "generation_config.json: 100%|███████████████████| 116/116 [00:00<00:00, 531kB/s]\n",
            "2024-08-23:18:05:48,378 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-23:18:05:48,379 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,379 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-23:18:05:48,379 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,379 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-23:18:05:48,379 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,379 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-23:18:05:48,379 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,379 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-23:18:05:48,379 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,379 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-23:18:05:48,379 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,379 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-23:18:05:48,379 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,379 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-23:18:05:48,379 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,379 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-23:18:05:48,379 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,379 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-23:18:05:48,379 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,379 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-23:18:05:48,379 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,379 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-23:18:05:48,379 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,379 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-23:18:05:48,379 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,379 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-23:18:05:48,379 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,380 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-23:18:05:48,380 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,380 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-23:18:05:48,380 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,380 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-23:18:05:48,380 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,380 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-23:18:05:48,380 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,380 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-23:18:05:48,380 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,380 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-23:18:05:48,380 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,380 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-23:18:05:48,380 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,380 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-23:18:05:48,380 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,380 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-23:18:05:48,380 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,380 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-23:18:05:48,380 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,380 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-23:18:05:48,380 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,380 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-23:18:05:48,380 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,380 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-23:18:05:48,380 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,380 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-23:18:05:48,380 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,380 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-23:18:05:48,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-23:18:05:48,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-23:18:05:48,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-23:18:05:48,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-23:18:05:48,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-23:18:05:48,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-23:18:05:48,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-23:18:05:48,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-23:18:05:48,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-23:18:05:48,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-23:18:05:48,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-23:18:05:48,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-23:18:05:48,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-23:18:05:48,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-23:18:05:48,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-23:18:05:48,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-23:18:05:48,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-23:18:05:48,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-23:18:05:48,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-23:18:05:48,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-23:18:05:48,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-23:18:05:48,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-23:18:05:48,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-23:18:05:48,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-23:18:05:48,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-23:18:05:48,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-23:18:05:48,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-23:18:05:48,383 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,383 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-23:18:05:48,383 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,383 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-23:18:05:48,383 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,383 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-23:18:05:48,383 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:18:05:48,383 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-23:18:05:48,392 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 575.00it/s]\n",
            "2024-08-23:18:05:48,571 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 578.55it/s]\n",
            "2024-08-23:18:05:48,812 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 581.02it/s]\n",
            "2024-08-23:18:05:49,081 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 580.00it/s]\n",
            "2024-08-23:18:05:49,336 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 581.33it/s]\n",
            "2024-08-23:18:05:49,513 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 583.63it/s]\n",
            "2024-08-23:18:05:49,690 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 579.56it/s]\n",
            "2024-08-23:18:05:49,867 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 583.35it/s]\n",
            "2024-08-23:18:05:50,047 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 585.70it/s]\n",
            "2024-08-23:18:05:50,223 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 582.99it/s]\n",
            "2024-08-23:18:05:50,638 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 584.70it/s]\n",
            "2024-08-23:18:05:50,893 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 586.25it/s]\n",
            "2024-08-23:18:05:51,555 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 637.21it/s]\n",
            "2024-08-23:18:05:52,056 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 716.89it/s]\n",
            "2024-08-23:18:05:52,347 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 715.16it/s]\n",
            "2024-08-23:18:05:52,491 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 711.53it/s]\n",
            "2024-08-23:18:05:52,881 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 699.14it/s]\n",
            "2024-08-23:18:05:53,103 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 715.30it/s]\n",
            "2024-08-23:18:05:53,414 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 701.66it/s]\n",
            "2024-08-23:18:05:53,579 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 711.95it/s]\n",
            "2024-08-23:18:05:53,724 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 704.76it/s]\n",
            "2024-08-23:18:05:54,110 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 705.42it/s]\n",
            "2024-08-23:18:05:54,363 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 706.34it/s]\n",
            "2024-08-23:18:05:54,508 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 710.25it/s]\n",
            "2024-08-23:18:05:54,831 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 710.70it/s]\n",
            "2024-08-23:18:05:54,981 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 721.67it/s]\n",
            "2024-08-23:18:05:55,314 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 723.30it/s]\n",
            "2024-08-23:18:05:55,457 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 614.76it/s]\n",
            "2024-08-23:18:05:56,759 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 714.21it/s]\n",
            "2024-08-23:18:05:57,200 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 718.75it/s]\n",
            "2024-08-23:18:05:57,604 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 716.73it/s]\n",
            "2024-08-23:18:05:57,994 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 719.90it/s]\n",
            "2024-08-23:18:05:58,231 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 718.45it/s]\n",
            "2024-08-23:18:05:58,395 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 711.12it/s]\n",
            "2024-08-23:18:05:58,681 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 715.23it/s]\n",
            "2024-08-23:18:05:58,959 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 716.62it/s]\n",
            "2024-08-23:18:05:59,518 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 716.27it/s]\n",
            "2024-08-23:18:05:59,859 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 716.57it/s]\n",
            "2024-08-23:18:06:00,641 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 707.30it/s]\n",
            "2024-08-23:18:06:00,832 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 709.46it/s]\n",
            "2024-08-23:18:06:01,718 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 705.51it/s]\n",
            "2024-08-23:18:06:01,879 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 720.89it/s]\n",
            "2024-08-23:18:06:02,228 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 726.68it/s]\n",
            "2024-08-23:18:06:02,513 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 720.97it/s]\n",
            "2024-08-23:18:06:02,656 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 720.11it/s]\n",
            "2024-08-23:18:06:02,836 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 714.28it/s]\n",
            "2024-08-23:18:06:03,074 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 722.49it/s]\n",
            "2024-08-23:18:06:03,365 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 702.39it/s]\n",
            "2024-08-23:18:06:03,712 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 723.45it/s]\n",
            "2024-08-23:18:06:03,885 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 725.79it/s]\n",
            "2024-08-23:18:06:04,039 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 719.79it/s]\n",
            "2024-08-23:18:06:04,272 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 709.91it/s]\n",
            "2024-08-23:18:06:04,773 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 615.39it/s]\n",
            "2024-08-23:18:06:06,261 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 723.94it/s]\n",
            "2024-08-23:18:06:06,703 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 715.09it/s]\n",
            "2024-08-23:18:06:07,168 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 720.96it/s]\n",
            "2024-08-23:18:06:09,356 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 717.04it/s]\n",
            "2024-08-23:18:06:09,601 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 16398.36it/s]\n",
            "2024-08-23:18:06:11,129 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1424.47it/s]\n",
            "2024-08-23:18:06:12,009 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
            "Running loglikelihood requests: 100%|███| 174850/174850 [48:38<00:00, 59.91it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-23:18:56:47,323 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=kaitchup/Mistral-NeMo-Minitron-8B-Base-AutoRound-GPTQ-sym-4bit), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.4795|±  |0.0146|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.5094|±  |0.0146|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.1875|±  |0.0036|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.5378|±  |0.0040|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.4948|±  |0.0069|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.3333|±  |0.0422|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7333|±  |0.0345|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.7696|±  |0.0296|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.8312|±  |0.0244|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.7355|±  |0.0403|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.5648|±  |0.0479|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.5706|±  |0.0389|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.5405|±  |0.0268|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2536|±  |0.0146|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.5048|±  |0.0284|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.5710|±  |0.0275|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4576|±  |0.0127|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.6433|±  |0.0367|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.6015|±  |0.0086|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.5800|±  |0.0496|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.5774|±  |0.0304|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.5376|±  |0.0380|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.2700|±  |0.0446|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.6099|±  |0.0327|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.6311|±  |0.0478|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.7308|±  |0.0291|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.5600|±  |0.0499|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.6960|±  |0.0164|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.6536|±  |0.0272|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.3972|±  |0.0292|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.6507|±  |0.0290|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.4578|±  |0.0388|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.6253|±  |0.0085|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.3158|±  |0.0437|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.6364|±  |0.0343|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.7720|±  |0.0303|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.5256|±  |0.0253|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.5924|±  |0.0319|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.7468|±  |0.0186|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.6107|±  |0.0428|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.5507|±  |0.0201|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.5364|±  |0.0478|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.6571|±  |0.0304|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.7214|±  |0.0317|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.7800|±  |0.0416|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.4539|±  |0.0086|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.2800|±  |0.0451|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.4593|±  |0.0430|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.5724|±  |0.0403|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.5764|±  |0.0413|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4500|±  |0.0500|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.3900|±  |0.0490|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.3600|±  |0.0482|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.3333|±  |0.0469|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.5200|±  |0.0502|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.4936|±  |0.0327|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.4483|±  |0.0414|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.3730|±  |0.0249|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7032|±  |0.0260|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.4138|±  |0.0347|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.5600|±  |0.0499|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3000|±  |0.0279|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.3576|±  |0.0391|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.5231|±  |0.0341|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.3304|±  |0.0446|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.5378|±  |0.0040|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.4948|±  |0.0069|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.6015|±  |0.0086|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.6253|±  |0.0085|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.4539|±  |0.0086|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=kaitchup/Mistral-NeMo-Minitron-8B-Base-AutoRound-GPTQ-sym-4bit --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d43d8731-ce51-4f92-ae01-d59d29b7b381",
      "metadata": {
        "id": "d43d8731-ce51-4f92-ae01-d59d29b7b381",
        "outputId": "00c5f30a-d9ca-4166-8577-b71d23444b76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-24:18:47:15,965 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-24:18:47:16,057 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-24:18:47:28,545 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-24:18:47:28,547 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-24:18:47:28,547 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': './AutoRound/Mistral-NeMo-Minitron-8B-Base-AutoRound-GPTQ-asym-4bit/'}\n",
            "2024-08-24:18:47:28,783 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-24:18:47:28,784 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "2024-08-24:18:47:29,182 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "2024-08-24:18:47:30,003 WARNING  [qlinear_cuda.py:18] CUDA extension not installed.\n",
            "2024-08-24:18:47:30,003 WARNING  [qlinear_cuda_old.py:17] CUDA extension not installed.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4709: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at ./AutoRound/Mistral-NeMo-Minitron-8B-Base-AutoRound-GPTQ-asym-4bit/ were not used when initializing MistralForCausalLM: ['model.layers.0.mlp.down_proj.bias', 'model.layers.0.mlp.gate_proj.bias', 'model.layers.0.mlp.up_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.o_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.1.mlp.down_proj.bias', 'model.layers.1.mlp.gate_proj.bias', 'model.layers.1.mlp.up_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.o_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.10.mlp.down_proj.bias', 'model.layers.10.mlp.gate_proj.bias', 'model.layers.10.mlp.up_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.o_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.11.mlp.down_proj.bias', 'model.layers.11.mlp.gate_proj.bias', 'model.layers.11.mlp.up_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.o_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.12.mlp.down_proj.bias', 'model.layers.12.mlp.gate_proj.bias', 'model.layers.12.mlp.up_proj.bias', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.o_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.13.mlp.down_proj.bias', 'model.layers.13.mlp.gate_proj.bias', 'model.layers.13.mlp.up_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.o_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.14.mlp.down_proj.bias', 'model.layers.14.mlp.gate_proj.bias', 'model.layers.14.mlp.up_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.o_proj.bias', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.15.mlp.down_proj.bias', 'model.layers.15.mlp.gate_proj.bias', 'model.layers.15.mlp.up_proj.bias', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.o_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.16.mlp.down_proj.bias', 'model.layers.16.mlp.gate_proj.bias', 'model.layers.16.mlp.up_proj.bias', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.o_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.17.mlp.down_proj.bias', 'model.layers.17.mlp.gate_proj.bias', 'model.layers.17.mlp.up_proj.bias', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.o_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.18.mlp.down_proj.bias', 'model.layers.18.mlp.gate_proj.bias', 'model.layers.18.mlp.up_proj.bias', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.o_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.19.mlp.down_proj.bias', 'model.layers.19.mlp.gate_proj.bias', 'model.layers.19.mlp.up_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.o_proj.bias', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.2.mlp.down_proj.bias', 'model.layers.2.mlp.gate_proj.bias', 'model.layers.2.mlp.up_proj.bias', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.o_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.20.mlp.down_proj.bias', 'model.layers.20.mlp.gate_proj.bias', 'model.layers.20.mlp.up_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.o_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.21.mlp.down_proj.bias', 'model.layers.21.mlp.gate_proj.bias', 'model.layers.21.mlp.up_proj.bias', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.o_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.22.mlp.down_proj.bias', 'model.layers.22.mlp.gate_proj.bias', 'model.layers.22.mlp.up_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.o_proj.bias', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.23.mlp.down_proj.bias', 'model.layers.23.mlp.gate_proj.bias', 'model.layers.23.mlp.up_proj.bias', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.o_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.24.mlp.down_proj.bias', 'model.layers.24.mlp.gate_proj.bias', 'model.layers.24.mlp.up_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.o_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.25.mlp.down_proj.bias', 'model.layers.25.mlp.gate_proj.bias', 'model.layers.25.mlp.up_proj.bias', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.o_proj.bias', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.26.mlp.down_proj.bias', 'model.layers.26.mlp.gate_proj.bias', 'model.layers.26.mlp.up_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.o_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.27.mlp.down_proj.bias', 'model.layers.27.mlp.gate_proj.bias', 'model.layers.27.mlp.up_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.o_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.28.mlp.down_proj.bias', 'model.layers.28.mlp.gate_proj.bias', 'model.layers.28.mlp.up_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.o_proj.bias', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.29.mlp.down_proj.bias', 'model.layers.29.mlp.gate_proj.bias', 'model.layers.29.mlp.up_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.29.self_attn.o_proj.bias', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.3.mlp.down_proj.bias', 'model.layers.3.mlp.gate_proj.bias', 'model.layers.3.mlp.up_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.o_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.30.mlp.down_proj.bias', 'model.layers.30.mlp.gate_proj.bias', 'model.layers.30.mlp.up_proj.bias', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.o_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.31.mlp.down_proj.bias', 'model.layers.31.mlp.gate_proj.bias', 'model.layers.31.mlp.up_proj.bias', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.31.self_attn.o_proj.bias', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.32.mlp.down_proj.bias', 'model.layers.32.mlp.gate_proj.bias', 'model.layers.32.mlp.up_proj.bias', 'model.layers.32.self_attn.k_proj.bias', 'model.layers.32.self_attn.o_proj.bias', 'model.layers.32.self_attn.q_proj.bias', 'model.layers.32.self_attn.v_proj.bias', 'model.layers.33.mlp.down_proj.bias', 'model.layers.33.mlp.gate_proj.bias', 'model.layers.33.mlp.up_proj.bias', 'model.layers.33.self_attn.k_proj.bias', 'model.layers.33.self_attn.o_proj.bias', 'model.layers.33.self_attn.q_proj.bias', 'model.layers.33.self_attn.v_proj.bias', 'model.layers.34.mlp.down_proj.bias', 'model.layers.34.mlp.gate_proj.bias', 'model.layers.34.mlp.up_proj.bias', 'model.layers.34.self_attn.k_proj.bias', 'model.layers.34.self_attn.o_proj.bias', 'model.layers.34.self_attn.q_proj.bias', 'model.layers.34.self_attn.v_proj.bias', 'model.layers.35.mlp.down_proj.bias', 'model.layers.35.mlp.gate_proj.bias', 'model.layers.35.mlp.up_proj.bias', 'model.layers.35.self_attn.k_proj.bias', 'model.layers.35.self_attn.o_proj.bias', 'model.layers.35.self_attn.q_proj.bias', 'model.layers.35.self_attn.v_proj.bias', 'model.layers.36.mlp.down_proj.bias', 'model.layers.36.mlp.gate_proj.bias', 'model.layers.36.mlp.up_proj.bias', 'model.layers.36.self_attn.k_proj.bias', 'model.layers.36.self_attn.o_proj.bias', 'model.layers.36.self_attn.q_proj.bias', 'model.layers.36.self_attn.v_proj.bias', 'model.layers.37.mlp.down_proj.bias', 'model.layers.37.mlp.gate_proj.bias', 'model.layers.37.mlp.up_proj.bias', 'model.layers.37.self_attn.k_proj.bias', 'model.layers.37.self_attn.o_proj.bias', 'model.layers.37.self_attn.q_proj.bias', 'model.layers.37.self_attn.v_proj.bias', 'model.layers.38.mlp.down_proj.bias', 'model.layers.38.mlp.gate_proj.bias', 'model.layers.38.mlp.up_proj.bias', 'model.layers.38.self_attn.k_proj.bias', 'model.layers.38.self_attn.o_proj.bias', 'model.layers.38.self_attn.q_proj.bias', 'model.layers.38.self_attn.v_proj.bias', 'model.layers.39.mlp.down_proj.bias', 'model.layers.39.mlp.gate_proj.bias', 'model.layers.39.mlp.up_proj.bias', 'model.layers.39.self_attn.k_proj.bias', 'model.layers.39.self_attn.o_proj.bias', 'model.layers.39.self_attn.q_proj.bias', 'model.layers.39.self_attn.v_proj.bias', 'model.layers.4.mlp.down_proj.bias', 'model.layers.4.mlp.gate_proj.bias', 'model.layers.4.mlp.up_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.o_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.5.mlp.down_proj.bias', 'model.layers.5.mlp.gate_proj.bias', 'model.layers.5.mlp.up_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.o_proj.bias', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.6.mlp.down_proj.bias', 'model.layers.6.mlp.gate_proj.bias', 'model.layers.6.mlp.up_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.o_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.7.mlp.down_proj.bias', 'model.layers.7.mlp.gate_proj.bias', 'model.layers.7.mlp.up_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.o_proj.bias', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.8.mlp.down_proj.bias', 'model.layers.8.mlp.gate_proj.bias', 'model.layers.8.mlp.up_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.o_proj.bias', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.9.mlp.down_proj.bias', 'model.layers.9.mlp.gate_proj.bias', 'model.layers.9.mlp.up_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.o_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.v_proj.bias']\n",
            "- This IS expected if you are initializing MistralForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing MistralForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "2024-08-24:18:49:06,738 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-24:18:49:06,738 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,738 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-24:18:49:06,738 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,738 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-24:18:49:06,738 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,738 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-24:18:49:06,739 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,739 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-24:18:49:06,739 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,739 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-24:18:49:06,739 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,739 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-24:18:49:06,739 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,739 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-24:18:49:06,739 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,739 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-24:18:49:06,739 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,739 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-24:18:49:06,739 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,739 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-24:18:49:06,739 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,739 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-24:18:49:06,739 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,739 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-24:18:49:06,739 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,739 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-24:18:49:06,739 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,739 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-24:18:49:06,739 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,739 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-24:18:49:06,740 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,740 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-24:18:49:06,740 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,740 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-24:18:49:06,740 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,740 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-24:18:49:06,740 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,740 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-24:18:49:06,740 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,740 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-24:18:49:06,740 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,740 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-24:18:49:06,740 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,740 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-24:18:49:06,740 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,740 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-24:18:49:06,740 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,740 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-24:18:49:06,740 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,740 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-24:18:49:06,740 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,740 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-24:18:49:06,740 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,740 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-24:18:49:06,740 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,740 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-24:18:49:06,741 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,741 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-24:18:49:06,741 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,741 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-24:18:49:06,741 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,741 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-24:18:49:06,741 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,741 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-24:18:49:06,741 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,741 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-24:18:49:06,741 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,741 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-24:18:49:06,741 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,741 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-24:18:49:06,741 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,741 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-24:18:49:06,741 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,741 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-24:18:49:06,741 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,741 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-24:18:49:06,741 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,741 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-24:18:49:06,741 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,741 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-24:18:49:06,742 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,742 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-24:18:49:06,742 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,742 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-24:18:49:06,742 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,742 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-24:18:49:06,742 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,742 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-24:18:49:06,742 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,742 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-24:18:49:06,742 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,742 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-24:18:49:06,742 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,742 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-24:18:49:06,742 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,742 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-24:18:49:06,742 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,742 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-24:18:49:06,742 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,742 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-24:18:49:06,742 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,742 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-24:18:49:06,742 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,742 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-24:18:49:06,742 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,742 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-24:18:49:06,743 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,743 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-24:18:49:06,743 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,743 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-24:18:49:06,743 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,743 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-24:18:49:06,743 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,743 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-24:18:49:06,743 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,743 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-24:18:49:06,743 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:18:49:06,743 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-24:18:49:06,751 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 554.67it/s]\n",
            "2024-08-24:18:49:06,939 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 556.80it/s]\n",
            "2024-08-24:18:49:07,202 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 558.14it/s]\n",
            "2024-08-24:18:49:07,483 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 570.74it/s]\n",
            "2024-08-24:18:49:07,743 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 582.28it/s]\n",
            "2024-08-24:18:49:07,920 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 580.09it/s]\n",
            "2024-08-24:18:49:08,098 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 582.80it/s]\n",
            "2024-08-24:18:49:08,275 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 581.03it/s]\n",
            "2024-08-24:18:49:08,456 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 543.27it/s]\n",
            "2024-08-24:18:49:08,645 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 586.11it/s]\n",
            "2024-08-24:18:49:09,057 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 573.14it/s]\n",
            "2024-08-24:18:49:09,318 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 635.17it/s]\n",
            "2024-08-24:18:49:09,931 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 706.33it/s]\n",
            "2024-08-24:18:49:10,383 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 704.60it/s]\n",
            "2024-08-24:18:49:10,680 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 697.62it/s]\n",
            "2024-08-24:18:49:10,828 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 707.51it/s]\n",
            "2024-08-24:18:49:11,220 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 710.48it/s]\n",
            "2024-08-24:18:49:11,439 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 710.64it/s]\n",
            "2024-08-24:18:49:11,752 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 712.29it/s]\n",
            "2024-08-24:18:49:11,914 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 713.23it/s]\n",
            "2024-08-24:18:49:12,058 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 707.89it/s]\n",
            "2024-08-24:18:49:12,444 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 711.94it/s]\n",
            "2024-08-24:18:49:12,694 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 715.56it/s]\n",
            "2024-08-24:18:49:12,838 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 713.08it/s]\n",
            "2024-08-24:18:49:13,159 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 711.60it/s]\n",
            "2024-08-24:18:49:13,309 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 715.48it/s]\n",
            "2024-08-24:18:49:13,645 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 713.54it/s]\n",
            "2024-08-24:18:49:13,789 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 609.26it/s]\n",
            "2024-08-24:18:49:15,105 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 702.44it/s]\n",
            "2024-08-24:18:49:15,553 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 697.74it/s]\n",
            "2024-08-24:18:49:15,969 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 706.58it/s]\n",
            "2024-08-24:18:49:16,366 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 707.11it/s]\n",
            "2024-08-24:18:49:16,608 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 707.75it/s]\n",
            "2024-08-24:18:49:16,774 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 713.58it/s]\n",
            "2024-08-24:18:49:17,059 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 712.10it/s]\n",
            "2024-08-24:18:49:17,338 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 709.93it/s]\n",
            "2024-08-24:18:49:17,903 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 707.73it/s]\n",
            "2024-08-24:18:49:18,249 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 710.31it/s]\n",
            "2024-08-24:18:49:19,037 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 661.70it/s]\n",
            "2024-08-24:18:49:19,241 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 712.82it/s]\n",
            "2024-08-24:18:49:20,124 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 713.22it/s]\n",
            "2024-08-24:18:49:20,283 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 708.15it/s]\n",
            "2024-08-24:18:49:20,638 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 711.55it/s]\n",
            "2024-08-24:18:49:20,929 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 710.65it/s]\n",
            "2024-08-24:18:49:21,074 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 706.16it/s]\n",
            "2024-08-24:18:49:21,258 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 706.81it/s]\n",
            "2024-08-24:18:49:21,499 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 709.30it/s]\n",
            "2024-08-24:18:49:21,795 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 710.39it/s]\n",
            "2024-08-24:18:49:22,139 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 714.87it/s]\n",
            "2024-08-24:18:49:22,313 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 713.29it/s]\n",
            "2024-08-24:18:49:22,469 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 713.05it/s]\n",
            "2024-08-24:18:49:22,704 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 713.92it/s]\n",
            "2024-08-24:18:49:23,203 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 609.20it/s]\n",
            "2024-08-24:18:49:24,707 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 715.41it/s]\n",
            "2024-08-24:18:49:25,154 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 707.66it/s]\n",
            "2024-08-24:18:49:25,624 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 710.50it/s]\n",
            "2024-08-24:18:49:27,845 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 713.00it/s]\n",
            "2024-08-24:18:49:28,092 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 14130.79it/s]\n",
            "2024-08-24:18:49:29,766 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1404.33it/s]\n",
            "2024-08-24:18:49:30,660 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n",
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
            "Running loglikelihood requests: 100%|███| 174850/174850 [48:28<00:00, 60.12it/s]\n",
            "2024-08-24:19:39:53,281 WARNING  [huggingface.py:1427] Failed to get model SHA for ./AutoRound/Mistral-NeMo-Minitron-8B-Base-AutoRound-GPTQ-asym-4bit/ at revision main. Error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './AutoRound/Mistral-NeMo-Minitron-8B-Base-AutoRound-GPTQ-asym-4bit/'. Use `repo_type` argument if needed.\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-24:19:39:54,462 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=./AutoRound/Mistral-NeMo-Minitron-8B-Base-AutoRound-GPTQ-asym-4bit/), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.5350|±  |0.0146|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.5742|±  |0.0144|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.3158|±  |0.0042|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.6470|±  |0.0038|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5868|±  |0.0065|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.4048|±  |0.0439|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7818|±  |0.0323|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.8088|±  |0.0276|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.8354|±  |0.0241|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.7851|±  |0.0375|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.7778|±  |0.0402|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7791|±  |0.0326|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.7283|±  |0.0239|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2436|±  |0.0144|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.7428|±  |0.0248|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.7531|±  |0.0240|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.5359|±  |0.0127|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.8480|±  |0.0275|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.7187|±  |0.0077|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.6700|±  |0.0473|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.7057|±  |0.0280|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.6301|±  |0.0368|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.3300|±  |0.0473|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.7354|±  |0.0296|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.7864|±  |0.0406|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8932|±  |0.0202|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.7500|±  |0.0435|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.8404|±  |0.0131|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.7418|±  |0.0251|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.5071|±  |0.0298|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.7132|±  |0.0275|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5181|±  |0.0389|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.7543|±  |0.0076|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.4386|±  |0.0467|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.8081|±  |0.0281|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8912|±  |0.0225|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.6692|±  |0.0239|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.7143|±  |0.0293|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.8532|±  |0.0152|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.7557|±  |0.0377|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.6863|±  |0.0188|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6545|±  |0.0455|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.7796|±  |0.0265|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.8458|±  |0.0255|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.9100|±  |0.0288|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5614|±  |0.0085|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3300|±  |0.0473|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.6444|±  |0.0414|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.7697|±  |0.0343|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.7569|±  |0.0359|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.5000|±  |0.0503|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.4200|±  |0.0496|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.4100|±  |0.0494|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.4314|±  |0.0493|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.7500|±  |0.0435|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.6255|±  |0.0316|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.6069|±  |0.0407|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4524|±  |0.0256|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.8097|±  |0.0223|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.5320|±  |0.0351|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.7000|±  |0.0461|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3704|±  |0.0294|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.4503|±  |0.0406|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.5833|±  |0.0336|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.3839|±  |0.0462|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.6470|±  |0.0038|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5868|±  |0.0065|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.7187|±  |0.0077|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.7543|±  |0.0076|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5614|±  |0.0085|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=./AutoRound/Mistral-NeMo-Minitron-8B-Base-AutoRound-GPTQ-asym-4bit/ --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###mistralai/Mistral-Nemo-Base-2407"
      ],
      "metadata": {
        "id": "RJWR4H64Fhpn"
      },
      "id": "RJWR4H64Fhpn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c38033c-9619-4031-9551-3ec2c43ecd51",
      "metadata": {
        "id": "0c38033c-9619-4031-9551-3ec2c43ecd51",
        "outputId": "5f69028e-089c-426a-e7a5-9e4fca9069d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 702.84it/s]\n",
            "2024-08-23:17:36:57,910 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 715.55it/s]\n",
            "2024-08-23:17:36:58,693 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 717.06it/s]\n",
            "2024-08-23:17:36:58,882 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 715.79it/s]\n",
            "2024-08-23:17:36:59,761 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 715.22it/s]\n",
            "2024-08-23:17:36:59,919 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 714.00it/s]\n",
            "2024-08-23:17:37:00,272 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 711.80it/s]\n",
            "2024-08-23:17:37:00,563 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 711.04it/s]\n",
            "2024-08-23:17:37:00,708 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 710.28it/s]\n",
            "2024-08-23:17:37:00,891 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 714.83it/s]\n",
            "2024-08-23:17:37:01,129 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 710.96it/s]\n",
            "2024-08-23:17:37:01,424 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 707.00it/s]\n",
            "2024-08-23:17:37:01,770 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 709.22it/s]\n",
            "2024-08-23:17:37:01,945 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 706.42it/s]\n",
            "2024-08-23:17:37:02,103 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 717.74it/s]\n",
            "2024-08-23:17:37:02,337 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 682.69it/s]\n",
            "2024-08-23:17:37:02,857 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 589.86it/s]\n",
            "2024-08-23:17:37:04,409 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 580.06it/s]\n",
            "2024-08-23:17:37:04,958 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 585.63it/s]\n",
            "2024-08-23:17:37:05,527 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 687.91it/s]\n",
            "2024-08-23:17:37:07,830 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 715.66it/s]\n",
            "2024-08-23:17:37:08,076 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 14548.73it/s]\n",
            "2024-08-23:17:37:09,790 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1400.51it/s]\n",
            "2024-08-23:17:37:10,687 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
            "Running loglikelihood requests: 100%|██| 174850/174850 [23:03<00:00, 126.38it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-23:18:02:13,772 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=mistralai/Mistral-Nemo-Base-2407,dtype=float16), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.5572|±  |0.0145|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.5802|±  |0.0144|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.3248|±  |0.0043|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.6459|±  |0.0038|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5830|±  |0.0065|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.4286|±  |0.0443|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7939|±  |0.0316|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.8235|±  |0.0268|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.8059|±  |0.0257|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.8017|±  |0.0364|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.8148|±  |0.0376|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7423|±  |0.0344|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.7370|±  |0.0237|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2425|±  |0.0143|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.7556|±  |0.0244|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.7685|±  |0.0235|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.5156|±  |0.0128|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.8538|±  |0.0271|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.7287|±  |0.0077|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.5900|±  |0.0494|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.7170|±  |0.0277|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.6474|±  |0.0364|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.4300|±  |0.0498|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.7265|±  |0.0299|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.8058|±  |0.0392|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8718|±  |0.0219|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.7600|±  |0.0429|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.8404|±  |0.0131|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.7582|±  |0.0245|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.5355|±  |0.0298|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.7647|±  |0.0258|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5181|±  |0.0389|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.7566|±  |0.0076|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.4825|±  |0.0470|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.8030|±  |0.0283|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8705|±  |0.0242|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.6538|±  |0.0241|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.7185|±  |0.0292|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.8367|±  |0.0158|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.8092|±  |0.0345|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.7108|±  |0.0183|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.7091|±  |0.0435|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.7224|±  |0.0287|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.8756|±  |0.0233|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.9200|±  |0.0273|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5503|±  |0.0085|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3800|±  |0.0488|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.6741|±  |0.0405|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.7434|±  |0.0355|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.7431|±  |0.0365|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4200|±  |0.0496|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.5200|±  |0.0502|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.4200|±  |0.0496|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.4118|±  |0.0490|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.7700|±  |0.0423|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5830|±  |0.0322|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.6138|±  |0.0406|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4365|±  |0.0255|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7742|±  |0.0238|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.5320|±  |0.0351|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.7000|±  |0.0461|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3407|±  |0.0289|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.3974|±  |0.0400|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.5648|±  |0.0338|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.4286|±  |0.0470|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.6459|±  |0.0038|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5830|±  |0.0065|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.7287|±  |0.0077|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.7566|±  |0.0076|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5503|±  |0.0085|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=mistralai/Mistral-Nemo-Base-2407,dtype=float16 --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84e3ee51-8e11-4070-90f1-2c65fe1be0a2",
      "metadata": {
        "id": "84e3ee51-8e11-4070-90f1-2c65fe1be0a2",
        "outputId": "138b2c50-d785-454f-89df-1aa195f50e0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-23:19:47:15,078 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-23:19:47:15,164 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-23:19:47:28,019 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-23:19:47:28,022 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-23:19:47:28,022 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'mistralai/Mistral-Nemo-Base-2407', 'load_in_8bit': True}\n",
            "2024-08-23:19:47:28,264 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-23:19:47:28,264 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "2024-08-23:19:47:28,707 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:37<00:00,  7.42s/it]\n",
            "2024-08-23:19:48:07,137 WARNING  [big_modeling.py:451] You shouldn't move a model that is dispatched using accelerate hooks.\n",
            "2024-08-23:19:48:35,154 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-23:19:48:35,154 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,154 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-23:19:48:35,154 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,154 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-23:19:48:35,154 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,154 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-23:19:48:35,154 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,154 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-23:19:48:35,154 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,154 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-23:19:48:35,154 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,154 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-23:19:48:35,154 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,154 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-23:19:48:35,155 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,155 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-23:19:48:35,155 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,155 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-23:19:48:35,155 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,155 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-23:19:48:35,155 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,155 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-23:19:48:35,155 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,155 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-23:19:48:35,155 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,155 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-23:19:48:35,155 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,155 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-23:19:48:35,155 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,155 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-23:19:48:35,155 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,155 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-23:19:48:35,155 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,155 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-23:19:48:35,155 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,155 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-23:19:48:35,155 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,155 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-23:19:48:35,155 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,156 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-23:19:48:35,156 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,156 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-23:19:48:35,156 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,156 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-23:19:48:35,156 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,156 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-23:19:48:35,156 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,156 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-23:19:48:35,156 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,156 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-23:19:48:35,156 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,156 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-23:19:48:35,156 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,156 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-23:19:48:35,156 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,156 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-23:19:48:35,156 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,156 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-23:19:48:35,156 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,156 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-23:19:48:35,156 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,156 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-23:19:48:35,156 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,156 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-23:19:48:35,157 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,157 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-23:19:48:35,157 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,157 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-23:19:48:35,157 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,157 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-23:19:48:35,157 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,157 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-23:19:48:35,157 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,157 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-23:19:48:35,157 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,157 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-23:19:48:35,157 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,157 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-23:19:48:35,157 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,157 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-23:19:48:35,157 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,157 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-23:19:48:35,157 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,157 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-23:19:48:35,157 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,157 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-23:19:48:35,157 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,157 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-23:19:48:35,157 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,157 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-23:19:48:35,158 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,158 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-23:19:48:35,158 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,158 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-23:19:48:35,158 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,158 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-23:19:48:35,158 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,158 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-23:19:48:35,158 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,158 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-23:19:48:35,158 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,158 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-23:19:48:35,158 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,158 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-23:19:48:35,158 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,158 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-23:19:48:35,158 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,158 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-23:19:48:35,158 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,158 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-23:19:48:35,158 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,158 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-23:19:48:35,158 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,158 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-23:19:48:35,158 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,159 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-23:19:48:35,159 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-23:19:48:35,159 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-23:19:48:35,167 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 570.42it/s]\n",
            "2024-08-23:19:48:35,348 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 552.22it/s]\n",
            "2024-08-23:19:48:35,599 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 555.49it/s]\n",
            "2024-08-23:19:48:35,880 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 578.10it/s]\n",
            "2024-08-23:19:48:36,137 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 581.29it/s]\n",
            "2024-08-23:19:48:36,314 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 578.58it/s]\n",
            "2024-08-23:19:48:36,492 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 580.13it/s]\n",
            "2024-08-23:19:48:36,669 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 583.17it/s]\n",
            "2024-08-23:19:48:36,850 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 579.85it/s]\n",
            "2024-08-23:19:48:37,027 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 582.07it/s]\n",
            "2024-08-23:19:48:37,442 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 579.68it/s]\n",
            "2024-08-23:19:48:37,700 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 579.80it/s]\n",
            "2024-08-23:19:48:38,369 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 689.35it/s]\n",
            "2024-08-23:19:48:38,834 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 708.62it/s]\n",
            "2024-08-23:19:48:39,129 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 706.34it/s]\n",
            "2024-08-23:19:48:39,274 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 714.46it/s]\n",
            "2024-08-23:19:48:39,663 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 709.92it/s]\n",
            "2024-08-23:19:48:39,882 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 714.22it/s]\n",
            "2024-08-23:19:48:40,193 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 713.33it/s]\n",
            "2024-08-23:19:48:40,355 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 714.90it/s]\n",
            "2024-08-23:19:48:40,499 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 709.98it/s]\n",
            "2024-08-23:19:48:40,882 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 710.85it/s]\n",
            "2024-08-23:19:48:41,133 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 705.88it/s]\n",
            "2024-08-23:19:48:41,279 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 710.36it/s]\n",
            "2024-08-23:19:48:41,602 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 709.05it/s]\n",
            "2024-08-23:19:48:41,751 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 711.07it/s]\n",
            "2024-08-23:19:48:42,089 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 706.98it/s]\n",
            "2024-08-23:19:48:42,235 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 699.27it/s]\n",
            "2024-08-23:19:48:43,537 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 707.22it/s]\n",
            "2024-08-23:19:48:43,982 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 708.58it/s]\n",
            "2024-08-23:19:48:44,391 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 710.69it/s]\n",
            "2024-08-23:19:48:44,785 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 705.90it/s]\n",
            "2024-08-23:19:48:45,026 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 709.20it/s]\n",
            "2024-08-23:19:48:45,192 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 705.07it/s]\n",
            "2024-08-23:19:48:45,481 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 702.58it/s]\n",
            "2024-08-23:19:48:45,764 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 707.03it/s]\n",
            "2024-08-23:19:48:46,330 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 705.40it/s]\n",
            "2024-08-23:19:48:46,677 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 707.80it/s]\n",
            "2024-08-23:19:48:47,468 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 709.20it/s]\n",
            "2024-08-23:19:48:47,659 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 706.90it/s]\n",
            "2024-08-23:19:48:48,548 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 709.56it/s]\n",
            "2024-08-23:19:48:48,707 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 709.09it/s]\n",
            "2024-08-23:19:48:49,063 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 705.74it/s]\n",
            "2024-08-23:19:48:49,356 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 701.34it/s]\n",
            "2024-08-23:19:48:49,503 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 706.84it/s]\n",
            "2024-08-23:19:48:49,686 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 699.61it/s]\n",
            "2024-08-23:19:48:49,929 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 708.97it/s]\n",
            "2024-08-23:19:48:50,226 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 708.67it/s]\n",
            "2024-08-23:19:48:50,570 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 711.25it/s]\n",
            "2024-08-23:19:48:50,745 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 711.95it/s]\n",
            "2024-08-23:19:48:50,902 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 714.04it/s]\n",
            "2024-08-23:19:48:51,136 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 715.56it/s]\n",
            "2024-08-23:19:48:51,634 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 614.76it/s]\n",
            "2024-08-23:19:48:53,124 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 703.90it/s]\n",
            "2024-08-23:19:48:53,579 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 706.61it/s]\n",
            "2024-08-23:19:48:54,050 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 706.02it/s]\n",
            "2024-08-23:19:48:56,282 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 708.58it/s]\n",
            "2024-08-23:19:48:56,531 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 15595.97it/s]\n",
            "2024-08-23:19:48:58,106 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1394.93it/s]\n",
            "2024-08-23:19:48:59,003 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "Running loglikelihood requests: 100%|███| 174850/174850 [45:17<00:00, 64.33it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-23:20:36:13,189 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=mistralai/Mistral-Nemo-Base-2407,load_in_8bit=True), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.5520|±  |0.0145|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.5768|±  |0.0144|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.3210|±  |0.0043|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.6394|±  |0.0038|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5781|±  |0.0065|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.4127|±  |0.0440|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7879|±  |0.0319|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.8186|±  |0.0270|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.8270|±  |0.0246|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.7934|±  |0.0370|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.8056|±  |0.0383|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7669|±  |0.0332|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.7283|±  |0.0239|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2425|±  |0.0143|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.7363|±  |0.0250|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.7685|±  |0.0235|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.5046|±  |0.0128|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.8538|±  |0.0271|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.7226|±  |0.0077|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.6100|±  |0.0490|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.7170|±  |0.0277|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.6243|±  |0.0369|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.4100|±  |0.0494|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.7085|±  |0.0305|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.7961|±  |0.0399|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8718|±  |0.0219|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.7600|±  |0.0429|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.8301|±  |0.0134|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.7516|±  |0.0247|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.5284|±  |0.0298|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.7684|±  |0.0256|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5241|±  |0.0389|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.7465|±  |0.0076|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.4474|±  |0.0468|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.8081|±  |0.0281|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8756|±  |0.0238|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.6282|±  |0.0245|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.7185|±  |0.0292|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.8349|±  |0.0159|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.7863|±  |0.0360|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.6928|±  |0.0187|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6818|±  |0.0446|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.7347|±  |0.0283|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.8557|±  |0.0248|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.9200|±  |0.0273|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5442|±  |0.0085|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3900|±  |0.0490|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.6963|±  |0.0397|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.7303|±  |0.0361|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.7361|±  |0.0369|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4600|±  |0.0501|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.5300|±  |0.0502|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.4200|±  |0.0496|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.3824|±  |0.0484|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.7800|±  |0.0416|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5532|±  |0.0325|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.5862|±  |0.0410|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4339|±  |0.0255|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7903|±  |0.0232|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.5172|±  |0.0352|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.6800|±  |0.0469|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3296|±  |0.0287|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.3775|±  |0.0396|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.5370|±  |0.0340|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.4375|±  |0.0471|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.6394|±  |0.0038|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5781|±  |0.0065|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.7226|±  |0.0077|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.7465|±  |0.0076|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5442|±  |0.0085|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=mistralai/Mistral-Nemo-Base-2407,load_in_8bit=True --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35106ad6-bfd9-453e-9fab-74527ff3e9c3",
      "metadata": {
        "id": "35106ad6-bfd9-453e-9fab-74527ff3e9c3",
        "outputId": "ebea20ea-630b-42b7-faa9-81c53bed3611"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-24:09:37:38,572 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-24:09:37:38,676 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-24:09:37:51,983 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-24:09:37:51,985 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-24:09:37:51,985 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'mistralai/Mistral-Nemo-Base-2407', 'load_in_4bit': True}\n",
            "2024-08-24:09:37:52,212 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-24:09:37:52,212 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "config.json: 100%|█████████████████████████████| 623/623 [00:00<00:00, 4.12MB/s]\n",
            "tokenizer_config.json: 100%|█████████████████| 177k/177k [00:00<00:00, 14.0MB/s]\n",
            "tokenizer.json: 100%|██████████████████████| 9.26M/9.26M [00:00<00:00, 33.6MB/s]\n",
            "special_tokens_map.json: 100%|█████████████████| 414/414 [00:00<00:00, 1.81MB/s]\n",
            "2024-08-24:09:37:53,321 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "model.safetensors.index.json: 100%|████████| 29.9k/29.9k [00:00<00:00, 67.2MB/s]\n",
            "Downloading shards:   0%|                                 | 0/5 [00:00<?, ?it/s]\n",
            "model-00001-of-00005.safetensors:   0%|             | 0.00/4.87G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:   2%|     | 73.4M/4.87G [00:00<00:06, 697MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:   3%|▏     | 157M/4.87G [00:00<00:06, 738MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:   5%|▎     | 241M/4.87G [00:00<00:06, 750MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:   7%|▍     | 325M/4.87G [00:00<00:06, 750MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:   8%|▌     | 409M/4.87G [00:00<00:05, 757MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  10%|▌     | 493M/4.87G [00:00<00:05, 760MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  12%|▋     | 577M/4.87G [00:00<00:05, 762MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  14%|▊     | 661M/4.87G [00:00<00:05, 701MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  15%|▉     | 744M/4.87G [00:01<00:05, 721MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  17%|█     | 828M/4.87G [00:01<00:05, 737MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  19%|█     | 912M/4.87G [00:01<00:05, 747MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  20%|█▏    | 996M/4.87G [00:01<00:05, 755MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  22%|█    | 1.08G/4.87G [00:01<00:04, 761MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  24%|█▏   | 1.16G/4.87G [00:01<00:04, 763MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  26%|█▎   | 1.25G/4.87G [00:01<00:04, 766MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  27%|█▎   | 1.33G/4.87G [00:01<00:04, 757MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  29%|█▍   | 1.42G/4.87G [00:01<00:04, 756MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  31%|█▌   | 1.50G/4.87G [00:01<00:04, 761MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  33%|█▋   | 1.58G/4.87G [00:02<00:04, 766MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  34%|█▋   | 1.67G/4.87G [00:02<00:04, 769MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  36%|█▊   | 1.75G/4.87G [00:02<00:04, 760MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  38%|█▉   | 1.84G/4.87G [00:02<00:03, 765MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  39%|█▉   | 1.92G/4.87G [00:02<00:04, 736MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  41%|██   | 2.00G/4.87G [00:02<00:03, 720MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  43%|██▏  | 2.08G/4.87G [00:02<00:03, 706MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  44%|██▏  | 2.15G/4.87G [00:02<00:03, 693MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  46%|██▎  | 2.22G/4.87G [00:03<00:03, 690MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  47%|██▎  | 2.31G/4.87G [00:03<00:03, 714MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  49%|██▍  | 2.39G/4.87G [00:03<00:03, 733MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  51%|██▌  | 2.47G/4.87G [00:03<00:03, 746MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  53%|██▋  | 2.56G/4.87G [00:03<00:03, 755MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  54%|██▋  | 2.64G/4.87G [00:03<00:02, 758MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  56%|██▊  | 2.73G/4.87G [00:03<00:02, 760MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  58%|██▉  | 2.81G/4.87G [00:03<00:02, 763MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  59%|██▉  | 2.89G/4.87G [00:03<00:02, 765MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  61%|███  | 2.98G/4.87G [00:03<00:02, 766MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  63%|███▏ | 3.06G/4.87G [00:04<00:02, 767MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  65%|███▏ | 3.15G/4.87G [00:04<00:02, 768MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  66%|███▎ | 3.23G/4.87G [00:04<00:02, 768MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  68%|███▍ | 3.31G/4.87G [00:04<00:02, 768MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  70%|███▍ | 3.40G/4.87G [00:04<00:01, 774MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  72%|███▌ | 3.49G/4.87G [00:04<00:01, 809MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  73%|███▋ | 3.58G/4.87G [00:04<00:01, 771MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  75%|███▊ | 3.66G/4.87G [00:04<00:01, 743MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  77%|███▊ | 3.74G/4.87G [00:04<00:01, 749MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  79%|███▉ | 3.83G/4.87G [00:05<00:01, 754MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  80%|████ | 3.91G/4.87G [00:05<00:01, 757MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  82%|████ | 4.00G/4.87G [00:05<00:01, 743MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  84%|████▏| 4.08G/4.87G [00:05<00:01, 749MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  86%|████▎| 4.16G/4.87G [00:05<00:00, 753MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  87%|████▎| 4.25G/4.87G [00:05<00:00, 752MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  89%|████▍| 4.33G/4.87G [00:05<00:00, 755MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  91%|████▌| 4.41G/4.87G [00:05<00:00, 743MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  92%|████▌| 4.50G/4.87G [00:06<00:00, 744MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  94%|████▋| 4.58G/4.87G [00:06<00:00, 762MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  96%|████▊| 4.67G/4.87G [00:06<00:00, 776MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors:  98%|████▉| 4.75G/4.87G [00:06<00:00, 759MB/s]\u001b[A\n",
            "model-00001-of-00005.safetensors: 100%|█████| 4.87G/4.87G [00:06<00:00, 751MB/s]\u001b[A\n",
            "Downloading shards:  20%|█████                    | 1/5 [00:06<00:26,  6.62s/it]\n",
            "model-00002-of-00005.safetensors:   0%|             | 0.00/4.91G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:   2%|     | 83.9M/4.91G [00:00<00:06, 745MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:   3%|▏     | 168M/4.91G [00:00<00:06, 755MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:   5%|▎     | 252M/4.91G [00:00<00:07, 627MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:   7%|▍     | 325M/4.91G [00:00<00:07, 626MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:   8%|▍     | 409M/4.91G [00:00<00:06, 675MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  10%|▌     | 493M/4.91G [00:00<00:06, 707MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  12%|▋     | 577M/4.91G [00:00<00:05, 726MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  13%|▊     | 661M/4.91G [00:00<00:05, 742MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  15%|▉     | 744M/4.91G [00:01<00:05, 752MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  17%|█     | 828M/4.91G [00:01<00:05, 759MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  19%|█     | 912M/4.91G [00:01<00:05, 765MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  20%|█▏    | 996M/4.91G [00:01<00:05, 767MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  22%|█    | 1.08G/4.91G [00:01<00:05, 749MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  24%|█▏   | 1.16G/4.91G [00:01<00:04, 761MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  25%|█▎   | 1.25G/4.91G [00:01<00:04, 739MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  27%|█▎   | 1.33G/4.91G [00:01<00:04, 744MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  29%|█▍   | 1.42G/4.91G [00:01<00:04, 745MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  31%|█▌   | 1.50G/4.91G [00:02<00:04, 723MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  32%|█▌   | 1.58G/4.91G [00:02<00:04, 734MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  34%|█▋   | 1.67G/4.91G [00:02<00:04, 682MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  35%|█▊   | 1.74G/4.91G [00:02<00:04, 672MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  37%|█▊   | 1.82G/4.91G [00:02<00:04, 699MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  39%|█▉   | 1.91G/4.91G [00:02<00:04, 719MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  41%|██   | 1.99G/4.91G [00:02<00:03, 730MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  42%|██   | 2.08G/4.91G [00:02<00:03, 740MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  44%|██▏  | 2.16G/4.91G [00:02<00:03, 747MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  46%|██▎  | 2.24G/4.91G [00:03<00:03, 736MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  47%|██▎  | 2.33G/4.91G [00:03<00:03, 759MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  49%|██▍  | 2.41G/4.91G [00:03<00:03, 746MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  51%|██▌  | 2.50G/4.91G [00:03<00:03, 751MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  53%|██▋  | 2.58G/4.91G [00:03<00:03, 754MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  54%|██▋  | 2.66G/4.91G [00:03<00:02, 757MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  56%|██▊  | 2.75G/4.91G [00:03<00:02, 758MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  58%|██▉  | 2.83G/4.91G [00:03<00:02, 759MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  59%|██▉  | 2.92G/4.91G [00:03<00:02, 759MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  61%|███  | 3.00G/4.91G [00:04<00:02, 757MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  63%|███▏ | 3.08G/4.91G [00:04<00:02, 738MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  65%|███▏ | 3.17G/4.91G [00:04<00:02, 716MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  66%|███▎ | 3.24G/4.91G [00:04<00:02, 666MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  68%|███▍ | 3.31G/4.91G [00:04<00:02, 631MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  69%|███▍ | 3.39G/4.91G [00:04<00:02, 608MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  70%|███▌ | 3.45G/4.91G [00:04<00:02, 595MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  72%|███▌ | 3.51G/4.91G [00:04<00:02, 583MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  73%|███▋ | 3.58G/4.91G [00:05<00:02, 575MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  74%|███▋ | 3.64G/4.91G [00:05<00:02, 570MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  75%|███▊ | 3.70G/4.91G [00:05<00:02, 567MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  77%|███▊ | 3.76G/4.91G [00:05<00:01, 576MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  78%|███▉ | 3.84G/4.91G [00:05<00:01, 587MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  80%|███▉ | 3.91G/4.91G [00:05<00:01, 622MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  81%|████ | 3.97G/4.91G [00:05<00:01, 619MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  82%|████ | 4.04G/4.91G [00:05<00:01, 619MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  84%|████▏| 4.12G/4.91G [00:05<00:01, 663MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  86%|████▎| 4.20G/4.91G [00:06<00:00, 709MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  87%|████▎| 4.29G/4.91G [00:06<00:00, 743MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  89%|████▍| 4.37G/4.91G [00:06<00:00, 707MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  91%|████▌| 4.46G/4.91G [00:06<00:00, 723MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  93%|████▋| 4.54G/4.91G [00:06<00:00, 732MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  94%|████▋| 4.62G/4.91G [00:06<00:00, 473MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  96%|████▊| 4.71G/4.91G [00:06<00:00, 534MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors:  98%|████▉| 4.79G/4.91G [00:07<00:00, 590MB/s]\u001b[A\n",
            "model-00002-of-00005.safetensors: 100%|█████| 4.91G/4.91G [00:07<00:00, 684MB/s]\u001b[A\n",
            "Downloading shards:  40%|██████████               | 2/5 [00:13<00:21,  7.01s/it]\n",
            "model-00003-of-00005.safetensors:   0%|             | 0.00/4.91G [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:   2%|     | 83.9M/4.91G [00:00<00:06, 763MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:   3%|▏     | 168M/4.91G [00:00<00:06, 778MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:   5%|▎     | 252M/4.91G [00:00<00:05, 783MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:   7%|▍     | 336M/4.91G [00:00<00:05, 782MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:   9%|▌     | 419M/4.91G [00:00<00:05, 784MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  10%|▌     | 503M/4.91G [00:00<00:05, 786MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  12%|▋     | 587M/4.91G [00:00<00:05, 788MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  14%|▊     | 671M/4.91G [00:00<00:05, 739MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  15%|▉     | 755M/4.91G [00:00<00:05, 752MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  17%|█     | 839M/4.91G [00:01<00:05, 763MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  19%|█▏    | 923M/4.91G [00:01<00:05, 767MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  21%|█    | 1.01G/4.91G [00:01<00:05, 772MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  22%|█    | 1.09G/4.91G [00:01<00:04, 777MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  24%|█▏   | 1.17G/4.91G [00:01<00:04, 781MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  26%|█▎   | 1.26G/4.91G [00:01<00:04, 782MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  27%|█▎   | 1.34G/4.91G [00:01<00:04, 782MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  29%|█▍   | 1.44G/4.91G [00:01<00:04, 814MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  31%|█▌   | 1.52G/4.91G [00:01<00:04, 798MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  33%|█▋   | 1.60G/4.91G [00:02<00:04, 781MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  34%|█▋   | 1.69G/4.91G [00:02<00:04, 786MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  36%|█▊   | 1.77G/4.91G [00:02<00:03, 793MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  38%|█▉   | 1.86G/4.91G [00:02<00:03, 793MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  40%|█▉   | 1.94G/4.91G [00:02<00:03, 789MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  41%|██   | 2.02G/4.91G [00:02<00:04, 710MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  43%|██▏  | 2.12G/4.91G [00:02<00:03, 750MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  45%|██▎  | 2.21G/4.91G [00:02<00:03, 795MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  47%|██▎  | 2.30G/4.91G [00:02<00:03, 776MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  49%|██▍  | 2.38G/4.91G [00:03<00:03, 788MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  50%|██▌  | 2.47G/4.91G [00:03<00:02, 823MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  52%|██▌  | 2.56G/4.91G [00:03<00:02, 798MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  54%|██▋  | 2.64G/4.91G [00:03<00:02, 763MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  56%|██▊  | 2.73G/4.91G [00:03<00:03, 695MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  57%|██▊  | 2.80G/4.91G [00:03<00:03, 651MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  59%|██▉  | 2.87G/4.91G [00:03<00:03, 622MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  60%|███  | 2.95G/4.91G [00:03<00:03, 603MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  61%|███  | 3.01G/4.91G [00:04<00:03, 592MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  63%|███▏ | 3.08G/4.91G [00:04<00:02, 616MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  65%|███▏ | 3.17G/4.91G [00:04<00:02, 650MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  66%|███▎ | 3.25G/4.91G [00:04<00:02, 690MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  68%|███▍ | 3.33G/4.91G [00:04<00:02, 719MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  70%|███▍ | 3.42G/4.91G [00:04<00:02, 741MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  71%|███▌ | 3.50G/4.91G [00:04<00:01, 756MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  73%|███▋ | 3.59G/4.91G [00:04<00:01, 764MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  75%|███▋ | 3.67G/4.91G [00:04<00:01, 772MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  76%|███▊ | 3.75G/4.91G [00:05<00:01, 775MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  78%|███▉ | 3.84G/4.91G [00:05<00:01, 780MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  80%|███▉ | 3.92G/4.91G [00:05<00:01, 785MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  82%|████ | 4.01G/4.91G [00:05<00:01, 787MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  83%|████▏| 4.09G/4.91G [00:05<00:01, 789MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  85%|████▎| 4.17G/4.91G [00:05<00:00, 790MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  87%|████▎| 4.26G/4.91G [00:05<00:00, 787MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  88%|████▍| 4.34G/4.91G [00:05<00:00, 789MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  90%|████▌| 4.42G/4.91G [00:05<00:00, 788MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  92%|████▌| 4.51G/4.91G [00:05<00:00, 787MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  94%|████▋| 4.59G/4.91G [00:06<00:00, 784MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  95%|████▊| 4.68G/4.91G [00:06<00:00, 784MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors:  97%|████▊| 4.76G/4.91G [00:06<00:00, 784MB/s]\u001b[A\n",
            "model-00003-of-00005.safetensors: 100%|█████| 4.91G/4.91G [00:06<00:00, 756MB/s]\u001b[A\n",
            "Downloading shards:  60%|███████████████          | 3/5 [00:20<00:13,  6.83s/it]\n",
            "model-00004-of-00005.safetensors:   0%|             | 0.00/4.91G [00:00<?, ?B/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:   2%|     | 83.9M/4.91G [00:00<00:05, 818MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:   3%|▏     | 168M/4.91G [00:00<00:07, 663MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:   5%|▎     | 241M/4.91G [00:00<00:07, 654MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:   7%|▍     | 325M/4.91G [00:00<00:06, 710MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:   8%|▍     | 409M/4.91G [00:00<00:06, 742MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  10%|▌     | 493M/4.91G [00:00<00:05, 763MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  12%|▋     | 577M/4.91G [00:00<00:05, 777MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  13%|▊     | 661M/4.91G [00:00<00:05, 786MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  15%|▉     | 744M/4.91G [00:00<00:05, 792MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  17%|█     | 828M/4.91G [00:01<00:05, 797MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  19%|█     | 912M/4.91G [00:01<00:05, 782MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  20%|█▏    | 996M/4.91G [00:01<00:04, 788MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  22%|█    | 1.08G/4.91G [00:01<00:04, 791MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  24%|█▏   | 1.16G/4.91G [00:01<00:04, 789MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  25%|█▎   | 1.25G/4.91G [00:01<00:04, 791MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  27%|█▎   | 1.33G/4.91G [00:01<00:04, 793MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  29%|█▍   | 1.42G/4.91G [00:01<00:04, 788MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  31%|█▌   | 1.50G/4.91G [00:01<00:04, 789MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  32%|█▌   | 1.58G/4.91G [00:02<00:04, 791MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  34%|█▋   | 1.67G/4.91G [00:02<00:04, 777MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  36%|█▊   | 1.75G/4.91G [00:02<00:04, 774MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  37%|█▊   | 1.84G/4.91G [00:02<00:03, 779MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  39%|█▉   | 1.92G/4.91G [00:02<00:03, 782MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  41%|██   | 2.00G/4.91G [00:02<00:03, 786MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  43%|██▏  | 2.09G/4.91G [00:02<00:03, 787MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  44%|██▏  | 2.17G/4.91G [00:02<00:03, 785MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  46%|██▎  | 2.25G/4.91G [00:02<00:03, 786MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  48%|██▍  | 2.34G/4.91G [00:03<00:03, 766MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  49%|██▍  | 2.42G/4.91G [00:03<00:03, 774MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  51%|██▌  | 2.51G/4.91G [00:03<00:03, 779MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  53%|██▋  | 2.59G/4.91G [00:03<00:03, 671MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  54%|██▋  | 2.67G/4.91G [00:03<00:03, 704MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  56%|██▊  | 2.76G/4.91G [00:03<00:02, 726MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  58%|██▉  | 2.84G/4.91G [00:03<00:02, 741MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  60%|██▉  | 2.93G/4.91G [00:03<00:02, 747MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  61%|███  | 3.01G/4.91G [00:03<00:02, 760MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  63%|███▏ | 3.09G/4.91G [00:04<00:02, 746MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  65%|███▏ | 3.18G/4.91G [00:04<00:02, 756MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  66%|███▎ | 3.26G/4.91G [00:04<00:02, 769MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  68%|███▍ | 3.34G/4.91G [00:04<00:01, 784MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  70%|███▍ | 3.43G/4.91G [00:04<00:01, 772MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  72%|███▌ | 3.51G/4.91G [00:04<00:01, 779MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  73%|███▋ | 3.60G/4.91G [00:04<00:01, 768MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  75%|███▋ | 3.68G/4.91G [00:04<00:01, 767MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  77%|███▊ | 3.76G/4.91G [00:04<00:01, 779MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  79%|███▉ | 3.86G/4.91G [00:05<00:01, 798MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  80%|████ | 3.94G/4.91G [00:05<00:01, 809MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  82%|████ | 4.03G/4.91G [00:05<00:01, 794MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  84%|████▏| 4.11G/4.91G [00:05<00:00, 804MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  86%|████▎| 4.20G/4.91G [00:05<00:00, 816MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  87%|████▎| 4.29G/4.91G [00:05<00:01, 505MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  89%|████▍| 4.36G/4.91G [00:05<00:01, 533MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  90%|████▌| 4.44G/4.91G [00:06<00:00, 558MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  92%|████▌| 4.51G/4.91G [00:06<00:00, 577MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  93%|████▋| 4.58G/4.91G [00:06<00:00, 594MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  95%|████▋| 4.66G/4.91G [00:06<00:00, 608MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  96%|████▊| 4.73G/4.91G [00:06<00:00, 618MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors:  98%|████▉| 4.80G/4.91G [00:06<00:00, 626MB/s]\u001b[A\n",
            "model-00004-of-00005.safetensors: 100%|█████| 4.91G/4.91G [00:06<00:00, 728MB/s]\u001b[A\n",
            "Downloading shards:  80%|████████████████████     | 4/5 [00:27<00:06,  6.85s/it]\n",
            "model-00005-of-00005.safetensors:   0%|             | 0.00/4.91G [00:00<?, ?B/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:   1%|     | 62.9M/4.91G [00:00<00:08, 597MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:   3%|▏     | 147M/4.91G [00:00<00:06, 715MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:   4%|▎     | 220M/4.91G [00:00<00:06, 672MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:   6%|▎     | 304M/4.91G [00:00<00:06, 715MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:   8%|▍     | 388M/4.91G [00:00<00:06, 740MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  10%|▌     | 472M/4.91G [00:00<00:06, 733MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  11%|▋     | 556M/4.91G [00:00<00:05, 749MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  13%|▊     | 640M/4.91G [00:00<00:05, 762MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  15%|▉     | 724M/4.91G [00:00<00:05, 767MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  16%|▉     | 807M/4.91G [00:01<00:05, 774MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  18%|█     | 891M/4.91G [00:01<00:05, 780MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  20%|█▏    | 975M/4.91G [00:01<00:05, 781MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  22%|█    | 1.06G/4.91G [00:01<00:04, 782MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  23%|█▏   | 1.14G/4.91G [00:01<00:04, 783MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  25%|█▏   | 1.23G/4.91G [00:01<00:04, 785MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  27%|█▎   | 1.31G/4.91G [00:01<00:04, 784MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  28%|█▍   | 1.39G/4.91G [00:01<00:04, 779MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  30%|█▌   | 1.48G/4.91G [00:01<00:04, 720MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  32%|█▌   | 1.55G/4.91G [00:02<00:04, 701MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  33%|█▋   | 1.64G/4.91G [00:02<00:04, 725MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  35%|█▊   | 1.72G/4.91G [00:02<00:04, 740MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  37%|█▊   | 1.80G/4.91G [00:02<00:04, 732MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  38%|█▉   | 1.89G/4.91G [00:02<00:04, 711MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  40%|██   | 1.97G/4.91G [00:02<00:03, 734MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  42%|██   | 2.06G/4.91G [00:02<00:03, 752MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  44%|██▏  | 2.14G/4.91G [00:02<00:03, 751MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  45%|██▎  | 2.22G/4.91G [00:02<00:03, 749MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  47%|██▎  | 2.31G/4.91G [00:03<00:03, 755MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  49%|██▍  | 2.39G/4.91G [00:03<00:03, 763MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  50%|██▌  | 2.47G/4.91G [00:03<00:03, 770MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  52%|██▌  | 2.56G/4.91G [00:03<00:03, 692MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  54%|██▋  | 2.64G/4.91G [00:03<00:03, 717MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  56%|██▊  | 2.73G/4.91G [00:03<00:02, 734MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  57%|██▊  | 2.81G/4.91G [00:03<00:02, 747MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  59%|██▉  | 2.89G/4.91G [00:03<00:02, 757MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  61%|███  | 2.98G/4.91G [00:03<00:02, 763MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  62%|███  | 3.06G/4.91G [00:04<00:02, 767MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  64%|███▏ | 3.15G/4.91G [00:04<00:02, 754MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  66%|███▎ | 3.23G/4.91G [00:04<00:02, 760MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  68%|███▍ | 3.31G/4.91G [00:04<00:02, 766MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  69%|███▍ | 3.40G/4.91G [00:04<00:01, 772MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  71%|███▌ | 3.48G/4.91G [00:04<00:01, 771MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  73%|███▋ | 3.57G/4.91G [00:04<00:01, 771MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  74%|███▋ | 3.65G/4.91G [00:04<00:01, 739MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  76%|███▊ | 3.73G/4.91G [00:05<00:01, 676MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  78%|███▉ | 3.81G/4.91G [00:05<00:01, 637MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  79%|███▉ | 3.88G/4.91G [00:05<00:01, 609MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  81%|████ | 3.95G/4.91G [00:05<00:01, 638MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  82%|████ | 4.05G/4.91G [00:05<00:01, 710MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  84%|████▏| 4.14G/4.91G [00:05<00:01, 765MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  86%|████▎| 4.23G/4.91G [00:05<00:00, 757MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  88%|████▍| 4.31G/4.91G [00:05<00:00, 768MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  90%|████▍| 4.39G/4.91G [00:05<00:00, 777MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  91%|████▌| 4.48G/4.91G [00:06<00:00, 784MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  93%|████▋| 4.56G/4.91G [00:06<00:00, 790MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  95%|████▋| 4.65G/4.91G [00:06<00:00, 767MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  96%|████▊| 4.73G/4.91G [00:06<00:00, 769MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors:  98%|████▉| 4.81G/4.91G [00:06<00:00, 761MB/s]\u001b[A\n",
            "model-00005-of-00005.safetensors: 100%|█████| 4.91G/4.91G [00:06<00:00, 743MB/s]\u001b[A\n",
            "Downloading shards: 100%|█████████████████████████| 5/5 [00:34<00:00,  6.82s/it]\n",
            "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:06<00:00,  1.26s/it]\n",
            "generation_config.json: 100%|███████████████████| 116/116 [00:00<00:00, 487kB/s]\n",
            "2024-08-24:09:38:35,400 WARNING  [big_modeling.py:451] You shouldn't move a model that is dispatched using accelerate hooks.\n",
            "Downloading readme: 100%|███████████████████| 9.00k/9.00k [00:00<00:00, 270kB/s]\n",
            "Downloading data: 100%|███████████████████████| 190k/190k [00:00<00:00, 733kB/s]\n",
            "Downloading data: 100%|███████████████████████| 204k/204k [00:00<00:00, 870kB/s]\n",
            "Downloading data: 100%|█████████████████████| 55.7k/55.7k [00:00<00:00, 302kB/s]\n",
            "Generating train split: 100%|████| 1119/1119 [00:00<00:00, 102467.60 examples/s]\n",
            "Generating test split: 100%|█████| 1172/1172 [00:00<00:00, 178987.92 examples/s]\n",
            "Generating validation split: 100%|██| 299/299 [00:00<00:00, 82165.82 examples/s]\n",
            "Downloading readme: 100%|███████████████████| 10.5k/10.5k [00:00<00:00, 308kB/s]\n",
            "Downloading data: 100%|████████████████████| 4.15M/4.15M [00:00<00:00, 13.7MB/s]\n",
            "Downloading data: 100%|█████████████████████| 45.3k/45.3k [00:00<00:00, 278kB/s]\n",
            "Generating test split: 100%|███| 12032/12032 [00:00<00:00, 191750.54 examples/s]\n",
            "Generating validation split: 100%|████| 70/70 [00:00<00:00, 18238.37 examples/s]\n",
            "Downloading builder script: 100%|███████████| 5.86k/5.86k [00:00<00:00, 171kB/s]\n",
            "Downloading readme: 100%|██████████████████| 1.11k/1.11k [00:00<00:00, 36.0kB/s]\n",
            "Downloading data: 100%|██████████████████████| 166M/166M [00:04<00:00, 39.2MB/s]\n",
            "Generating test split: 171 examples [00:00, 1597.22 examples/s]\n",
            "Generating validation split: 19 examples [00:00, 4118.86 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 47.54 examples/s]\n",
            "Generating test split: 1534 examples [00:00, 7466.43 examples/s]\n",
            "Generating validation split: 170 examples [00:00, 10745.71 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 46.86 examples/s]\n",
            "Generating test split: 324 examples [00:00, 2665.20 examples/s]\n",
            "Generating validation split: 35 examples [00:00, 5699.45 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 47.64 examples/s]\n",
            "Generating test split: 311 examples [00:00, 2662.50 examples/s]\n",
            "Generating validation split: 34 examples [00:00, 7286.61 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 47.78 examples/s]\n",
            "Generating test split: 895 examples [00:00, 5714.66 examples/s]\n",
            "Generating validation split: 100 examples [00:00, 10279.15 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 47.46 examples/s]\n",
            "Generating test split: 346 examples [00:00, 2755.25 examples/s]\n",
            "Generating validation split: 38 examples [00:00, 4922.28 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 47.62 examples/s]\n",
            "Generating test split: 163 examples [00:00, 1518.12 examples/s]\n",
            "Generating validation split: 18 examples [00:00, 3288.79 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.19 examples/s]\n",
            "Generating test split: 108 examples [00:00, 1056.32 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 1890.72 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 47.60 examples/s]\n",
            "Generating test split: 121 examples [00:00, 1145.45 examples/s]\n",
            "Generating validation split: 13 examples [00:00, 2885.89 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.75 examples/s]\n",
            "Generating test split: 237 examples [00:00, 2001.90 examples/s]\n",
            "Generating validation split: 26 examples [00:00, 3571.37 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 46.45 examples/s]\n",
            "Generating test split: 204 examples [00:00, 1818.08 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 3151.14 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 47.40 examples/s]\n",
            "Generating test split: 165 examples [00:00, 1525.30 examples/s]\n",
            "Generating validation split: 18 examples [00:00, 2646.71 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.84 examples/s]\n",
            "Generating test split: 126 examples [00:00, 1171.06 examples/s]\n",
            "Generating validation split: 14 examples [00:00, 3254.46 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 49.21 examples/s]\n",
            "Generating test split: 100 examples [00:00, 933.11 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2741.21 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.37 examples/s]\n",
            "Generating test split: 201 examples [00:00, 1894.09 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 3406.60 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 47.44 examples/s]\n",
            "Generating test split: 245 examples [00:00, 2238.55 examples/s]\n",
            "Generating validation split: 27 examples [00:00, 3737.50 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.78 examples/s]\n",
            "Generating test split: 110 examples [00:00, 1043.96 examples/s]\n",
            "Generating validation split: 12 examples [00:00, 2300.24 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.88 examples/s]\n",
            "Generating test split: 612 examples [00:00, 4624.25 examples/s]\n",
            "Generating validation split: 69 examples [00:00, 7653.43 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 47.26 examples/s]\n",
            "Generating test split: 131 examples [00:00, 1250.38 examples/s]\n",
            "Generating validation split: 12 examples [00:00, 2603.81 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.08 examples/s]\n",
            "Generating test split: 545 examples [00:00, 4056.12 examples/s]\n",
            "Generating validation split: 60 examples [00:00, 6999.45 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 47.77 examples/s]\n",
            "Generating test split: 238 examples [00:00, 2080.23 examples/s]\n",
            "Generating validation split: 26 examples [00:00, 4157.21 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.39 examples/s]\n",
            "Generating test split: 390 examples [00:00, 3298.53 examples/s]\n",
            "Generating validation split: 43 examples [00:00, 7309.52 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.97 examples/s]\n",
            "Generating test split: 193 examples [00:00, 1781.08 examples/s]\n",
            "Generating validation split: 21 examples [00:00, 5420.00 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 47.47 examples/s]\n",
            "Generating test split: 198 examples [00:00, 1742.23 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 6470.88 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.78 examples/s]\n",
            "Generating test split: 114 examples [00:00, 1087.08 examples/s]\n",
            "Generating validation split: 12 examples [00:00, 2966.27 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.08 examples/s]\n",
            "Generating test split: 166 examples [00:00, 1556.96 examples/s]\n",
            "Generating validation split: 18 examples [00:00, 3436.23 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.26 examples/s]\n",
            "Generating test split: 272 examples [00:00, 2298.42 examples/s]\n",
            "Generating validation split: 31 examples [00:00, 5008.41 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.13 examples/s]\n",
            "Generating test split: 282 examples [00:00, 2355.11 examples/s]\n",
            "Generating validation split: 31 examples [00:00, 4152.38 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.84 examples/s]\n",
            "Generating test split: 306 examples [00:00, 2675.21 examples/s]\n",
            "Generating validation split: 33 examples [00:00, 5945.02 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.84 examples/s]\n",
            "Generating test split: 783 examples [00:00, 5485.06 examples/s]\n",
            "Generating validation split: 86 examples [00:00, 11629.06 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 46.51 examples/s]\n",
            "Generating test split: 100 examples [00:00, 965.44 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3749.78 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.22 examples/s]\n",
            "Generating test split: 234 examples [00:00, 2106.23 examples/s]\n",
            "Generating validation split: 25 examples [00:00, 4275.54 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.96 examples/s]\n",
            "Generating test split: 103 examples [00:00, 983.19 examples/s] \n",
            "Generating validation split: 11 examples [00:00, 2384.98 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.42 examples/s]\n",
            "Generating test split: 223 examples [00:00, 2016.27 examples/s]\n",
            "Generating validation split: 23 examples [00:00, 4300.32 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.21 examples/s]\n",
            "Generating test split: 100 examples [00:00, 980.22 examples/s]\n",
            "Generating validation split: 10 examples [00:00, 3184.02 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 47.20 examples/s]\n",
            "Generating test split: 173 examples [00:00, 1595.12 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 5050.61 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 49.05 examples/s]\n",
            "Generating test split: 265 examples [00:00, 2266.55 examples/s]\n",
            "Generating validation split: 29 examples [00:00, 5945.30 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 49.22 examples/s]\n",
            "Generating test split: 100 examples [00:00, 914.62 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3566.59 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.27 examples/s]\n",
            "Generating test split: 112 examples [00:00, 1091.26 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3166.60 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.74 examples/s]\n",
            "Generating test split: 216 examples [00:00, 1906.24 examples/s]\n",
            "Generating validation split: 23 examples [00:00, 4720.31 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 47.53 examples/s]\n",
            "Generating test split: 151 examples [00:00, 1358.01 examples/s]\n",
            "Generating validation split: 17 examples [00:00, 3684.16 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 47.63 examples/s]\n",
            "Generating test split: 270 examples [00:00, 2429.28 examples/s]\n",
            "Generating validation split: 29 examples [00:00, 6354.67 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.53 examples/s]\n",
            "Generating test split: 100 examples [00:00, 958.40 examples/s]\n",
            "Generating validation split: 9 examples [00:00, 3044.50 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.92 examples/s]\n",
            "Generating test split: 203 examples [00:00, 1871.18 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 3794.03 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 49.28 examples/s]\n",
            "Generating test split: 310 examples [00:00, 2737.50 examples/s]\n",
            "Generating validation split: 32 examples [00:00, 6753.43 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 47.31 examples/s]\n",
            "Generating test split: 378 examples [00:00, 3096.62 examples/s]\n",
            "Generating validation split: 41 examples [00:00, 6074.19 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 49.13 examples/s]\n",
            "Generating test split: 145 examples [00:00, 1378.30 examples/s]\n",
            "Generating validation split: 16 examples [00:00, 3866.39 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.31 examples/s]\n",
            "Generating test split: 235 examples [00:00, 2129.97 examples/s]\n",
            "Generating validation split: 26 examples [00:00, 7022.02 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.47 examples/s]\n",
            "Generating test split: 100 examples [00:00, 964.99 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2457.12 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.01 examples/s]\n",
            "Generating test split: 102 examples [00:00, 954.53 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3227.52 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 47.66 examples/s]\n",
            "Generating test split: 100 examples [00:00, 941.34 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2731.15 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 49.65 examples/s]\n",
            "Generating test split: 100 examples [00:00, 921.21 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2120.57 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.28 examples/s]\n",
            "Generating test split: 100 examples [00:00, 961.81 examples/s]\n",
            "Generating validation split: 8 examples [00:00, 1483.27 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.25 examples/s]\n",
            "Generating test split: 144 examples [00:00, 1409.31 examples/s]\n",
            "Generating validation split: 16 examples [00:00, 2767.26 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.68 examples/s]\n",
            "Generating test split: 152 examples [00:00, 1449.49 examples/s]\n",
            "Generating validation split: 16 examples [00:00, 5114.62 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 47.02 examples/s]\n",
            "Generating test split: 135 examples [00:00, 1297.69 examples/s]\n",
            "Generating validation split: 14 examples [00:00, 4243.71 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 49.55 examples/s]\n",
            "Generating test split: 100 examples [00:00, 975.76 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2980.45 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 48.80 examples/s]\n",
            "2024-08-24:09:39:20,979 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-24:09:39:20,979 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,979 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-24:09:39:20,979 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,979 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-24:09:39:20,979 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,979 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-24:09:39:20,979 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,979 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-24:09:39:20,979 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,980 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-24:09:39:20,980 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,980 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-24:09:39:20,980 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,980 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-24:09:39:20,980 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,980 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-24:09:39:20,980 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,980 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-24:09:39:20,980 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,980 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-24:09:39:20,980 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,980 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-24:09:39:20,980 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,980 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-24:09:39:20,980 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,980 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-24:09:39:20,980 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,980 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-24:09:39:20,980 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,980 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-24:09:39:20,980 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,980 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-24:09:39:20,980 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,981 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-24:09:39:20,981 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,981 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-24:09:39:20,981 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,981 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-24:09:39:20,981 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,981 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-24:09:39:20,981 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,981 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-24:09:39:20,981 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,981 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-24:09:39:20,981 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,981 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-24:09:39:20,981 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,981 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-24:09:39:20,981 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,981 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-24:09:39:20,981 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,981 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-24:09:39:20,981 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,981 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-24:09:39:20,981 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,981 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-24:09:39:20,981 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,982 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-24:09:39:20,982 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,982 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-24:09:39:20,982 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,982 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-24:09:39:20,982 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,982 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-24:09:39:20,982 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,982 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-24:09:39:20,982 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,982 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-24:09:39:20,982 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,982 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-24:09:39:20,982 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,982 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-24:09:39:20,982 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,982 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-24:09:39:20,982 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,982 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-24:09:39:20,982 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,982 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-24:09:39:20,982 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,982 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-24:09:39:20,982 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,983 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-24:09:39:20,983 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,983 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-24:09:39:20,983 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,983 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-24:09:39:20,983 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,983 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-24:09:39:20,983 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,983 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-24:09:39:20,983 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,983 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-24:09:39:20,983 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,983 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-24:09:39:20,983 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,983 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-24:09:39:20,983 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,983 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-24:09:39:20,983 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,983 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-24:09:39:20,983 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,983 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-24:09:39:20,983 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,983 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-24:09:39:20,984 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,984 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-24:09:39:20,984 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,984 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-24:09:39:20,984 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,984 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-24:09:39:20,984 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,984 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-24:09:39:20,984 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,984 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-24:09:39:20,984 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,984 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-24:09:39:20,984 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:09:39:20,984 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-24:09:39:20,993 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 575.39it/s]\n",
            "2024-08-24:09:39:21,172 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 571.66it/s]\n",
            "2024-08-24:09:39:21,415 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 580.05it/s]\n",
            "2024-08-24:09:39:21,685 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 578.72it/s]\n",
            "2024-08-24:09:39:21,941 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 586.35it/s]\n",
            "2024-08-24:09:39:22,117 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 581.03it/s]\n",
            "2024-08-24:09:39:22,294 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 576.60it/s]\n",
            "2024-08-24:09:39:22,472 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 585.17it/s]\n",
            "2024-08-24:09:39:22,652 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 581.97it/s]\n",
            "2024-08-24:09:39:22,829 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 567.64it/s]\n",
            "2024-08-24:09:39:23,254 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 539.48it/s]\n",
            "2024-08-24:09:39:23,530 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 582.97it/s]\n",
            "2024-08-24:09:39:24,197 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 585.47it/s]\n",
            "2024-08-24:09:39:24,742 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 581.14it/s]\n",
            "2024-08-24:09:39:25,101 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 582.58it/s]\n",
            "2024-08-24:09:39:25,278 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 585.32it/s]\n",
            "2024-08-24:09:39:25,752 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 579.08it/s]\n",
            "2024-08-24:09:39:26,020 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 704.83it/s]\n",
            "2024-08-24:09:39:26,337 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 716.85it/s]\n",
            "2024-08-24:09:39:26,498 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 719.47it/s]\n",
            "2024-08-24:09:39:26,641 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 716.63it/s]\n",
            "2024-08-24:09:39:27,021 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 724.56it/s]\n",
            "2024-08-24:09:39:27,268 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 717.72it/s]\n",
            "2024-08-24:09:39:27,412 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 717.98it/s]\n",
            "2024-08-24:09:39:27,731 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 712.38it/s]\n",
            "2024-08-24:09:39:27,880 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 481.28it/s]\n",
            "2024-08-24:09:39:28,376 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 702.68it/s]\n",
            "2024-08-24:09:39:28,522 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 708.77it/s]\n",
            "2024-08-24:09:39:29,657 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 708.92it/s]\n",
            "2024-08-24:09:39:30,101 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 700.19it/s]\n",
            "2024-08-24:09:39:30,515 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 713.81it/s]\n",
            "2024-08-24:09:39:30,907 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 689.36it/s]\n",
            "2024-08-24:09:39:31,155 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 717.52it/s]\n",
            "2024-08-24:09:39:31,319 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 720.08it/s]\n",
            "2024-08-24:09:39:31,602 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 720.03it/s]\n",
            "2024-08-24:09:39:31,877 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 724.41it/s]\n",
            "2024-08-24:09:39:32,430 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 718.55it/s]\n",
            "2024-08-24:09:39:32,771 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 719.90it/s]\n",
            "2024-08-24:09:39:33,548 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 710.59it/s]\n",
            "2024-08-24:09:39:33,738 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 706.21it/s]\n",
            "2024-08-24:09:39:34,628 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 697.95it/s]\n",
            "2024-08-24:09:39:34,790 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 703.71it/s]\n",
            "2024-08-24:09:39:35,148 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 696.22it/s]\n",
            "2024-08-24:09:39:35,445 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 702.15it/s]\n",
            "2024-08-24:09:39:35,592 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 705.23it/s]\n",
            "2024-08-24:09:39:35,776 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 676.82it/s]\n",
            "2024-08-24:09:39:36,029 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 714.02it/s]\n",
            "2024-08-24:09:39:36,323 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 714.56it/s]\n",
            "2024-08-24:09:39:36,665 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 728.03it/s]\n",
            "2024-08-24:09:39:36,836 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 719.84it/s]\n",
            "2024-08-24:09:39:36,991 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 710.11it/s]\n",
            "2024-08-24:09:39:37,227 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 714.22it/s]\n",
            "2024-08-24:09:39:37,725 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 624.40it/s]\n",
            "2024-08-24:09:39:39,191 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 719.13it/s]\n",
            "2024-08-24:09:39:39,636 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 716.14it/s]\n",
            "2024-08-24:09:39:40,101 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 711.52it/s]\n",
            "2024-08-24:09:39:42,316 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 712.82it/s]\n",
            "2024-08-24:09:39:42,563 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 16107.30it/s]\n",
            "2024-08-24:09:39:44,106 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1403.75it/s]\n",
            "2024-08-24:09:39:44,999 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
            "Running loglikelihood requests: 100%|██| 174850/174850 [29:01<00:00, 100.42it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-24:10:10:39,323 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=mistralai/Mistral-Nemo-Base-2407,load_in_4bit=True), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.5068|±  |0.0146|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.5478|±  |0.0145|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.2719|±  |0.0041|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.6167|±  |0.0038|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5554|±  |0.0066|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.4206|±  |0.0442|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7576|±  |0.0335|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.7892|±  |0.0286|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.8059|±  |0.0257|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.8430|±  |0.0332|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.7685|±  |0.0408|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7117|±  |0.0356|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.6676|±  |0.0254|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2425|±  |0.0143|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.7524|±  |0.0245|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.7191|±  |0.0250|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4713|±  |0.0127|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.8421|±  |0.0280|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.7039|±  |0.0079|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.6400|±  |0.0482|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.7094|±  |0.0279|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.6069|±  |0.0372|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.4100|±  |0.0494|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.6951|±  |0.0309|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.7864|±  |0.0406|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8419|±  |0.0239|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.7000|±  |0.0461|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.8199|±  |0.0137|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.7222|±  |0.0256|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.5000|±  |0.0298|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.7206|±  |0.0273|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5181|±  |0.0389|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.7299|±  |0.0078|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.4561|±  |0.0469|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.7778|±  |0.0296|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8912|±  |0.0225|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.6333|±  |0.0244|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.6849|±  |0.0302|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.8349|±  |0.0159|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.7634|±  |0.0373|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.6536|±  |0.0192|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6636|±  |0.0453|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.7061|±  |0.0292|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.8408|±  |0.0259|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.8800|±  |0.0327|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5119|±  |0.0086|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3500|±  |0.0479|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.5852|±  |0.0426|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.6711|±  |0.0382|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.6875|±  |0.0388|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4700|±  |0.0502|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.3900|±  |0.0490|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.3500|±  |0.0479|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.4216|±  |0.0491|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.7300|±  |0.0446|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5362|±  |0.0326|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.5241|±  |0.0416|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4127|±  |0.0254|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7710|±  |0.0239|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.4680|±  |0.0351|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.6100|±  |0.0490|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3222|±  |0.0285|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.3377|±  |0.0386|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.5694|±  |0.0338|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.4286|±  |0.0470|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.6167|±  |0.0038|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5554|±  |0.0066|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.7039|±  |0.0079|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.7299|±  |0.0078|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5119|±  |0.0086|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=mistralai/Mistral-Nemo-Base-2407,load_in_4bit=True --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74319369-84dd-4810-aead-64e1190fb30c",
      "metadata": {
        "id": "74319369-84dd-4810-aead-64e1190fb30c",
        "outputId": "d189c234-8cdc-48df-bc90-d47e6e8fac61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 601.46it/s]\n",
            "2024-08-23:15:09:39,978 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 708.83it/s]\n",
            "2024-08-23:15:09:40,422 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 708.26it/s]\n",
            "2024-08-23:15:09:40,831 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 706.95it/s]\n",
            "2024-08-23:15:09:41,227 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 706.50it/s]\n",
            "2024-08-23:15:09:41,468 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 709.42it/s]\n",
            "2024-08-23:15:09:41,634 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 712.13it/s]\n",
            "2024-08-23:15:09:41,920 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 680.79it/s]\n",
            "2024-08-23:15:09:42,211 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 585.03it/s]\n",
            "2024-08-23:15:09:42,897 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 576.04it/s]\n",
            "2024-08-23:15:09:43,321 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 578.34it/s]\n",
            "2024-08-23:15:09:44,292 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 579.58it/s]\n",
            "2024-08-23:15:09:44,525 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 647.86it/s]\n",
            "2024-08-23:15:09:45,498 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 725.05it/s]\n",
            "2024-08-23:15:09:45,654 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 702.61it/s]\n",
            "2024-08-23:15:09:46,012 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 722.79it/s]\n",
            "2024-08-23:15:09:46,299 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 721.27it/s]\n",
            "2024-08-23:15:09:46,442 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 703.67it/s]\n",
            "2024-08-23:15:09:46,626 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 701.65it/s]\n",
            "2024-08-23:15:09:46,870 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 721.47it/s]\n",
            "2024-08-23:15:09:47,161 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 707.28it/s]\n",
            "2024-08-23:15:09:47,506 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 708.20it/s]\n",
            "2024-08-23:15:09:47,682 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 574.97it/s]\n",
            "2024-08-23:15:09:47,875 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 583.52it/s]\n",
            "2024-08-23:15:09:48,163 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 577.59it/s]\n",
            "2024-08-23:15:09:48,779 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 488.83it/s]\n",
            "2024-08-23:15:09:50,654 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 564.09it/s]\n",
            "2024-08-23:15:09:51,221 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 562.66it/s]\n",
            "2024-08-23:15:09:51,815 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 615.20it/s]\n",
            "2024-08-23:15:09:54,393 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 701.99it/s]\n",
            "2024-08-23:15:09:54,644 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 14159.29it/s]\n",
            "2024-08-23:15:09:56,315 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1297.24it/s]\n",
            "2024-08-23:15:09:57,280 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
            "Running loglikelihood requests: 100%|█| 174850/174850 [1:08:30<00:00, 42.54it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-23:16:20:25,308 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=kaitchup/Mistral-Nemo-Base-2407-AutoRound-GPTQ-sym-4bit), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.5162|±  |0.0146|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.5614|±  |0.0145|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.2979|±  |0.0042|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.6246|±  |0.0038|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5626|±  |0.0066|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.4365|±  |0.0444|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7758|±  |0.0326|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.8088|±  |0.0276|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.8186|±  |0.0251|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.7851|±  |0.0375|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.7870|±  |0.0396|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7117|±  |0.0356|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.6965|±  |0.0248|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2413|±  |0.0143|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.7363|±  |0.0250|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.7284|±  |0.0247|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4844|±  |0.0128|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.8421|±  |0.0280|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.6997|±  |0.0079|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.5900|±  |0.0494|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.6642|±  |0.0291|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.5607|±  |0.0378|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.4300|±  |0.0498|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.6906|±  |0.0310|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.7767|±  |0.0412|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8376|±  |0.0242|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.7500|±  |0.0435|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.8263|±  |0.0135|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.7549|±  |0.0246|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.5071|±  |0.0298|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.7059|±  |0.0277|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.4880|±  |0.0389|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.7293|±  |0.0078|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.4211|±  |0.0464|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.8081|±  |0.0281|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8653|±  |0.0246|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.6410|±  |0.0243|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.6681|±  |0.0306|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.8092|±  |0.0168|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.7710|±  |0.0369|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.6781|±  |0.0189|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6909|±  |0.0443|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.6980|±  |0.0294|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.8408|±  |0.0259|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.8700|±  |0.0338|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5411|±  |0.0085|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3500|±  |0.0479|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.6444|±  |0.0414|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.7500|±  |0.0352|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.7569|±  |0.0359|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4600|±  |0.0501|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.4700|±  |0.0502|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.3600|±  |0.0482|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.4118|±  |0.0490|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.7700|±  |0.0423|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5702|±  |0.0324|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.5931|±  |0.0409|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4259|±  |0.0255|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7806|±  |0.0235|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.5074|±  |0.0352|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.6600|±  |0.0476|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3481|±  |0.0290|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.4172|±  |0.0403|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.5463|±  |0.0340|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.4107|±  |0.0467|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.6246|±  |0.0038|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5626|±  |0.0066|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.6997|±  |0.0079|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.7293|±  |0.0078|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5411|±  |0.0085|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=kaitchup/Mistral-Nemo-Base-2407-AutoRound-GPTQ-sym-4bit --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54a09ca8-f195-4761-a298-176cf133fde5",
      "metadata": {
        "id": "54a09ca8-f195-4761-a298-176cf133fde5",
        "outputId": "12bcfeb1-60ab-4370-a516-65fd96cb5240"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-25:16:34:46,861 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-25:16:34:46,967 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-25:16:35:00,418 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-25:16:35:00,420 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-25:16:35:00,420 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': './AutoRound/Mistral-Nemo-Base-2407-AutoRound-GPTQ-asym-4bit'}\n",
            "2024-08-25:16:35:00,527 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-25:16:35:00,527 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "2024-08-25:16:35:00,988 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "2024-08-25:16:35:01,831 WARNING  [qlinear_cuda.py:18] CUDA extension not installed.\n",
            "2024-08-25:16:35:01,831 WARNING  [qlinear_cuda_old.py:17] CUDA extension not installed.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4709: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at ./AutoRound/Mistral-Nemo-Base-2407-AutoRound-GPTQ-asym-4bit were not used when initializing MistralForCausalLM: ['model.layers.0.mlp.down_proj.bias', 'model.layers.0.mlp.gate_proj.bias', 'model.layers.0.mlp.up_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.o_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.1.mlp.down_proj.bias', 'model.layers.1.mlp.gate_proj.bias', 'model.layers.1.mlp.up_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.o_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.10.mlp.down_proj.bias', 'model.layers.10.mlp.gate_proj.bias', 'model.layers.10.mlp.up_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.o_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.11.mlp.down_proj.bias', 'model.layers.11.mlp.gate_proj.bias', 'model.layers.11.mlp.up_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.o_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.12.mlp.down_proj.bias', 'model.layers.12.mlp.gate_proj.bias', 'model.layers.12.mlp.up_proj.bias', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.o_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.13.mlp.down_proj.bias', 'model.layers.13.mlp.gate_proj.bias', 'model.layers.13.mlp.up_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.o_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.14.mlp.down_proj.bias', 'model.layers.14.mlp.gate_proj.bias', 'model.layers.14.mlp.up_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.o_proj.bias', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.15.mlp.down_proj.bias', 'model.layers.15.mlp.gate_proj.bias', 'model.layers.15.mlp.up_proj.bias', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.o_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.16.mlp.down_proj.bias', 'model.layers.16.mlp.gate_proj.bias', 'model.layers.16.mlp.up_proj.bias', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.o_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.17.mlp.down_proj.bias', 'model.layers.17.mlp.gate_proj.bias', 'model.layers.17.mlp.up_proj.bias', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.o_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.18.mlp.down_proj.bias', 'model.layers.18.mlp.gate_proj.bias', 'model.layers.18.mlp.up_proj.bias', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.o_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.19.mlp.down_proj.bias', 'model.layers.19.mlp.gate_proj.bias', 'model.layers.19.mlp.up_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.o_proj.bias', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.2.mlp.down_proj.bias', 'model.layers.2.mlp.gate_proj.bias', 'model.layers.2.mlp.up_proj.bias', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.o_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.20.mlp.down_proj.bias', 'model.layers.20.mlp.gate_proj.bias', 'model.layers.20.mlp.up_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.o_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.21.mlp.down_proj.bias', 'model.layers.21.mlp.gate_proj.bias', 'model.layers.21.mlp.up_proj.bias', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.o_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.22.mlp.down_proj.bias', 'model.layers.22.mlp.gate_proj.bias', 'model.layers.22.mlp.up_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.o_proj.bias', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.23.mlp.down_proj.bias', 'model.layers.23.mlp.gate_proj.bias', 'model.layers.23.mlp.up_proj.bias', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.o_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.24.mlp.down_proj.bias', 'model.layers.24.mlp.gate_proj.bias', 'model.layers.24.mlp.up_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.o_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.25.mlp.down_proj.bias', 'model.layers.25.mlp.gate_proj.bias', 'model.layers.25.mlp.up_proj.bias', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.o_proj.bias', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.26.mlp.down_proj.bias', 'model.layers.26.mlp.gate_proj.bias', 'model.layers.26.mlp.up_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.o_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.27.mlp.down_proj.bias', 'model.layers.27.mlp.gate_proj.bias', 'model.layers.27.mlp.up_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.o_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.28.mlp.down_proj.bias', 'model.layers.28.mlp.gate_proj.bias', 'model.layers.28.mlp.up_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.o_proj.bias', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.29.mlp.down_proj.bias', 'model.layers.29.mlp.gate_proj.bias', 'model.layers.29.mlp.up_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.29.self_attn.o_proj.bias', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.3.mlp.down_proj.bias', 'model.layers.3.mlp.gate_proj.bias', 'model.layers.3.mlp.up_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.o_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.30.mlp.down_proj.bias', 'model.layers.30.mlp.gate_proj.bias', 'model.layers.30.mlp.up_proj.bias', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.o_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.31.mlp.down_proj.bias', 'model.layers.31.mlp.gate_proj.bias', 'model.layers.31.mlp.up_proj.bias', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.31.self_attn.o_proj.bias', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.32.mlp.down_proj.bias', 'model.layers.32.mlp.gate_proj.bias', 'model.layers.32.mlp.up_proj.bias', 'model.layers.32.self_attn.k_proj.bias', 'model.layers.32.self_attn.o_proj.bias', 'model.layers.32.self_attn.q_proj.bias', 'model.layers.32.self_attn.v_proj.bias', 'model.layers.33.mlp.down_proj.bias', 'model.layers.33.mlp.gate_proj.bias', 'model.layers.33.mlp.up_proj.bias', 'model.layers.33.self_attn.k_proj.bias', 'model.layers.33.self_attn.o_proj.bias', 'model.layers.33.self_attn.q_proj.bias', 'model.layers.33.self_attn.v_proj.bias', 'model.layers.34.mlp.down_proj.bias', 'model.layers.34.mlp.gate_proj.bias', 'model.layers.34.mlp.up_proj.bias', 'model.layers.34.self_attn.k_proj.bias', 'model.layers.34.self_attn.o_proj.bias', 'model.layers.34.self_attn.q_proj.bias', 'model.layers.34.self_attn.v_proj.bias', 'model.layers.35.mlp.down_proj.bias', 'model.layers.35.mlp.gate_proj.bias', 'model.layers.35.mlp.up_proj.bias', 'model.layers.35.self_attn.k_proj.bias', 'model.layers.35.self_attn.o_proj.bias', 'model.layers.35.self_attn.q_proj.bias', 'model.layers.35.self_attn.v_proj.bias', 'model.layers.36.mlp.down_proj.bias', 'model.layers.36.mlp.gate_proj.bias', 'model.layers.36.mlp.up_proj.bias', 'model.layers.36.self_attn.k_proj.bias', 'model.layers.36.self_attn.o_proj.bias', 'model.layers.36.self_attn.q_proj.bias', 'model.layers.36.self_attn.v_proj.bias', 'model.layers.37.mlp.down_proj.bias', 'model.layers.37.mlp.gate_proj.bias', 'model.layers.37.mlp.up_proj.bias', 'model.layers.37.self_attn.k_proj.bias', 'model.layers.37.self_attn.o_proj.bias', 'model.layers.37.self_attn.q_proj.bias', 'model.layers.37.self_attn.v_proj.bias', 'model.layers.38.mlp.down_proj.bias', 'model.layers.38.mlp.gate_proj.bias', 'model.layers.38.mlp.up_proj.bias', 'model.layers.38.self_attn.k_proj.bias', 'model.layers.38.self_attn.o_proj.bias', 'model.layers.38.self_attn.q_proj.bias', 'model.layers.38.self_attn.v_proj.bias', 'model.layers.39.mlp.down_proj.bias', 'model.layers.39.mlp.gate_proj.bias', 'model.layers.39.mlp.up_proj.bias', 'model.layers.39.self_attn.k_proj.bias', 'model.layers.39.self_attn.o_proj.bias', 'model.layers.39.self_attn.q_proj.bias', 'model.layers.39.self_attn.v_proj.bias', 'model.layers.4.mlp.down_proj.bias', 'model.layers.4.mlp.gate_proj.bias', 'model.layers.4.mlp.up_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.o_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.5.mlp.down_proj.bias', 'model.layers.5.mlp.gate_proj.bias', 'model.layers.5.mlp.up_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.o_proj.bias', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.6.mlp.down_proj.bias', 'model.layers.6.mlp.gate_proj.bias', 'model.layers.6.mlp.up_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.o_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.7.mlp.down_proj.bias', 'model.layers.7.mlp.gate_proj.bias', 'model.layers.7.mlp.up_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.o_proj.bias', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.8.mlp.down_proj.bias', 'model.layers.8.mlp.gate_proj.bias', 'model.layers.8.mlp.up_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.o_proj.bias', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.9.mlp.down_proj.bias', 'model.layers.9.mlp.gate_proj.bias', 'model.layers.9.mlp.up_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.o_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.v_proj.bias']\n",
            "- This IS expected if you are initializing MistralForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing MistralForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "2024-08-25:16:36:33,474 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-25:16:36:33,474 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,474 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-25:16:36:33,474 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,474 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-25:16:36:33,474 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,474 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-25:16:36:33,474 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,474 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-25:16:36:33,475 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,475 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-25:16:36:33,475 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,475 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-25:16:36:33,475 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,475 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-25:16:36:33,475 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,475 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-25:16:36:33,475 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,475 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-25:16:36:33,475 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,475 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-25:16:36:33,475 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,475 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-25:16:36:33,475 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,475 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-25:16:36:33,475 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,475 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-25:16:36:33,475 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,475 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-25:16:36:33,475 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,475 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-25:16:36:33,475 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,475 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-25:16:36:33,476 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,476 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-25:16:36:33,476 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,476 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-25:16:36:33,476 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,476 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-25:16:36:33,476 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,476 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-25:16:36:33,476 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,476 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-25:16:36:33,476 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,476 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-25:16:36:33,476 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,476 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-25:16:36:33,476 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,476 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-25:16:36:33,476 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,476 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-25:16:36:33,476 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,476 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-25:16:36:33,476 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,476 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-25:16:36:33,476 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,477 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-25:16:36:33,477 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,477 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-25:16:36:33,477 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,477 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-25:16:36:33,477 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,477 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-25:16:36:33,477 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,477 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-25:16:36:33,477 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,477 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-25:16:36:33,477 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,477 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-25:16:36:33,477 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,477 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-25:16:36:33,477 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,477 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-25:16:36:33,477 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,477 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-25:16:36:33,477 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,477 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-25:16:36:33,477 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,477 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-25:16:36:33,478 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,478 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-25:16:36:33,478 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,478 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-25:16:36:33,478 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,478 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-25:16:36:33,478 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,478 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-25:16:36:33,478 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,478 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-25:16:36:33,478 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,478 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-25:16:36:33,478 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,478 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-25:16:36:33,478 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,478 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-25:16:36:33,478 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,478 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-25:16:36:33,478 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,478 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-25:16:36:33,478 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,478 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-25:16:36:33,478 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,479 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-25:16:36:33,479 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,479 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-25:16:36:33,479 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,479 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-25:16:36:33,479 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,479 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-25:16:36:33,479 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,479 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-25:16:36:33,479 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,479 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-25:16:36:33,479 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,479 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-25:16:36:33,479 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,479 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-25:16:36:33,479 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:16:36:33,479 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-25:16:36:33,489 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 568.43it/s]\n",
            "2024-08-25:16:36:33,671 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 567.39it/s]\n",
            "2024-08-25:16:36:33,916 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 570.71it/s]\n",
            "2024-08-25:16:36:34,190 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 574.13it/s]\n",
            "2024-08-25:16:36:34,449 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 573.23it/s]\n",
            "2024-08-25:16:36:34,629 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 577.22it/s]\n",
            "2024-08-25:16:36:34,807 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 562.38it/s]\n",
            "2024-08-25:16:36:34,990 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 578.05it/s]\n",
            "2024-08-25:16:36:35,172 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 571.84it/s]\n",
            "2024-08-25:16:36:35,352 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 573.33it/s]\n",
            "2024-08-25:16:36:35,774 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 572.37it/s]\n",
            "2024-08-25:16:36:36,035 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 574.16it/s]\n",
            "2024-08-25:16:36:36,712 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 574.00it/s]\n",
            "2024-08-25:16:36:37,267 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 611.08it/s]\n",
            "2024-08-25:16:36:37,610 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 695.65it/s]\n",
            "2024-08-25:16:36:37,758 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 699.90it/s]\n",
            "2024-08-25:16:36:38,155 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 699.48it/s]\n",
            "2024-08-25:16:36:38,377 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 697.67it/s]\n",
            "2024-08-25:16:36:38,696 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 690.16it/s]\n",
            "2024-08-25:16:36:38,863 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 701.35it/s]\n",
            "2024-08-25:16:36:39,010 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 691.41it/s]\n",
            "2024-08-25:16:36:39,404 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 695.70it/s]\n",
            "2024-08-25:16:36:39,660 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 694.93it/s]\n",
            "2024-08-25:16:36:39,809 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 689.95it/s]\n",
            "2024-08-25:16:36:40,141 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 700.08it/s]\n",
            "2024-08-25:16:36:40,293 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 697.42it/s]\n",
            "2024-08-25:16:36:40,638 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 688.03it/s]\n",
            "2024-08-25:16:36:40,788 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 598.81it/s]\n",
            "2024-08-25:16:36:42,126 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 697.39it/s]\n",
            "2024-08-25:16:36:42,578 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 690.03it/s]\n",
            "2024-08-25:16:36:42,998 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 695.50it/s]\n",
            "2024-08-25:16:36:43,401 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 693.13it/s]\n",
            "2024-08-25:16:36:43,647 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 682.09it/s]\n",
            "2024-08-25:16:36:43,819 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 696.07it/s]\n",
            "2024-08-25:16:36:44,113 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 699.54it/s]\n",
            "2024-08-25:16:36:44,397 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 701.99it/s]\n",
            "2024-08-25:16:36:44,968 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 707.30it/s]\n",
            "2024-08-25:16:36:45,314 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 703.58it/s]\n",
            "2024-08-25:16:36:46,111 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 705.28it/s]\n",
            "2024-08-25:16:36:46,302 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 706.79it/s]\n",
            "2024-08-25:16:36:47,193 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 704.79it/s]\n",
            "2024-08-25:16:36:47,353 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 705.05it/s]\n",
            "2024-08-25:16:36:47,711 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 691.33it/s]\n",
            "2024-08-25:16:36:48,010 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 700.38it/s]\n",
            "2024-08-25:16:36:48,157 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 706.35it/s]\n",
            "2024-08-25:16:36:48,341 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 700.72it/s]\n",
            "2024-08-25:16:36:48,584 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 691.27it/s]\n",
            "2024-08-25:16:36:48,888 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 679.05it/s]\n",
            "2024-08-25:16:36:49,247 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 694.52it/s]\n",
            "2024-08-25:16:36:49,427 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 694.33it/s]\n",
            "2024-08-25:16:36:49,587 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 692.38it/s]\n",
            "2024-08-25:16:36:49,829 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 695.81it/s]\n",
            "2024-08-25:16:36:50,340 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 609.12it/s]\n",
            "2024-08-25:16:36:51,845 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 644.98it/s]\n",
            "2024-08-25:16:36:52,340 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 706.37it/s]\n",
            "2024-08-25:16:36:52,811 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 701.46it/s]\n",
            "2024-08-25:16:36:55,060 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 688.95it/s]\n",
            "2024-08-25:16:36:55,316 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 16335.82it/s]\n",
            "2024-08-25:16:36:56,875 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1391.69it/s]\n",
            "2024-08-25:16:36:57,776 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n",
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
            "Running loglikelihood requests: 100%|█| 174850/174850 [1:08:22<00:00, 42.62it/s]\n",
            "2024-08-25:17:47:16,008 WARNING  [huggingface.py:1427] Failed to get model SHA for ./AutoRound/Mistral-Nemo-Base-2407-AutoRound-GPTQ-asym-4bit at revision main. Error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './AutoRound/Mistral-Nemo-Base-2407-AutoRound-GPTQ-asym-4bit'. Use `repo_type` argument if needed.\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-25:17:47:17,098 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=./AutoRound/Mistral-Nemo-Base-2407-AutoRound-GPTQ-asym-4bit), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.5469|±  |0.0145|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.5708|±  |0.0145|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.3046|±  |0.0042|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.6305|±  |0.0038|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5668|±  |0.0066|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.3810|±  |0.0434|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7818|±  |0.0323|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.8186|±  |0.0270|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.8017|±  |0.0260|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.7934|±  |0.0370|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.7685|±  |0.0408|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7607|±  |0.0335|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.7254|±  |0.0240|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2425|±  |0.0143|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.7492|±  |0.0246|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.7160|±  |0.0251|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4909|±  |0.0128|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.8421|±  |0.0280|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.7171|±  |0.0078|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.6000|±  |0.0492|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.6981|±  |0.0283|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.6127|±  |0.0371|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.4700|±  |0.0502|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.7040|±  |0.0306|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.7573|±  |0.0425|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8803|±  |0.0213|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.6900|±  |0.0465|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.8250|±  |0.0136|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.7451|±  |0.0250|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.5532|±  |0.0297|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.7463|±  |0.0264|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5241|±  |0.0389|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.7325|±  |0.0078|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.4386|±  |0.0467|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.7424|±  |0.0312|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8601|±  |0.0250|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.6282|±  |0.0245|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.6723|±  |0.0305|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.8165|±  |0.0166|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.7939|±  |0.0355|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.7010|±  |0.0185|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6545|±  |0.0455|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.6980|±  |0.0294|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.8657|±  |0.0241|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.9100|±  |0.0288|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5404|±  |0.0085|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3800|±  |0.0488|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.6296|±  |0.0417|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.7434|±  |0.0355|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.7222|±  |0.0375|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4400|±  |0.0499|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.5000|±  |0.0503|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.3900|±  |0.0490|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.4020|±  |0.0488|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.7400|±  |0.0441|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5745|±  |0.0323|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.6207|±  |0.0404|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4392|±  |0.0256|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7581|±  |0.0244|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.5123|±  |0.0352|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.7000|±  |0.0461|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3444|±  |0.0290|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.4172|±  |0.0403|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.5324|±  |0.0340|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.4018|±  |0.0465|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.6305|±  |0.0038|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5668|±  |0.0066|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.7171|±  |0.0078|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.7325|±  |0.0078|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5404|±  |0.0085|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=./AutoRound/Mistral-Nemo-Base-2407-AutoRound-GPTQ-asym-4bit --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###meta-llama/Meta-Llama-3.1-8B"
      ],
      "metadata": {
        "id": "B4WI4yqDGAXY"
      },
      "id": "B4WI4yqDGAXY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b582e87-64a4-4047-b9b9-7203f82e1c7e",
      "metadata": {
        "id": "8b582e87-64a4-4047-b9b9-7203f82e1c7e",
        "outputId": "b4fb4242-cb57-43b3-a67c-7684a5cad77e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-24:10:48:17,252 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-24:10:48:17,347 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-24:10:48:29,710 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-24:10:48:29,713 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-24:10:48:29,713 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3.1-8B', 'dtype': 'float16'}\n",
            "2024-08-24:10:48:29,974 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-24:10:48:29,974 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "config.json: 100%|█████████████████████████████| 826/826 [00:00<00:00, 4.07MB/s]\n",
            "tokenizer_config.json: 100%|████████████████| 50.5k/50.5k [00:00<00:00, 177MB/s]\n",
            "tokenizer.json: 100%|██████████████████████| 9.09M/9.09M [00:00<00:00, 36.3MB/s]\n",
            "special_tokens_map.json: 100%|████████████████| 73.0/73.0 [00:00<00:00, 367kB/s]\n",
            "2024-08-24:10:48:30,995 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "model.safetensors.index.json: 100%|████████| 23.9k/23.9k [00:00<00:00, 52.9MB/s]\n",
            "Downloading shards:   0%|                                 | 0/4 [00:00<?, ?it/s]\n",
            "model-00001-of-00004.safetensors:   0%|             | 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   0%|     | 21.0M/4.98G [00:00<00:27, 180MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   1%|     | 52.4M/4.98G [00:00<00:21, 234MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   2%|     | 94.4M/4.98G [00:00<00:17, 283MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   3%|▏     | 126M/4.98G [00:00<00:18, 257MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   3%|▏     | 168M/4.98G [00:00<00:16, 296MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   4%|▎     | 210M/4.98G [00:00<00:15, 317MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   5%|▎     | 252M/4.98G [00:00<00:14, 326MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   6%|▎     | 294M/4.98G [00:00<00:13, 339MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   7%|▍     | 336M/4.98G [00:01<00:13, 347MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   8%|▍     | 377M/4.98G [00:01<00:13, 353MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   8%|▌     | 419M/4.98G [00:01<00:12, 354MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:   9%|▌     | 461M/4.98G [00:01<00:12, 357MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  10%|▌     | 503M/4.98G [00:01<00:12, 359MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  11%|▋     | 545M/4.98G [00:01<00:12, 361MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  12%|▋     | 587M/4.98G [00:01<00:12, 364MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  13%|▊     | 629M/4.98G [00:01<00:11, 364MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  13%|▊     | 671M/4.98G [00:02<00:18, 236MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  15%|▊     | 724M/4.98G [00:02<00:15, 277MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  15%|▉     | 765M/4.98G [00:02<00:14, 297MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  16%|▉     | 807M/4.98G [00:02<00:13, 312MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  17%|█     | 849M/4.98G [00:02<00:12, 328MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  18%|█     | 891M/4.98G [00:02<00:12, 333MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  19%|█▏    | 933M/4.98G [00:02<00:11, 344MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  20%|█▏    | 975M/4.98G [00:03<00:11, 349MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  20%|█    | 1.02G/4.98G [00:03<00:11, 353MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  21%|█    | 1.06G/4.98G [00:03<00:10, 358MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  22%|█    | 1.10G/4.98G [00:03<00:10, 359MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  23%|█▏   | 1.14G/4.98G [00:03<00:10, 350MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24%|█▏   | 1.18G/4.98G [00:03<00:12, 316MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  25%|█▏   | 1.24G/4.98G [00:03<00:10, 350MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  26%|█▎   | 1.28G/4.98G [00:03<00:10, 354MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  27%|█▎   | 1.32G/4.98G [00:04<00:27, 133MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  27%|█▎   | 1.35G/4.98G [00:04<00:26, 137MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  28%|█▍   | 1.39G/4.98G [00:05<00:20, 171MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  29%|█▍   | 1.44G/4.98G [00:05<00:17, 204MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  29%|█▍   | 1.47G/4.98G [00:05<00:16, 214MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  30%|█▌   | 1.51G/4.98G [00:05<00:13, 251MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  31%|█▌   | 1.55G/4.98G [00:05<00:12, 278MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  32%|█▌   | 1.59G/4.98G [00:05<00:11, 301MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  33%|█▋   | 1.64G/4.98G [00:05<00:10, 315MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  34%|█▋   | 1.68G/4.98G [00:06<00:14, 228MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  35%|█▋   | 1.73G/4.98G [00:06<00:11, 273MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  36%|█▊   | 1.77G/4.98G [00:06<00:10, 294MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  36%|█▊   | 1.81G/4.98G [00:06<00:10, 310MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  37%|█▊   | 1.86G/4.98G [00:06<00:09, 324MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  38%|█▉   | 1.90G/4.98G [00:06<00:09, 330MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  39%|█▉   | 1.94G/4.98G [00:06<00:08, 340MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  40%|█▉   | 1.98G/4.98G [00:06<00:08, 345MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  41%|██   | 2.02G/4.98G [00:06<00:08, 346MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  42%|██   | 2.07G/4.98G [00:07<00:08, 348MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  42%|██   | 2.11G/4.98G [00:07<00:08, 347MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  43%|██▏  | 2.15G/4.98G [00:07<00:07, 359MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  44%|██▏  | 2.19G/4.98G [00:07<00:07, 357MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  45%|██▏  | 2.23G/4.98G [00:07<00:07, 361MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  46%|██▎  | 2.28G/4.98G [00:07<00:07, 363MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  47%|██▎  | 2.32G/4.98G [00:07<00:07, 364MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  47%|██▎  | 2.36G/4.98G [00:07<00:07, 360MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  48%|██▍  | 2.40G/4.98G [00:08<00:07, 355MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  49%|██▍  | 2.44G/4.98G [00:08<00:07, 359MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  50%|██▍  | 2.49G/4.98G [00:08<00:06, 361MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  51%|██▌  | 2.53G/4.98G [00:08<00:06, 360MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  52%|██▌  | 2.57G/4.98G [00:08<00:06, 362MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  52%|██▌  | 2.61G/4.98G [00:08<00:06, 363MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  53%|██▋  | 2.65G/4.98G [00:08<00:06, 363MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  54%|██▋  | 2.69G/4.98G [00:08<00:07, 314MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  55%|██▋  | 2.74G/4.98G [00:09<00:08, 258MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  56%|██▊  | 2.78G/4.98G [00:09<00:07, 290MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  57%|██▊  | 2.82G/4.98G [00:09<00:07, 308MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  58%|██▉  | 2.86G/4.98G [00:09<00:06, 310MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  58%|██▉  | 2.90G/4.98G [00:09<00:06, 321MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  59%|██▉  | 2.95G/4.98G [00:09<00:06, 308MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  60%|███  | 2.99G/4.98G [00:10<00:11, 180MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  61%|███  | 3.02G/4.98G [00:10<00:13, 149MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  61%|███  | 3.04G/4.98G [00:10<00:13, 141MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  62%|███  | 3.07G/4.98G [00:10<00:12, 151MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  62%|███  | 3.09G/4.98G [00:11<00:13, 140MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  63%|███▏ | 3.11G/4.98G [00:11<00:14, 127MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  63%|███▏ | 3.14G/4.98G [00:11<00:14, 123MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  63%|███▏ | 3.16G/4.98G [00:11<00:15, 114MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  64%|███▏ | 3.18G/4.98G [00:11<00:15, 118MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  64%|███▏ | 3.20G/4.98G [00:11<00:14, 127MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  65%|███▏ | 3.22G/4.98G [00:12<00:14, 122MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  65%|███▎ | 3.24G/4.98G [00:12<00:14, 121MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  66%|███▎ | 3.26G/4.98G [00:12<00:14, 118MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  66%|███▎ | 3.28G/4.98G [00:12<00:15, 107MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  66%|██▋ | 3.30G/4.98G [00:13<00:20, 81.0MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  67%|██▋ | 3.32G/4.98G [00:13<00:18, 88.0MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  67%|██▋ | 3.34G/4.98G [00:13<00:17, 91.4MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  68%|██▋ | 3.37G/4.98G [00:13<00:16, 96.9MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  68%|███▍ | 3.39G/4.98G [00:13<00:13, 114MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  68%|███▍ | 3.41G/4.98G [00:14<00:13, 113MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  69%|███▍ | 3.43G/4.98G [00:14<00:13, 114MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  69%|███▍ | 3.45G/4.98G [00:14<00:14, 108MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  70%|███▍ | 3.47G/4.98G [00:14<00:13, 109MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  70%|███▌ | 3.49G/4.98G [00:14<00:12, 117MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  71%|███▌ | 3.51G/4.98G [00:14<00:12, 115MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  71%|██▊ | 3.53G/4.98G [00:15<00:14, 99.4MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  71%|██▊ | 3.55G/4.98G [00:15<00:14, 99.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  72%|███▌ | 3.61G/4.98G [00:15<00:08, 167MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  73%|███▋ | 3.65G/4.98G [00:15<00:06, 209MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  74%|███▋ | 3.69G/4.98G [00:15<00:05, 243MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  75%|███▊ | 3.73G/4.98G [00:15<00:04, 272MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  76%|███▊ | 3.77G/4.98G [00:16<00:04, 296MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  77%|███▊ | 3.82G/4.98G [00:16<00:03, 311MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  78%|███▉ | 3.86G/4.98G [00:16<00:03, 322MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  78%|███▉ | 3.90G/4.98G [00:16<00:03, 333MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  79%|███▉ | 3.94G/4.98G [00:16<00:03, 343MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  80%|████ | 3.98G/4.98G [00:16<00:02, 346MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  81%|████ | 4.03G/4.98G [00:16<00:02, 352MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  82%|████ | 4.07G/4.98G [00:16<00:02, 344MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  83%|████▏| 4.11G/4.98G [00:17<00:05, 162MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  83%|████▏| 4.15G/4.98G [00:17<00:04, 198MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  84%|████▏| 4.19G/4.98G [00:17<00:03, 229MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  85%|████▎| 4.24G/4.98G [00:17<00:02, 253MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  86%|████▎| 4.28G/4.98G [00:17<00:02, 251MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  87%|████▎| 4.32G/4.98G [00:18<00:02, 279MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  88%|████▍| 4.36G/4.98G [00:18<00:02, 293MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  88%|████▍| 4.40G/4.98G [00:18<00:02, 276MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  89%|████▍| 4.44G/4.98G [00:18<00:02, 261MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  90%|████▌| 4.49G/4.98G [00:18<00:01, 301MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  91%|████▌| 4.53G/4.98G [00:18<00:01, 316MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  92%|████▌| 4.57G/4.98G [00:18<00:01, 327MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  93%|████▋| 4.61G/4.98G [00:19<00:01, 329MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  94%|████▋| 4.66G/4.98G [00:19<00:00, 338MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  94%|████▋| 4.70G/4.98G [00:19<00:00, 346MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  95%|████▊| 4.74G/4.98G [00:19<00:00, 353MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  96%|████▊| 4.78G/4.98G [00:19<00:00, 352MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  97%|████▊| 4.82G/4.98G [00:19<00:00, 352MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  98%|████▉| 4.87G/4.98G [00:19<00:00, 353MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  99%|████▉| 4.91G/4.98G [00:20<00:00, 210MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors: 100%|█████| 4.98G/4.98G [00:20<00:00, 245MB/s]\u001b[A\n",
            "Downloading shards:  25%|██████▎                  | 1/4 [00:20<01:01, 20.38s/it]\n",
            "model-00002-of-00004.safetensors:   0%|             | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   1%|     | 41.9M/5.00G [00:00<00:12, 395MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   2%|     | 83.9M/5.00G [00:00<00:12, 389MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   3%|▏     | 126M/5.00G [00:00<00:12, 380MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   3%|▏     | 168M/5.00G [00:00<00:12, 382MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   4%|▎     | 210M/5.00G [00:00<00:12, 382MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   5%|▎     | 252M/5.00G [00:00<00:12, 385MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   6%|▎     | 294M/5.00G [00:00<00:12, 386MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   7%|▍     | 336M/5.00G [00:00<00:12, 384MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   8%|▍     | 377M/5.00G [00:01<00:12, 357MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   9%|▌     | 430M/5.00G [00:01<00:12, 375MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:   9%|▌     | 472M/5.00G [00:01<00:12, 377MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  10%|▌     | 514M/5.00G [00:01<00:11, 380MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  11%|▋     | 556M/5.00G [00:01<00:11, 382MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  12%|▋     | 598M/5.00G [00:01<00:12, 345MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  13%|▊     | 640M/5.00G [00:02<00:23, 182MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  14%|▊     | 692M/5.00G [00:02<00:18, 229MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  15%|▉     | 734M/5.00G [00:02<00:17, 249MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  16%|▉     | 776M/5.00G [00:02<00:19, 221MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  16%|▉     | 818M/5.00G [00:02<00:16, 257MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  17%|█     | 860M/5.00G [00:02<00:14, 285MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  18%|█     | 902M/5.00G [00:02<00:13, 301MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  19%|█▏    | 944M/5.00G [00:03<00:12, 317MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  20%|█▏    | 986M/5.00G [00:03<00:12, 334MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  21%|█    | 1.03G/5.00G [00:03<00:11, 346MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  21%|█    | 1.07G/5.00G [00:03<00:11, 356MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  22%|█    | 1.11G/5.00G [00:03<00:10, 363MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  23%|█▏   | 1.15G/5.00G [00:03<00:10, 360MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  24%|█▏   | 1.20G/5.00G [00:03<00:10, 359MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  25%|█▏   | 1.24G/5.00G [00:03<00:10, 371MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  26%|█▎   | 1.28G/5.00G [00:03<00:09, 375MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  26%|█▎   | 1.32G/5.00G [00:04<00:10, 361MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  27%|█▎   | 1.36G/5.00G [00:04<00:10, 360MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  28%|█▍   | 1.41G/5.00G [00:04<00:09, 364MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  29%|█▍   | 1.45G/5.00G [00:04<00:09, 372MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  30%|█▍   | 1.49G/5.00G [00:04<00:10, 342MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  31%|█▌   | 1.53G/5.00G [00:04<00:10, 321MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  32%|█▌   | 1.58G/5.00G [00:04<00:09, 347MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  33%|█▋   | 1.63G/5.00G [00:04<00:10, 334MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  33%|█▋   | 1.67G/5.00G [00:05<00:09, 347MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  34%|█▋   | 1.71G/5.00G [00:05<00:09, 358MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  35%|█▊   | 1.75G/5.00G [00:05<00:08, 366MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  36%|█▊   | 1.79G/5.00G [00:05<00:08, 372MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  37%|█▊   | 1.84G/5.00G [00:05<00:08, 377MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  38%|█▉   | 1.88G/5.00G [00:05<00:08, 381MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  38%|█▉   | 1.92G/5.00G [00:05<00:08, 378MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  39%|█▉   | 1.96G/5.00G [00:05<00:08, 379MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  40%|██   | 2.00G/5.00G [00:05<00:07, 382MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  41%|██   | 2.04G/5.00G [00:06<00:07, 381MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  42%|██   | 2.09G/5.00G [00:06<00:07, 383MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  43%|██▏  | 2.13G/5.00G [00:06<00:09, 287MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  43%|██▏  | 2.17G/5.00G [00:06<00:11, 244MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  44%|██▏  | 2.20G/5.00G [00:06<00:10, 257MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  45%|██▏  | 2.23G/5.00G [00:07<00:19, 142MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  45%|██▎  | 2.26G/5.00G [00:07<00:16, 164MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  46%|██▎  | 2.32G/5.00G [00:07<00:12, 216MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  47%|██▎  | 2.36G/5.00G [00:07<00:10, 250MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  48%|██▍  | 2.40G/5.00G [00:07<00:09, 280MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  49%|██▍  | 2.44G/5.00G [00:07<00:08, 306MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  50%|██▍  | 2.49G/5.00G [00:07<00:07, 327MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  51%|██▌  | 2.53G/5.00G [00:07<00:07, 341MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  51%|██▌  | 2.57G/5.00G [00:08<00:06, 354MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  52%|██▌  | 2.61G/5.00G [00:08<00:06, 357MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  53%|██▋  | 2.65G/5.00G [00:08<00:09, 236MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  54%|██▋  | 2.68G/5.00G [00:08<00:11, 209MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  55%|██▋  | 2.74G/5.00G [00:08<00:08, 262MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  56%|██▊  | 2.78G/5.00G [00:08<00:07, 281MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  56%|██▊  | 2.82G/5.00G [00:09<00:07, 305MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  57%|██▊  | 2.86G/5.00G [00:09<00:06, 313MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  58%|██▉  | 2.90G/5.00G [00:09<00:06, 329MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  59%|██▉  | 2.95G/5.00G [00:09<00:06, 328MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  60%|██▉  | 2.99G/5.00G [00:09<00:05, 341MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  61%|███  | 3.04G/5.00G [00:09<00:05, 376MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  62%|███  | 3.08G/5.00G [00:09<00:05, 379MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  62%|███  | 3.12G/5.00G [00:09<00:05, 364MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  63%|███▏ | 3.17G/5.00G [00:10<00:04, 369MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  64%|███▏ | 3.21G/5.00G [00:10<00:08, 221MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  65%|███▏ | 3.24G/5.00G [00:10<00:09, 192MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  65%|███▎ | 3.27G/5.00G [00:10<00:10, 168MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  66%|███▎ | 3.30G/5.00G [00:11<00:10, 156MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  66%|███▎ | 3.32G/5.00G [00:11<00:10, 154MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  67%|███▎ | 3.34G/5.00G [00:11<00:11, 149MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  67%|███▎ | 3.37G/5.00G [00:11<00:12, 136MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  68%|███▍ | 3.39G/5.00G [00:11<00:13, 123MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  68%|███▍ | 3.41G/5.00G [00:12<00:14, 108MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  69%|███▍ | 3.43G/5.00G [00:12<00:12, 122MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  69%|███▍ | 3.45G/5.00G [00:12<00:13, 114MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  69%|███▍ | 3.47G/5.00G [00:12<00:13, 113MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  70%|███▍ | 3.49G/5.00G [00:12<00:12, 123MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  70%|███▌ | 3.51G/5.00G [00:12<00:11, 132MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  71%|███▌ | 3.53G/5.00G [00:13<00:11, 127MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  71%|███▌ | 3.55G/5.00G [00:13<00:12, 119MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  72%|███▌ | 3.58G/5.00G [00:13<00:12, 113MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  72%|███▌ | 3.60G/5.00G [00:13<00:12, 115MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  72%|███▌ | 3.62G/5.00G [00:13<00:12, 111MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  73%|███▋ | 3.65G/5.00G [00:13<00:09, 137MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  73%|███▋ | 3.67G/5.00G [00:14<00:08, 150MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  74%|███▋ | 3.69G/5.00G [00:14<00:08, 155MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  74%|███▋ | 3.71G/5.00G [00:14<00:09, 142MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  75%|███▋ | 3.73G/5.00G [00:14<00:08, 150MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  75%|███▊ | 3.75G/5.00G [00:14<00:09, 135MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  76%|███▊ | 3.77G/5.00G [00:14<00:09, 128MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  76%|███▊ | 3.80G/5.00G [00:15<00:09, 121MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  76%|███▊ | 3.82G/5.00G [00:15<00:09, 122MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  77%|███▊ | 3.84G/5.00G [00:15<00:10, 116MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  77%|███▊ | 3.86G/5.00G [00:15<00:10, 113MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  78%|███▉ | 3.88G/5.00G [00:15<00:08, 130MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  78%|███▉ | 3.90G/5.00G [00:15<00:08, 130MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  79%|███▉ | 3.94G/5.00G [00:16<00:05, 180MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  80%|███▉ | 3.98G/5.00G [00:16<00:04, 229MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  80%|████ | 4.02G/5.00G [00:16<00:04, 201MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  81%|████ | 4.05G/5.00G [00:16<00:08, 108MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  82%|████ | 4.09G/5.00G [00:17<00:06, 145MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  83%|████▏| 4.13G/5.00G [00:17<00:04, 185MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  83%|████▏| 4.17G/5.00G [00:17<00:03, 223MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  84%|████▏| 4.22G/5.00G [00:17<00:03, 249MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  85%|████▎| 4.26G/5.00G [00:18<00:05, 128MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  86%|████▎| 4.30G/5.00G [00:18<00:04, 160MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  87%|████▎| 4.34G/5.00G [00:18<00:03, 192MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  88%|████▍| 4.38G/5.00G [00:18<00:02, 227MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  89%|████▍| 4.42G/5.00G [00:18<00:02, 259MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  89%|████▍| 4.47G/5.00G [00:18<00:01, 288MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  90%|████▌| 4.51G/5.00G [00:18<00:01, 311MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  91%|████▌| 4.55G/5.00G [00:18<00:01, 331MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  92%|████▌| 4.59G/5.00G [00:18<00:01, 346MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  93%|████▋| 4.63G/5.00G [00:19<00:01, 357MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  94%|████▋| 4.68G/5.00G [00:19<00:00, 351MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  94%|████▋| 4.72G/5.00G [00:19<00:00, 347MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  95%|████▊| 4.77G/5.00G [00:19<00:00, 380MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  96%|████▊| 4.81G/5.00G [00:19<00:00, 381MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  97%|████▊| 4.85G/5.00G [00:19<00:00, 382MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  98%|████▉| 4.90G/5.00G [00:19<00:00, 381MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors:  99%|████▉| 4.94G/5.00G [00:19<00:00, 380MB/s]\u001b[A\n",
            "model-00002-of-00004.safetensors: 100%|█████| 5.00G/5.00G [00:20<00:00, 249MB/s]\u001b[A\n",
            "Downloading shards:  50%|████████████▌            | 2/4 [00:40<00:40, 20.24s/it]\n",
            "model-00003-of-00004.safetensors:   0%|             | 0.00/4.92G [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   0%|     | 21.0M/4.92G [00:00<00:29, 168MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   1%|     | 52.4M/4.92G [00:00<00:21, 224MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   2%|     | 94.4M/4.92G [00:00<00:16, 284MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   3%|▏     | 136M/4.92G [00:00<00:14, 320MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   4%|▏     | 178M/4.92G [00:00<00:13, 344MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   4%|▎     | 220M/4.92G [00:00<00:13, 351MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   5%|▎     | 262M/4.92G [00:00<00:12, 368MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   6%|▎     | 304M/4.92G [00:00<00:12, 374MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   7%|▍     | 346M/4.92G [00:01<00:12, 377MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   8%|▍     | 388M/4.92G [00:01<00:11, 380MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:   9%|▌     | 430M/4.92G [00:01<00:11, 380MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  10%|▌     | 472M/4.92G [00:01<00:11, 382MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  10%|▋     | 514M/4.92G [00:01<00:18, 239MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  11%|▋     | 556M/4.92G [00:01<00:16, 270MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  12%|▋     | 598M/4.92G [00:01<00:15, 285MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  13%|▊     | 640M/4.92G [00:02<00:34, 124MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  14%|▊     | 692M/4.92G [00:02<00:25, 168MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  15%|▉     | 734M/4.92G [00:02<00:20, 200MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  16%|▉     | 776M/4.92G [00:03<00:17, 230MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  17%|▉     | 818M/4.92G [00:03<00:16, 253MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  17%|█     | 860M/4.92G [00:03<00:14, 281MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  18%|█     | 902M/4.92G [00:03<00:13, 304MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  19%|█▏    | 944M/4.92G [00:03<00:12, 325MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  20%|█▏    | 986M/4.92G [00:03<00:11, 338MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  21%|█    | 1.03G/4.92G [00:03<00:11, 347MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  22%|█    | 1.07G/4.92G [00:03<00:16, 240MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  22%|█    | 1.10G/4.92G [00:04<00:17, 217MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  23%|█▏   | 1.15G/4.92G [00:04<00:13, 271MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  24%|█▏   | 1.20G/4.92G [00:04<00:12, 296MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  25%|█▎   | 1.24G/4.92G [00:04<00:11, 317MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  26%|█▎   | 1.28G/4.92G [00:04<00:10, 335MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  27%|█▎   | 1.32G/4.92G [00:04<00:10, 348MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  28%|█▍   | 1.36G/4.92G [00:04<00:10, 348MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  29%|█▍   | 1.41G/4.92G [00:04<00:09, 357MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  29%|█▍   | 1.45G/4.92G [00:05<00:09, 365MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  30%|█▌   | 1.49G/4.92G [00:05<00:09, 371MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  31%|█▌   | 1.53G/4.92G [00:05<00:09, 371MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  32%|█▌   | 1.57G/4.92G [00:05<00:08, 376MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  33%|█▋   | 1.61G/4.92G [00:05<00:08, 378MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  34%|█▋   | 1.66G/4.92G [00:05<00:08, 374MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  35%|█▋   | 1.70G/4.92G [00:05<00:08, 372MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  35%|█▊   | 1.74G/4.92G [00:05<00:09, 344MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  36%|█▊   | 1.79G/4.92G [00:06<00:08, 376MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  37%|█▊   | 1.84G/4.92G [00:06<00:08, 375MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  38%|█▉   | 1.88G/4.92G [00:06<00:08, 362MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  39%|█▉   | 1.92G/4.92G [00:06<00:08, 372MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  40%|█▉   | 1.96G/4.92G [00:07<00:24, 121MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  41%|██   | 1.99G/4.92G [00:07<00:27, 106MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  42%|██   | 2.04G/4.92G [00:07<00:19, 147MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  42%|██   | 2.09G/4.92G [00:07<00:15, 180MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  43%|██▏  | 2.13G/4.92G [00:07<00:13, 213MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  44%|██▏  | 2.17G/4.92G [00:08<00:11, 245MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  45%|██▎  | 2.21G/4.92G [00:08<00:10, 249MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  46%|██▎  | 2.25G/4.92G [00:08<00:10, 259MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  46%|██▎  | 2.29G/4.92G [00:08<00:09, 264MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  47%|██▎  | 2.32G/4.92G [00:08<00:09, 269MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  48%|██▍  | 2.35G/4.92G [00:08<00:09, 278MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  48%|██▍  | 2.38G/4.92G [00:08<00:08, 282MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  49%|██▍  | 2.41G/4.92G [00:08<00:08, 286MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  50%|██▍  | 2.44G/4.92G [00:09<00:08, 275MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  51%|██▌  | 2.49G/4.92G [00:09<00:08, 299MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  51%|██▌  | 2.53G/4.92G [00:09<00:07, 306MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  52%|██▌  | 2.56G/4.92G [00:09<00:07, 307MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  53%|██▋  | 2.59G/4.92G [00:09<00:07, 308MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  54%|██▋  | 2.63G/4.92G [00:09<00:07, 310MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  54%|██▋  | 2.67G/4.92G [00:09<00:07, 314MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  55%|██▊  | 2.72G/4.92G [00:09<00:06, 316MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  56%|██▊  | 2.76G/4.92G [00:10<00:07, 301MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  57%|██▊  | 2.79G/4.92G [00:10<00:11, 192MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  57%|██▎ | 2.82G/4.92G [00:11<00:29, 70.9MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  58%|██▎ | 2.86G/4.92G [00:11<00:21, 96.4MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  59%|██▉  | 2.90G/4.92G [00:11<00:16, 125MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  60%|██▉  | 2.94G/4.92G [00:12<00:13, 143MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  60%|███  | 2.97G/4.92G [00:12<00:13, 145MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  61%|███  | 3.00G/4.92G [00:12<00:12, 156MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  62%|███  | 3.03G/4.92G [00:12<00:11, 167MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  62%|███  | 3.07G/4.92G [00:12<00:08, 208MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  63%|███▏ | 3.11G/4.92G [00:12<00:07, 241MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  64%|███▏ | 3.15G/4.92G [00:12<00:07, 228MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  65%|███▏ | 3.18G/4.92G [00:13<00:09, 192MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  65%|███▎ | 3.21G/4.92G [00:13<00:12, 137MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  66%|███▎ | 3.25G/4.92G [00:13<00:09, 175MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  67%|███▎ | 3.28G/4.92G [00:13<00:08, 183MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  68%|███▍ | 3.32G/4.92G [00:13<00:07, 205MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  68%|███▍ | 3.36G/4.92G [00:14<00:09, 170MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  69%|███▍ | 3.38G/4.92G [00:14<00:09, 156MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  69%|███▍ | 3.40G/4.92G [00:14<00:09, 162MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  70%|███▍ | 3.44G/4.92G [00:14<00:07, 203MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  71%|███▌ | 3.48G/4.92G [00:14<00:06, 239MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  71%|███▌ | 3.51G/4.92G [00:15<00:07, 182MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  72%|███▌ | 3.54G/4.92G [00:15<00:09, 140MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  73%|███▋ | 3.57G/4.92G [00:15<00:09, 142MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  73%|███▋ | 3.59G/4.92G [00:15<00:10, 122MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  73%|███▋ | 3.61G/4.92G [00:16<00:11, 113MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  74%|███▋ | 3.65G/4.92G [00:16<00:07, 162MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  75%|███▊ | 3.69G/4.92G [00:16<00:05, 206MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  76%|███▊ | 3.73G/4.92G [00:16<00:04, 239MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  77%|███▊ | 3.77G/4.92G [00:16<00:04, 266MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  77%|███▊ | 3.81G/4.92G [00:16<00:04, 275MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  78%|███▉ | 3.84G/4.92G [00:16<00:04, 248MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  79%|███▉ | 3.89G/4.92G [00:16<00:03, 299MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  80%|███▉ | 3.93G/4.92G [00:17<00:03, 276MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  81%|████ | 3.98G/4.92G [00:17<00:03, 309MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  82%|████ | 4.03G/4.92G [00:17<00:02, 320MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  83%|████▏| 4.07G/4.92G [00:17<00:02, 333MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  84%|████▏| 4.11G/4.92G [00:17<00:02, 346MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  84%|████▏| 4.15G/4.92G [00:17<00:02, 349MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  85%|████▎| 4.19G/4.92G [00:17<00:02, 241MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  86%|████▎| 4.23G/4.92G [00:18<00:02, 249MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  87%|████▎| 4.26G/4.92G [00:18<00:02, 236MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  87%|████▎| 4.30G/4.92G [00:18<00:02, 273MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  88%|████▍| 4.34G/4.92G [00:18<00:01, 306MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  89%|████▍| 4.38G/4.92G [00:18<00:01, 327MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  90%|████▌| 4.42G/4.92G [00:18<00:01, 334MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  91%|████▌| 4.47G/4.92G [00:19<00:02, 199MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  92%|████▌| 4.50G/4.92G [00:19<00:03, 137MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  92%|████▌| 4.54G/4.92G [00:19<00:02, 168MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  93%|████▋| 4.57G/4.92G [00:19<00:02, 151MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  93%|████▋| 4.59G/4.92G [00:20<00:02, 152MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  94%|████▋| 4.63G/4.92G [00:20<00:01, 195MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  95%|████▊| 4.69G/4.92G [00:20<00:00, 249MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  96%|████▊| 4.73G/4.92G [00:20<00:00, 280MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  97%|████▊| 4.77G/4.92G [00:20<00:00, 303MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  98%|████▉| 4.81G/4.92G [00:20<00:00, 248MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors:  99%|████▉| 4.84G/4.92G [00:20<00:00, 255MB/s]\u001b[A\n",
            "model-00003-of-00004.safetensors: 100%|█████| 4.92G/4.92G [00:21<00:00, 234MB/s]\u001b[A\n",
            "Downloading shards:  75%|██████████████████▊      | 3/4 [01:01<00:20, 20.65s/it]\n",
            "model-00004-of-00004.safetensors:   0%|             | 0.00/1.17G [00:00<?, ?B/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   3%|▏    | 31.5M/1.17G [00:00<00:05, 223MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   5%|▎    | 62.9M/1.17G [00:00<00:04, 242MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:   9%|▌     | 105M/1.17G [00:00<00:03, 303MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  13%|▊     | 157M/1.17G [00:00<00:02, 344MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  17%|█     | 199M/1.17G [00:00<00:02, 360MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  21%|█▏    | 241M/1.17G [00:00<00:02, 363MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  24%|█▍    | 283M/1.17G [00:00<00:02, 368MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  28%|█▋    | 325M/1.17G [00:00<00:02, 371MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  31%|█▉    | 367M/1.17G [00:01<00:02, 375MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  35%|██    | 409M/1.17G [00:01<00:02, 374MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  39%|██▎   | 451M/1.17G [00:01<00:01, 375MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  42%|██▌   | 493M/1.17G [00:01<00:01, 373MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  46%|██▋   | 535M/1.17G [00:01<00:01, 374MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  49%|██▉   | 577M/1.17G [00:01<00:01, 368MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  53%|███▏  | 619M/1.17G [00:01<00:01, 373MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  57%|███▍  | 661M/1.17G [00:01<00:01, 374MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  60%|███▌  | 703M/1.17G [00:01<00:01, 374MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  64%|███▊  | 744M/1.17G [00:02<00:01, 369MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  67%|████  | 786M/1.17G [00:02<00:02, 184MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  70%|████▏ | 818M/1.17G [00:02<00:02, 168MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  75%|████▍ | 870M/1.17G [00:02<00:01, 222MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  78%|████▋ | 912M/1.17G [00:03<00:01, 254MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  82%|████▉ | 954M/1.17G [00:03<00:00, 280MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  85%|█████ | 996M/1.17G [00:03<00:00, 303MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  89%|████▍| 1.04G/1.17G [00:03<00:00, 323MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  92%|████▌| 1.08G/1.17G [00:03<00:00, 255MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors:  95%|████▊| 1.11G/1.17G [00:03<00:00, 191MB/s]\u001b[A\n",
            "model-00004-of-00004.safetensors: 100%|█████| 1.17G/1.17G [00:04<00:00, 291MB/s]\u001b[A\n",
            "Downloading shards: 100%|█████████████████████████| 4/4 [01:05<00:00, 16.44s/it]\n",
            "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:22<00:00,  5.53s/it]\n",
            "generation_config.json: 100%|███████████████████| 185/185 [00:00<00:00, 947kB/s]\n",
            "2024-08-24:10:50:34,380 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-24:10:50:34,380 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,380 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-24:10:50:34,380 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,380 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-24:10:50:34,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-24:10:50:34,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-24:10:50:34,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-24:10:50:34,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-24:10:50:34,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-24:10:50:34,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-24:10:50:34,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-24:10:50:34,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-24:10:50:34,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-24:10:50:34,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-24:10:50:34,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-24:10:50:34,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,381 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-24:10:50:34,381 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-24:10:50:34,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-24:10:50:34,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-24:10:50:34,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-24:10:50:34,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-24:10:50:34,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-24:10:50:34,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-24:10:50:34,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-24:10:50:34,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-24:10:50:34,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-24:10:50:34,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-24:10:50:34,382 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,382 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-24:10:50:34,383 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,383 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-24:10:50:34,383 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,383 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-24:10:50:34,383 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,383 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-24:10:50:34,383 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,383 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-24:10:50:34,383 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,383 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-24:10:50:34,383 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,383 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-24:10:50:34,383 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,383 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-24:10:50:34,383 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,383 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-24:10:50:34,383 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,383 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-24:10:50:34,383 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,383 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-24:10:50:34,383 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,383 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-24:10:50:34,383 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,383 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-24:10:50:34,383 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,384 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-24:10:50:34,384 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,384 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-24:10:50:34,384 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,384 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-24:10:50:34,384 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,384 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-24:10:50:34,384 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,384 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-24:10:50:34,384 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,384 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-24:10:50:34,384 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,384 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-24:10:50:34,384 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,384 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-24:10:50:34,384 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,384 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-24:10:50:34,384 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,384 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-24:10:50:34,384 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,384 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-24:10:50:34,384 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,384 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-24:10:50:34,385 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,385 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-24:10:50:34,385 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,385 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-24:10:50:34,385 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,385 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-24:10:50:34,385 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,385 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-24:10:50:34,385 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,385 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-24:10:50:34,385 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,385 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-24:10:50:34,385 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,385 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-24:10:50:34,385 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,385 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-24:10:50:34,385 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:10:50:34,385 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-24:10:50:34,394 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 522.87it/s]\n",
            "2024-08-24:10:50:34,591 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 542.09it/s]\n",
            "2024-08-24:10:50:34,847 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 535.64it/s]\n",
            "2024-08-24:10:50:35,139 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 544.28it/s]\n",
            "2024-08-24:10:50:35,412 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 550.61it/s]\n",
            "2024-08-24:10:50:35,599 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 540.63it/s]\n",
            "2024-08-24:10:50:35,789 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 544.99it/s]\n",
            "2024-08-24:10:50:35,979 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 545.57it/s]\n",
            "2024-08-24:10:50:36,171 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 546.51it/s]\n",
            "2024-08-24:10:50:36,359 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 542.52it/s]\n",
            "2024-08-24:10:50:36,804 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 543.88it/s]\n",
            "2024-08-24:10:50:37,078 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 553.23it/s]\n",
            "2024-08-24:10:50:37,780 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 547.59it/s]\n",
            "2024-08-24:10:50:38,361 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 544.42it/s]\n",
            "2024-08-24:10:50:38,745 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 553.88it/s]\n",
            "2024-08-24:10:50:38,931 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 552.43it/s]\n",
            "2024-08-24:10:50:39,433 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 597.58it/s]\n",
            "2024-08-24:10:50:39,693 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 711.72it/s]\n",
            "2024-08-24:10:50:40,005 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 706.85it/s]\n",
            "2024-08-24:10:50:40,168 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 691.65it/s]\n",
            "2024-08-24:10:50:40,317 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 720.50it/s]\n",
            "2024-08-24:10:50:40,695 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 704.36it/s]\n",
            "2024-08-24:10:50:40,948 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 705.25it/s]\n",
            "2024-08-24:10:50:41,094 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 706.51it/s]\n",
            "2024-08-24:10:50:41,420 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 715.76it/s]\n",
            "2024-08-24:10:50:41,569 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 496.80it/s]\n",
            "2024-08-24:10:50:42,049 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 699.65it/s]\n",
            "2024-08-24:10:50:42,196 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 714.30it/s]\n",
            "2024-08-24:10:50:43,322 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 713.25it/s]\n",
            "2024-08-24:10:50:43,763 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 712.75it/s]\n",
            "2024-08-24:10:50:44,170 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 704.06it/s]\n",
            "2024-08-24:10:50:44,567 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 711.28it/s]\n",
            "2024-08-24:10:50:44,807 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 704.32it/s]\n",
            "2024-08-24:10:50:44,974 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 702.38it/s]\n",
            "2024-08-24:10:50:45,264 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 701.66it/s]\n",
            "2024-08-24:10:50:45,547 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 711.86it/s]\n",
            "2024-08-24:10:50:46,110 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 701.49it/s]\n",
            "2024-08-24:10:50:46,459 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 708.00it/s]\n",
            "2024-08-24:10:50:47,250 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 710.67it/s]\n",
            "2024-08-24:10:50:47,440 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 717.25it/s]\n",
            "2024-08-24:10:50:48,316 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 705.92it/s]\n",
            "2024-08-24:10:50:48,476 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 718.10it/s]\n",
            "2024-08-24:10:50:48,827 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 706.54it/s]\n",
            "2024-08-24:10:50:49,119 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 682.18it/s]\n",
            "2024-08-24:10:50:49,270 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 703.39it/s]\n",
            "2024-08-24:10:50:49,455 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 716.80it/s]\n",
            "2024-08-24:10:50:49,692 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 715.88it/s]\n",
            "2024-08-24:10:50:49,985 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 698.49it/s]\n",
            "2024-08-24:10:50:50,334 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 705.51it/s]\n",
            "2024-08-24:10:50:50,511 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 707.06it/s]\n",
            "2024-08-24:10:50:50,668 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 706.24it/s]\n",
            "2024-08-24:10:50:50,905 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 704.88it/s]\n",
            "2024-08-24:10:50:51,410 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 620.46it/s]\n",
            "2024-08-24:10:50:52,886 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 719.53it/s]\n",
            "2024-08-24:10:50:53,331 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 712.59it/s]\n",
            "2024-08-24:10:50:53,798 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 710.56it/s]\n",
            "2024-08-24:10:50:56,015 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 713.42it/s]\n",
            "2024-08-24:10:50:56,261 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 16711.04it/s]\n",
            "2024-08-24:10:50:57,775 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1403.85it/s]\n",
            "2024-08-24:10:50:58,668 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
            "Running loglikelihood requests: 100%|██| 174850/174850 [15:05<00:00, 193.07it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-24:11:07:55,628 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=meta-llama/Meta-Llama-3.1-8B,dtype=float16), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.5119|±  |0.0146|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.5350|±  |0.0146|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.3288|±  |0.0043|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.6361|±  |0.0038|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5768|±  |0.0067|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.4048|±  |0.0439|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7455|±  |0.0340|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.8235|±  |0.0268|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.8270|±  |0.0246|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.8182|±  |0.0352|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.7222|±  |0.0433|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7730|±  |0.0329|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.7139|±  |0.0243|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2950|±  |0.0153|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.7010|±  |0.0260|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.7438|±  |0.0243|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4948|±  |0.0128|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.8421|±  |0.0280|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.7084|±  |0.0078|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.6200|±  |0.0488|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.7283|±  |0.0274|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.6358|±  |0.0367|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.2900|±  |0.0456|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.6502|±  |0.0320|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.8350|±  |0.0368|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8718|±  |0.0219|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.8300|±  |0.0378|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.8199|±  |0.0137|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.7614|±  |0.0244|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.4610|±  |0.0297|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.7206|±  |0.0273|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5301|±  |0.0389|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.7410|±  |0.0077|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.4649|±  |0.0469|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.7677|±  |0.0301|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8549|±  |0.0254|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.6436|±  |0.0243|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.7101|±  |0.0295|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.8349|±  |0.0159|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.7863|±  |0.0360|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.6895|±  |0.0187|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6727|±  |0.0449|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.7347|±  |0.0283|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.8408|±  |0.0259|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.8700|±  |0.0338|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5509|±  |0.0086|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3700|±  |0.0485|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.6593|±  |0.0409|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.7171|±  |0.0367|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.7708|±  |0.0351|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4500|±  |0.0500|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.5500|±  |0.0500|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.4300|±  |0.0498|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.4020|±  |0.0488|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.7900|±  |0.0409|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5362|±  |0.0326|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.5862|±  |0.0410|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4365|±  |0.0255|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7677|±  |0.0240|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.5468|±  |0.0350|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.6500|±  |0.0479|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.4111|±  |0.0300|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.4238|±  |0.0403|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.5417|±  |0.0340|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.4107|±  |0.0467|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.6361|±  |0.0038|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5768|±  |0.0067|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.7084|±  |0.0078|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.7410|±  |0.0077|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5509|±  |0.0086|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=meta-llama/Meta-Llama-3.1-8B,dtype=float16 --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b9e3b65-c735-4f98-ab6e-f31a3aea2973",
      "metadata": {
        "id": "2b9e3b65-c735-4f98-ab6e-f31a3aea2973",
        "outputId": "052f67d9-ee79-4b8e-a493-449c1a671bef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-24:11:08:01,372 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-24:11:08:01,476 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-24:11:08:16,263 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-24:11:08:16,265 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-24:11:08:16,265 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3.1-8B', 'load_in_8bit': True}\n",
            "2024-08-24:11:08:16,513 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-24:11:08:16,513 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "2024-08-24:11:08:17,078 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:18<00:00,  4.67s/it]\n",
            "2024-08-24:11:08:37,476 WARNING  [big_modeling.py:451] You shouldn't move a model that is dispatched using accelerate hooks.\n",
            "2024-08-24:11:09:13,756 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-24:11:09:13,756 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,756 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-24:11:09:13,756 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,756 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-24:11:09:13,756 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,756 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-24:11:09:13,756 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,756 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-24:11:09:13,756 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,756 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-24:11:09:13,756 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,756 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-24:11:09:13,757 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,757 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-24:11:09:13,757 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,757 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-24:11:09:13,757 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,757 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-24:11:09:13,757 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,757 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-24:11:09:13,757 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,757 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-24:11:09:13,757 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,757 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-24:11:09:13,757 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,757 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-24:11:09:13,757 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,757 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-24:11:09:13,757 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,757 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-24:11:09:13,757 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,757 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-24:11:09:13,757 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,757 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-24:11:09:13,757 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,757 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-24:11:09:13,758 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,758 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-24:11:09:13,758 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,758 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-24:11:09:13,758 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,758 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-24:11:09:13,758 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,758 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-24:11:09:13,758 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,758 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-24:11:09:13,758 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,758 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-24:11:09:13,758 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,758 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-24:11:09:13,758 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,758 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-24:11:09:13,758 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,758 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-24:11:09:13,758 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,758 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-24:11:09:13,758 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,758 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-24:11:09:13,758 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,758 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-24:11:09:13,759 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,759 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-24:11:09:13,759 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,759 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-24:11:09:13,759 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,759 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-24:11:09:13,759 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,759 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-24:11:09:13,759 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,759 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-24:11:09:13,759 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,759 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-24:11:09:13,759 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,759 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-24:11:09:13,759 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,759 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-24:11:09:13,759 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,759 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-24:11:09:13,759 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,759 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-24:11:09:13,759 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,759 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-24:11:09:13,759 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,759 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-24:11:09:13,760 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,760 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-24:11:09:13,760 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,760 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-24:11:09:13,760 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,760 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-24:11:09:13,760 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,760 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-24:11:09:13,760 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,760 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-24:11:09:13,760 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,760 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-24:11:09:13,760 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,760 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-24:11:09:13,760 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,760 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-24:11:09:13,760 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,760 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-24:11:09:13,760 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,760 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-24:11:09:13,760 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,760 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-24:11:09:13,760 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,760 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-24:11:09:13,761 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,761 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-24:11:09:13,761 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,761 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-24:11:09:13,761 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,761 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-24:11:09:13,761 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,761 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-24:11:09:13,761 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:09:13,761 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-24:11:09:13,770 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 576.97it/s]\n",
            "2024-08-24:11:09:13,948 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 579.49it/s]\n",
            "2024-08-24:11:09:14,188 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 580.74it/s]\n",
            "2024-08-24:11:09:14,458 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 581.75it/s]\n",
            "2024-08-24:11:09:14,714 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 581.74it/s]\n",
            "2024-08-24:11:09:14,891 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 581.32it/s]\n",
            "2024-08-24:11:09:15,068 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 584.36it/s]\n",
            "2024-08-24:11:09:15,244 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 580.47it/s]\n",
            "2024-08-24:11:09:15,425 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 583.43it/s]\n",
            "2024-08-24:11:09:15,601 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 584.24it/s]\n",
            "2024-08-24:11:09:16,015 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 580.43it/s]\n",
            "2024-08-24:11:09:16,272 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 581.43it/s]\n",
            "2024-08-24:11:09:16,941 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 584.01it/s]\n",
            "2024-08-24:11:09:17,486 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 578.99it/s]\n",
            "2024-08-24:11:09:17,847 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 581.75it/s]\n",
            "2024-08-24:11:09:18,024 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 584.29it/s]\n",
            "2024-08-24:11:09:18,499 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 593.17it/s]\n",
            "2024-08-24:11:09:18,761 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 703.60it/s]\n",
            "2024-08-24:11:09:19,077 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 701.85it/s]\n",
            "2024-08-24:11:09:19,241 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 702.08it/s]\n",
            "2024-08-24:11:09:19,388 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 703.60it/s]\n",
            "2024-08-24:11:09:19,775 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 706.32it/s]\n",
            "2024-08-24:11:09:20,027 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 705.79it/s]\n",
            "2024-08-24:11:09:20,173 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 709.26it/s]\n",
            "2024-08-24:11:09:20,496 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 705.04it/s]\n",
            "2024-08-24:11:09:20,647 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 703.76it/s]\n",
            "2024-08-24:11:09:20,989 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 702.29it/s]\n",
            "2024-08-24:11:09:21,135 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 616.49it/s]\n",
            "2024-08-24:11:09:22,436 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 706.90it/s]\n",
            "2024-08-24:11:09:22,881 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 705.84it/s]\n",
            "2024-08-24:11:09:23,292 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 707.14it/s]\n",
            "2024-08-24:11:09:23,688 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 706.09it/s]\n",
            "2024-08-24:11:09:23,930 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 706.51it/s]\n",
            "2024-08-24:11:09:24,096 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 697.81it/s]\n",
            "2024-08-24:11:09:24,388 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 703.26it/s]\n",
            "2024-08-24:11:09:24,670 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 707.21it/s]\n",
            "2024-08-24:11:09:25,236 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 706.92it/s]\n",
            "2024-08-24:11:09:25,583 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 706.02it/s]\n",
            "2024-08-24:11:09:26,376 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 708.77it/s]\n",
            "2024-08-24:11:09:26,566 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 705.04it/s]\n",
            "2024-08-24:11:09:27,458 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 706.90it/s]\n",
            "2024-08-24:11:09:27,618 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 712.06it/s]\n",
            "2024-08-24:11:09:27,972 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 711.77it/s]\n",
            "2024-08-24:11:09:28,263 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 710.99it/s]\n",
            "2024-08-24:11:09:28,408 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 710.48it/s]\n",
            "2024-08-24:11:09:28,590 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 705.94it/s]\n",
            "2024-08-24:11:09:28,831 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 696.72it/s]\n",
            "2024-08-24:11:09:29,133 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 708.35it/s]\n",
            "2024-08-24:11:09:29,477 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 710.19it/s]\n",
            "2024-08-24:11:09:29,652 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 711.21it/s]\n",
            "2024-08-24:11:09:29,809 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 709.28it/s]\n",
            "2024-08-24:11:09:30,045 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 712.39it/s]\n",
            "2024-08-24:11:09:30,544 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 619.30it/s]\n",
            "2024-08-24:11:09:32,025 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 716.37it/s]\n",
            "2024-08-24:11:09:32,472 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 712.42it/s]\n",
            "2024-08-24:11:09:32,939 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 709.70it/s]\n",
            "2024-08-24:11:09:35,160 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 709.94it/s]\n",
            "2024-08-24:11:09:35,408 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 16587.28it/s]\n",
            "2024-08-24:11:09:36,941 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1392.77it/s]\n",
            "2024-08-24:11:09:37,843 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "Running loglikelihood requests: 100%|███| 174850/174850 [29:36<00:00, 98.40it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-24:11:41:06,930 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=meta-llama/Meta-Llama-3.1-8B,load_in_8bit=True), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.5094|±  |0.0146|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.5384|±  |0.0146|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.3207|±  |0.0043|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.6292|±  |0.0038|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5683|±  |0.0067|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.4365|±  |0.0444|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7394|±  |0.0343|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.8186|±  |0.0270|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.8270|±  |0.0246|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.8099|±  |0.0358|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.7500|±  |0.0419|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7485|±  |0.0341|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.7052|±  |0.0245|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2838|±  |0.0151|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.6977|±  |0.0261|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.7222|±  |0.0249|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4857|±  |0.0128|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.8129|±  |0.0299|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.7055|±  |0.0078|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.6300|±  |0.0485|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.7132|±  |0.0278|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.6301|±  |0.0368|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.3100|±  |0.0465|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.6547|±  |0.0319|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.8155|±  |0.0384|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8675|±  |0.0222|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.7800|±  |0.0416|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.8097|±  |0.0140|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.7712|±  |0.0241|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.4752|±  |0.0298|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.7243|±  |0.0271|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5301|±  |0.0389|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.7394|±  |0.0077|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.4825|±  |0.0470|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.7677|±  |0.0301|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8808|±  |0.0234|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.6282|±  |0.0245|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.7143|±  |0.0293|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.8220|±  |0.0164|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.7710|±  |0.0369|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.6895|±  |0.0187|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6818|±  |0.0446|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.7265|±  |0.0285|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.8507|±  |0.0252|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.8800|±  |0.0327|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5373|±  |0.0086|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3700|±  |0.0485|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.6370|±  |0.0415|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.6776|±  |0.0380|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.8056|±  |0.0331|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4200|±  |0.0496|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.5200|±  |0.0502|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.4300|±  |0.0498|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.4216|±  |0.0491|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.8000|±  |0.0402|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5277|±  |0.0326|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.5517|±  |0.0414|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4233|±  |0.0254|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7516|±  |0.0246|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.5369|±  |0.0351|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.6000|±  |0.0492|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3815|±  |0.0296|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.4106|±  |0.0402|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.5370|±  |0.0340|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.4018|±  |0.0465|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.6292|±  |0.0038|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5683|±  |0.0067|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.7055|±  |0.0078|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.7394|±  |0.0077|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5373|±  |0.0086|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=meta-llama/Meta-Llama-3.1-8B,load_in_8bit=True --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9ed46f0-57ec-4d65-8dba-f6ddf74eef23",
      "metadata": {
        "id": "d9ed46f0-57ec-4d65-8dba-f6ddf74eef23",
        "outputId": "51612d94-7eb0-40fc-b180-b4e6783a20bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-24:11:41:12,578 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-24:11:41:12,691 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-24:11:41:26,137 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-24:11:41:26,139 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-24:11:41:26,139 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3.1-8B', 'load_in_4bit': True}\n",
            "2024-08-24:11:41:26,372 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-24:11:41:26,372 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "2024-08-24:11:41:26,777 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:03<00:00,  1.07it/s]\n",
            "2024-08-24:11:41:31,824 WARNING  [big_modeling.py:451] You shouldn't move a model that is dispatched using accelerate hooks.\n",
            "2024-08-24:11:41:58,442 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-24:11:41:58,442 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,442 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-24:11:41:58,442 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,442 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-24:11:41:58,442 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,442 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-24:11:41:58,442 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,442 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-24:11:41:58,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-24:11:41:58,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-24:11:41:58,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-24:11:41:58,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-24:11:41:58,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-24:11:41:58,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-24:11:41:58,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-24:11:41:58,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-24:11:41:58,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-24:11:41:58,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-24:11:41:58,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-24:11:41:58,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-24:11:41:58,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-24:11:41:58,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-24:11:41:58,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-24:11:41:58,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-24:11:41:58,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-24:11:41:58,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-24:11:41:58,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-24:11:41:58,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-24:11:41:58,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-24:11:41:58,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-24:11:41:58,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-24:11:41:58,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-24:11:41:58,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-24:11:41:58,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-24:11:41:58,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-24:11:41:58,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-24:11:41:58,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-24:11:41:58,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-24:11:41:58,445 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,445 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-24:11:41:58,445 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,445 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-24:11:41:58,445 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,445 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-24:11:41:58,445 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,445 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-24:11:41:58,445 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,445 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-24:11:41:58,445 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,445 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-24:11:41:58,445 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,445 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-24:11:41:58,445 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,445 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-24:11:41:58,445 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,445 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-24:11:41:58,445 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,445 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-24:11:41:58,445 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,445 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-24:11:41:58,445 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,445 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-24:11:41:58,445 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,445 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-24:11:41:58,445 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,445 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-24:11:41:58,445 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,445 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-24:11:41:58,446 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,446 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-24:11:41:58,446 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,446 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-24:11:41:58,446 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,446 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-24:11:41:58,446 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,446 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-24:11:41:58,446 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,446 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-24:11:41:58,446 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,446 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-24:11:41:58,446 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,446 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-24:11:41:58,446 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,446 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-24:11:41:58,446 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,446 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-24:11:41:58,446 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:11:41:58,446 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-24:11:41:58,455 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 573.25it/s]\n",
            "2024-08-24:11:41:58,635 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 579.21it/s]\n",
            "2024-08-24:11:41:58,875 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 577.07it/s]\n",
            "2024-08-24:11:41:59,146 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 580.54it/s]\n",
            "2024-08-24:11:41:59,401 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 553.45it/s]\n",
            "2024-08-24:11:41:59,587 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 584.05it/s]\n",
            "2024-08-24:11:41:59,764 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 584.86it/s]\n",
            "2024-08-24:11:41:59,940 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 584.74it/s]\n",
            "2024-08-24:11:42:00,119 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 582.91it/s]\n",
            "2024-08-24:11:42:00,296 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 583.55it/s]\n",
            "2024-08-24:11:42:00,710 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 628.65it/s]\n",
            "2024-08-24:11:42:00,948 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 706.72it/s]\n",
            "2024-08-24:11:42:01,498 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 709.87it/s]\n",
            "2024-08-24:11:42:01,947 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 701.06it/s]\n",
            "2024-08-24:11:42:02,245 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 678.54it/s]\n",
            "2024-08-24:11:42:02,397 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 685.88it/s]\n",
            "2024-08-24:11:42:02,802 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 704.30it/s]\n",
            "2024-08-24:11:42:03,023 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 702.47it/s]\n",
            "2024-08-24:11:42:03,339 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 697.50it/s]\n",
            "2024-08-24:11:42:03,505 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 691.97it/s]\n",
            "2024-08-24:11:42:03,654 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 702.61it/s]\n",
            "2024-08-24:11:42:04,042 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 708.09it/s]\n",
            "2024-08-24:11:42:04,293 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 705.43it/s]\n",
            "2024-08-24:11:42:04,440 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 702.83it/s]\n",
            "2024-08-24:11:42:04,766 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 705.43it/s]\n",
            "2024-08-24:11:42:04,916 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 702.44it/s]\n",
            "2024-08-24:11:42:05,259 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 698.60it/s]\n",
            "2024-08-24:11:42:05,406 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 702.60it/s]\n",
            "2024-08-24:11:42:06,704 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 700.31it/s]\n",
            "2024-08-24:11:42:07,153 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 706.63it/s]\n",
            "2024-08-24:11:42:07,563 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 696.82it/s]\n",
            "2024-08-24:11:42:07,965 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 703.05it/s]\n",
            "2024-08-24:11:42:08,208 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 704.80it/s]\n",
            "2024-08-24:11:42:08,375 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 704.42it/s]\n",
            "2024-08-24:11:42:08,664 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 701.37it/s]\n",
            "2024-08-24:11:42:08,947 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 704.36it/s]\n",
            "2024-08-24:11:42:09,516 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 692.93it/s]\n",
            "2024-08-24:11:42:09,869 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 702.54it/s]\n",
            "2024-08-24:11:42:10,667 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 687.80it/s]\n",
            "2024-08-24:11:42:10,863 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 697.96it/s]\n",
            "2024-08-24:11:42:11,764 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 719.70it/s]\n",
            "2024-08-24:11:42:11,922 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 720.98it/s]\n",
            "2024-08-24:11:42:12,271 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 705.96it/s]\n",
            "2024-08-24:11:42:12,564 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 711.27it/s]\n",
            "2024-08-24:11:42:12,709 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 708.78it/s]\n",
            "2024-08-24:11:42:12,892 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 690.42it/s]\n",
            "2024-08-24:11:42:13,139 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 713.53it/s]\n",
            "2024-08-24:11:42:13,434 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 718.93it/s]\n",
            "2024-08-24:11:42:13,773 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 715.97it/s]\n",
            "2024-08-24:11:42:13,947 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 720.23it/s]\n",
            "2024-08-24:11:42:14,102 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 707.66it/s]\n",
            "2024-08-24:11:42:14,339 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 702.73it/s]\n",
            "2024-08-24:11:42:14,845 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 609.37it/s]\n",
            "2024-08-24:11:42:16,348 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 708.52it/s]\n",
            "2024-08-24:11:42:16,800 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 705.56it/s]\n",
            "2024-08-24:11:42:17,272 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 696.63it/s]\n",
            "2024-08-24:11:42:19,535 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 706.07it/s]\n",
            "2024-08-24:11:42:19,784 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 16686.19it/s]\n",
            "2024-08-24:11:42:21,320 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1377.41it/s]\n",
            "2024-08-24:11:42:22,232 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
            "Running loglikelihood requests: 100%|██| 174850/174850 [19:17<00:00, 151.11it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-24:12:03:30,220 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=meta-llama/Meta-Llama-3.1-8B,load_in_4bit=True), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.4889|±  |0.0146|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.5119|±  |0.0146|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.2778|±  |0.0041|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.5768|±  |0.0039|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5201|±  |0.0067|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.3810|±  |0.0434|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7333|±  |0.0345|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.7500|±  |0.0304|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.7932|±  |0.0264|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.7521|±  |0.0394|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.7130|±  |0.0437|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.6933|±  |0.0362|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.6474|±  |0.0257|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2402|±  |0.0143|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.6495|±  |0.0271|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.6975|±  |0.0256|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4263|±  |0.0126|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.7895|±  |0.0313|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.6582|±  |0.0082|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.6200|±  |0.0488|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.6226|±  |0.0298|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.5838|±  |0.0376|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.3200|±  |0.0469|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.6233|±  |0.0325|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.7476|±  |0.0430|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8376|±  |0.0242|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.7400|±  |0.0441|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.7803|±  |0.0148|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.6634|±  |0.0271|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.4574|±  |0.0297|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.6250|±  |0.0294|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5181|±  |0.0389|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.6685|±  |0.0082|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.3947|±  |0.0460|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.7525|±  |0.0307|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8342|±  |0.0268|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.5282|±  |0.0253|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.5714|±  |0.0321|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.7798|±  |0.0178|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.6870|±  |0.0407|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.6176|±  |0.0197|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.5818|±  |0.0472|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.6245|±  |0.0310|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.8159|±  |0.0274|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.8600|±  |0.0349|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.4916|±  |0.0086|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3100|±  |0.0465|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.5630|±  |0.0428|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.6250|±  |0.0394|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.7569|±  |0.0359|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.3700|±  |0.0485|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.4400|±  |0.0499|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.3200|±  |0.0469|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.4216|±  |0.0491|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.7400|±  |0.0441|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5106|±  |0.0327|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.4966|±  |0.0417|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.3757|±  |0.0249|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7097|±  |0.0258|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.4729|±  |0.0351|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.6400|±  |0.0482|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3333|±  |0.0287|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.4040|±  |0.0401|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.4306|±  |0.0338|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.4554|±  |0.0473|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.5768|±  |0.0039|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5201|±  |0.0067|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.6582|±  |0.0082|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.6685|±  |0.0082|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.4916|±  |0.0086|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=meta-llama/Meta-Llama-3.1-8B,load_in_4bit=True --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b2b7c42-81b0-4555-940a-9c39fba2c6be",
      "metadata": {
        "id": "4b2b7c42-81b0-4555-940a-9c39fba2c6be",
        "outputId": "f00aa6c1-9ca0-429f-96fe-076e6a417ad0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-24:12:03:35,651 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-24:12:03:35,780 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-24:12:03:50,124 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-24:12:03:50,126 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-24:12:03:50,126 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'kaitchup/Meta-Llama-3.1-8B-AutoRound-GPTQ-sym-4bit'}\n",
            "2024-08-24:12:03:50,360 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-24:12:03:50,360 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "config.json: 100%|█████████████████████████| 1.52k/1.52k [00:00<00:00, 5.26MB/s]\n",
            "tokenizer_config.json: 100%|███████████████| 50.5k/50.5k [00:00<00:00, 96.1MB/s]\n",
            "tokenizer.json: 100%|██████████████████████| 9.09M/9.09M [00:00<00:00, 31.0MB/s]\n",
            "special_tokens_map.json: 100%|█████████████████| 301/301 [00:00<00:00, 1.34MB/s]\n",
            "2024-08-24:12:03:51,565 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "2024-08-24:12:03:52,556 WARNING  [qlinear_cuda.py:18] CUDA extension not installed.\n",
            "2024-08-24:12:03:52,557 WARNING  [qlinear_cuda_old.py:17] CUDA extension not installed.\n",
            "model.safetensors.index.json: 100%|█████████| 78.5k/78.5k [00:00<00:00, 135MB/s]\n",
            "Downloading shards:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0%|             | 0.00/4.68G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0%|    | 21.0M/4.68G [00:00<01:20, 57.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1%|    | 31.5M/4.68G [00:00<01:13, 63.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1%|    | 41.9M/4.68G [00:00<01:37, 47.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1%|    | 52.4M/4.68G [00:00<01:26, 53.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1%|    | 62.9M/4.68G [00:01<01:39, 46.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2%|    | 73.4M/4.68G [00:01<01:55, 40.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2%|    | 83.9M/4.68G [00:01<02:10, 35.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2%|     | 105M/4.68G [00:02<01:40, 45.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2%|     | 115M/4.68G [00:02<01:57, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3%|▏    | 126M/4.68G [00:03<02:15, 33.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3%|▏    | 136M/4.68G [00:03<02:34, 29.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3%|▏    | 147M/4.68G [00:03<02:35, 29.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3%|▏    | 157M/4.68G [00:04<02:23, 31.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4%|▏    | 168M/4.68G [00:04<02:49, 26.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4%|▏    | 178M/4.68G [00:04<02:31, 29.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4%|▏    | 199M/4.68G [00:05<01:47, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4%|▏    | 210M/4.68G [00:05<01:42, 43.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5%|▏    | 231M/4.68G [00:05<01:29, 49.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5%|▎    | 241M/4.68G [00:06<01:44, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5%|▎    | 252M/4.68G [00:06<01:30, 48.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6%|▎    | 262M/4.68G [00:06<01:34, 46.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6%|▎    | 273M/4.68G [00:06<01:27, 50.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6%|▎    | 294M/4.68G [00:06<01:08, 64.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6%|▎    | 304M/4.68G [00:07<01:35, 46.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7%|▎    | 325M/4.68G [00:07<01:40, 43.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7%|▎    | 336M/4.68G [00:08<01:41, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7%|▎    | 346M/4.68G [00:08<01:54, 37.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8%|▍    | 357M/4.68G [00:08<02:00, 35.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8%|▍    | 377M/4.68G [00:09<01:43, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8%|▍    | 388M/4.68G [00:09<01:49, 39.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9%|▍    | 409M/4.68G [00:10<01:52, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9%|▍    | 419M/4.68G [00:10<01:56, 36.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9%|▍    | 440M/4.68G [00:10<01:29, 47.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10%|▍    | 451M/4.68G [00:10<01:32, 45.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10%|▍    | 461M/4.68G [00:11<01:45, 39.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10%|▌    | 472M/4.68G [00:11<01:53, 37.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10%|▌    | 482M/4.68G [00:12<02:01, 34.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11%|▌    | 493M/4.68G [00:12<01:43, 40.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11%|▌    | 503M/4.68G [00:12<01:43, 40.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11%|▌    | 514M/4.68G [00:12<02:06, 32.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11%|▌    | 535M/4.68G [00:13<01:38, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12%|▌    | 545M/4.68G [00:13<02:01, 34.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12%|▌    | 566M/4.68G [00:13<01:32, 44.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12%|▌    | 577M/4.68G [00:14<01:38, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13%|▋    | 598M/4.68G [00:14<01:21, 50.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13%|▋    | 608M/4.68G [00:14<01:34, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13%|▋    | 629M/4.68G [00:15<01:23, 48.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14%|▋    | 640M/4.68G [00:15<01:24, 47.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14%|▋    | 650M/4.68G [00:15<01:21, 49.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14%|▋    | 661M/4.68G [00:16<01:44, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15%|▋    | 682M/4.68G [00:16<01:42, 39.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15%|▋    | 692M/4.68G [00:16<01:41, 39.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15%|▊    | 713M/4.68G [00:17<02:04, 31.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15%|▊    | 724M/4.68G [00:18<02:09, 30.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16%|▊    | 744M/4.68G [00:18<01:57, 33.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16%|▊    | 755M/4.68G [00:19<02:02, 32.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16%|▊    | 765M/4.68G [00:19<01:50, 35.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17%|▊    | 776M/4.68G [00:19<01:43, 37.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17%|▊    | 786M/4.68G [00:19<01:30, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17%|▊    | 797M/4.68G [00:19<01:27, 44.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17%|▊    | 807M/4.68G [00:20<01:30, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17%|▊    | 818M/4.68G [00:20<01:51, 34.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18%|▉    | 839M/4.68G [00:20<01:30, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18%|▉    | 849M/4.68G [00:21<01:36, 39.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19%|▉    | 870M/4.68G [00:21<01:23, 45.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19%|▉    | 881M/4.68G [00:22<01:45, 36.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19%|▉    | 891M/4.68G [00:22<02:32, 24.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19%|▉    | 902M/4.68G [00:23<02:26, 25.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19%|▉    | 912M/4.68G [00:23<02:17, 27.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20%|▉    | 933M/4.68G [00:23<01:44, 35.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20%|█    | 944M/4.68G [00:24<01:49, 34.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20%|█    | 954M/4.68G [00:24<01:57, 31.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21%|█    | 965M/4.68G [00:24<01:46, 35.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21%|█    | 986M/4.68G [00:25<01:21, 45.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21%|█    | 996M/4.68G [00:25<01:23, 44.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22%|▊   | 1.02G/4.68G [00:25<01:14, 49.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22%|▉   | 1.03G/4.68G [00:26<01:15, 48.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22%|▉   | 1.05G/4.68G [00:26<01:10, 51.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23%|▉   | 1.06G/4.68G [00:26<01:28, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23%|▉   | 1.07G/4.68G [00:27<01:22, 44.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23%|▉   | 1.08G/4.68G [00:27<01:18, 45.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23%|▉   | 1.09G/4.68G [00:27<01:24, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24%|▉   | 1.11G/4.68G [00:27<01:15, 47.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24%|▉   | 1.12G/4.68G [00:28<01:10, 50.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24%|▉   | 1.14G/4.68G [00:28<01:04, 54.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25%|▉   | 1.15G/4.68G [00:28<01:09, 50.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25%|█   | 1.17G/4.68G [00:28<00:54, 64.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25%|█   | 1.18G/4.68G [00:29<01:04, 54.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26%|█   | 1.21G/4.68G [00:29<01:12, 47.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26%|█   | 1.22G/4.68G [00:29<01:16, 45.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26%|█   | 1.24G/4.68G [00:30<01:16, 44.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27%|█   | 1.25G/4.68G [00:30<01:14, 46.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27%|█   | 1.26G/4.68G [00:30<01:14, 46.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27%|█   | 1.27G/4.68G [00:31<02:07, 26.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28%|█   | 1.29G/4.68G [00:32<01:50, 30.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28%|█   | 1.30G/4.68G [00:32<02:05, 26.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28%|█▏  | 1.32G/4.68G [00:33<01:35, 35.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28%|█▏  | 1.33G/4.68G [00:33<01:30, 36.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29%|█▏  | 1.35G/4.68G [00:33<01:20, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29%|█▏  | 1.36G/4.68G [00:34<01:22, 40.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30%|█▏  | 1.38G/4.68G [00:34<01:26, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30%|█▏  | 1.39G/4.68G [00:35<01:30, 36.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30%|█▏  | 1.42G/4.68G [00:35<01:16, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30%|█▏  | 1.43G/4.68G [00:35<01:14, 43.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31%|█▏  | 1.44G/4.68G [00:35<01:18, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31%|█▏  | 1.45G/4.68G [00:36<01:28, 36.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31%|█▏  | 1.46G/4.68G [00:36<01:52, 28.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31%|█▎  | 1.47G/4.68G [00:37<01:53, 28.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32%|█▎  | 1.48G/4.68G [00:37<01:39, 32.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32%|█▎  | 1.49G/4.68G [00:38<02:02, 26.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32%|█▎  | 1.51G/4.68G [00:38<01:26, 36.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32%|█▎  | 1.52G/4.68G [00:38<01:23, 37.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33%|█▎  | 1.54G/4.68G [00:39<01:22, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33%|█▎  | 1.55G/4.68G [00:39<01:29, 35.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33%|█▎  | 1.56G/4.68G [00:39<01:26, 36.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34%|█▎  | 1.57G/4.68G [00:40<01:26, 36.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34%|█▎  | 1.59G/4.68G [00:40<01:05, 47.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34%|█▎  | 1.60G/4.68G [00:40<01:07, 45.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35%|█▍  | 1.63G/4.68G [00:40<01:01, 49.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35%|█▍  | 1.64G/4.68G [00:41<01:12, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35%|█▍  | 1.65G/4.68G [00:41<01:04, 47.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35%|█▍  | 1.66G/4.68G [00:41<01:02, 48.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36%|█▍  | 1.67G/4.68G [00:41<01:07, 44.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36%|█▍  | 1.69G/4.68G [00:42<01:22, 36.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36%|█▍  | 1.70G/4.68G [00:43<01:25, 35.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37%|█▍  | 1.71G/4.68G [00:43<01:23, 35.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37%|█▍  | 1.72G/4.68G [00:43<01:17, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37%|█▍  | 1.73G/4.68G [00:43<01:24, 34.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37%|█▍  | 1.75G/4.68G [00:44<01:17, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38%|█▌  | 1.76G/4.68G [00:44<01:18, 37.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38%|█▌  | 1.78G/4.68G [00:45<01:03, 45.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38%|█▌  | 1.79G/4.68G [00:45<01:18, 36.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39%|█▌  | 1.81G/4.68G [00:45<01:08, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39%|█▌  | 1.82G/4.68G [00:46<01:06, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39%|█▌  | 1.85G/4.68G [00:46<00:56, 50.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40%|█▌  | 1.86G/4.68G [00:46<00:56, 49.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40%|█▌  | 1.87G/4.68G [00:46<00:55, 50.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40%|█▌  | 1.88G/4.68G [00:47<01:09, 40.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41%|█▌  | 1.90G/4.68G [00:47<01:04, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41%|█▋  | 1.91G/4.68G [00:48<01:15, 37.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41%|█▋  | 1.92G/4.68G [00:48<01:14, 37.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41%|█▋  | 1.93G/4.68G [00:48<01:06, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41%|█▋  | 1.94G/4.68G [00:48<01:11, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42%|█▋  | 1.96G/4.68G [00:49<01:07, 40.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42%|█▋  | 1.97G/4.68G [00:49<01:05, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42%|█▋  | 1.98G/4.68G [00:49<01:02, 43.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43%|█▋  | 1.99G/4.68G [00:49<00:53, 50.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43%|█▋  | 2.00G/4.68G [00:50<01:09, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43%|█▋  | 2.02G/4.68G [00:50<00:58, 45.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43%|█▋  | 2.03G/4.68G [00:50<00:55, 48.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44%|█▊  | 2.06G/4.68G [00:51<00:53, 48.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44%|█▊  | 2.07G/4.68G [00:51<01:02, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45%|█▊  | 2.09G/4.68G [00:52<00:57, 45.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45%|█▊  | 2.10G/4.68G [00:52<01:01, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45%|█▊  | 2.12G/4.68G [00:52<00:57, 44.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45%|█▊  | 2.13G/4.68G [00:53<00:58, 43.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46%|█▊  | 2.15G/4.68G [00:53<01:07, 37.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46%|█▊  | 2.16G/4.68G [00:53<01:02, 40.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47%|█▊  | 2.18G/4.68G [00:54<00:55, 44.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47%|█▊  | 2.19G/4.68G [00:54<00:50, 49.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47%|█▉  | 2.20G/4.68G [00:54<00:50, 49.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47%|█▉  | 2.21G/4.68G [00:54<00:48, 50.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48%|█▉  | 2.23G/4.68G [00:55<00:44, 55.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48%|█▉  | 2.24G/4.68G [00:55<00:53, 45.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48%|█▉  | 2.26G/4.68G [00:55<00:44, 54.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49%|█▉  | 2.28G/4.68G [00:56<00:51, 46.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49%|█▉  | 2.30G/4.68G [00:56<00:47, 50.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49%|█▉  | 2.31G/4.68G [00:56<00:50, 47.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50%|█▉  | 2.33G/4.68G [00:57<00:50, 46.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50%|█▉  | 2.34G/4.68G [00:57<01:01, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50%|██  | 2.36G/4.68G [00:58<00:50, 46.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51%|██  | 2.37G/4.68G [00:58<00:52, 44.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51%|██  | 2.39G/4.68G [00:58<00:56, 40.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51%|██  | 2.40G/4.68G [00:59<01:02, 36.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52%|██  | 2.42G/4.68G [00:59<00:54, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52%|██  | 2.43G/4.68G [01:00<00:58, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52%|██  | 2.45G/4.68G [01:00<00:51, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53%|██  | 2.46G/4.68G [01:00<01:03, 35.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53%|██  | 2.49G/4.68G [01:01<00:56, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53%|██▏ | 2.50G/4.68G [01:01<00:55, 39.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54%|██▏ | 2.51G/4.68G [01:01<00:50, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54%|██▏ | 2.52G/4.68G [01:02<00:55, 39.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54%|██▏ | 2.54G/4.68G [01:02<00:51, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54%|██▏ | 2.55G/4.68G [01:02<00:54, 39.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55%|██▏ | 2.57G/4.68G [01:03<00:46, 45.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55%|██▏ | 2.58G/4.68G [01:03<00:58, 35.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55%|██▏ | 2.59G/4.68G [01:04<01:05, 32.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56%|██▏ | 2.60G/4.68G [01:04<01:10, 29.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56%|██▏ | 2.61G/4.68G [01:05<01:11, 28.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56%|██▏ | 2.63G/4.68G [01:05<00:54, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56%|██▎ | 2.64G/4.68G [01:05<01:02, 32.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57%|██▎ | 2.66G/4.68G [01:06<00:47, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57%|██▎ | 2.67G/4.68G [01:06<00:52, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58%|██▎ | 2.69G/4.68G [01:06<00:47, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58%|██▎ | 2.71G/4.68G [01:07<00:58, 33.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58%|██▎ | 2.73G/4.68G [01:08<01:00, 32.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58%|██▎ | 2.74G/4.68G [01:08<00:55, 35.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59%|██▎ | 2.76G/4.68G [01:09<01:06, 28.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59%|██▎ | 2.77G/4.68G [01:10<01:38, 19.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60%|██▍ | 2.79G/4.68G [01:10<01:13, 25.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60%|██▍ | 2.80G/4.68G [01:10<01:02, 30.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60%|██▍ | 2.81G/4.68G [01:11<00:57, 32.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60%|██▍ | 2.82G/4.68G [01:11<01:10, 26.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60%|██▍ | 2.83G/4.68G [01:12<01:02, 29.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61%|██▍ | 2.84G/4.68G [01:12<00:56, 32.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61%|██▍ | 2.85G/4.68G [01:12<01:00, 30.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61%|██▍ | 2.87G/4.68G [01:13<01:12, 24.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62%|██▍ | 2.88G/4.68G [01:13<01:00, 29.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62%|██▍ | 2.90G/4.68G [01:15<01:17, 22.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62%|██▍ | 2.92G/4.68G [01:15<01:09, 25.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63%|██▌ | 2.94G/4.68G [01:15<00:58, 30.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63%|██▌ | 2.95G/4.68G [01:16<00:59, 29.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63%|██▌ | 2.97G/4.68G [01:16<00:47, 36.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64%|██▌ | 2.98G/4.68G [01:16<00:48, 35.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64%|██▌ | 3.00G/4.68G [01:17<00:41, 40.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64%|██▌ | 3.01G/4.68G [01:17<00:43, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65%|██▌ | 3.03G/4.68G [01:17<00:34, 47.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65%|██▌ | 3.04G/4.68G [01:18<00:44, 36.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65%|██▌ | 3.06G/4.68G [01:19<00:44, 36.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66%|██▌ | 3.07G/4.68G [01:19<00:43, 37.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66%|██▋ | 3.08G/4.68G [01:19<00:40, 39.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66%|██▋ | 3.09G/4.68G [01:19<00:36, 43.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66%|██▋ | 3.10G/4.68G [01:19<00:36, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67%|██▋ | 3.11G/4.68G [01:20<00:34, 45.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67%|██▋ | 3.12G/4.68G [01:20<00:53, 28.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67%|██▋ | 3.14G/4.68G [01:20<00:44, 34.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67%|██▋ | 3.15G/4.68G [01:21<00:42, 35.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67%|██▋ | 3.16G/4.68G [01:21<00:39, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68%|██▋ | 3.17G/4.68G [01:21<00:33, 45.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68%|██▋ | 3.18G/4.68G [01:21<00:34, 43.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68%|██▋ | 3.19G/4.68G [01:22<00:40, 36.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69%|██▋ | 3.21G/4.68G [01:22<00:37, 39.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69%|██▊ | 3.22G/4.68G [01:23<00:43, 33.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69%|██▊ | 3.24G/4.68G [01:23<00:39, 36.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69%|██▊ | 3.25G/4.68G [01:24<00:47, 30.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70%|██▊ | 3.27G/4.68G [01:24<00:45, 30.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70%|██▊ | 3.28G/4.68G [01:25<00:49, 28.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71%|██▊ | 3.30G/4.68G [01:25<00:41, 33.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71%|██▊ | 3.31G/4.68G [01:26<00:38, 36.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71%|██▊ | 3.32G/4.68G [01:26<00:34, 39.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71%|██▊ | 3.33G/4.68G [01:26<00:31, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71%|██▊ | 3.34G/4.68G [01:26<00:37, 35.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72%|██▉ | 3.37G/4.68G [01:27<00:44, 29.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72%|██▉ | 3.38G/4.68G [01:28<00:45, 28.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73%|██▉ | 3.40G/4.68G [01:28<00:35, 36.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73%|██▉ | 3.41G/4.68G [01:28<00:37, 33.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73%|██▉ | 3.42G/4.68G [01:28<00:32, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73%|██▉ | 3.43G/4.68G [01:29<00:31, 39.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73%|██▉ | 3.44G/4.68G [01:29<00:26, 47.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74%|██▉ | 3.45G/4.68G [01:29<00:32, 37.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74%|██▉ | 3.46G/4.68G [01:30<00:32, 37.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74%|██▉ | 3.48G/4.68G [01:30<00:28, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75%|██▉ | 3.49G/4.68G [01:30<00:32, 37.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75%|██▉ | 3.50G/4.68G [01:30<00:27, 43.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75%|███ | 3.51G/4.68G [01:31<00:28, 41.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75%|███ | 3.52G/4.68G [01:31<00:25, 46.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76%|███ | 3.54G/4.68G [01:31<00:19, 58.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76%|███ | 3.55G/4.68G [01:31<00:23, 48.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76%|███ | 3.57G/4.68G [01:32<00:23, 47.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76%|███ | 3.58G/4.68G [01:32<00:31, 35.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77%|███ | 3.59G/4.68G [01:32<00:27, 39.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77%|███ | 3.61G/4.68G [01:33<00:19, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77%|███ | 3.62G/4.68G [01:33<00:20, 52.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77%|███ | 3.63G/4.68G [01:34<00:34, 30.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78%|███ | 3.64G/4.68G [01:34<00:30, 34.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78%|███ | 3.65G/4.68G [01:34<00:33, 31.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78%|███▏| 3.67G/4.68G [01:35<00:31, 32.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79%|███▏| 3.68G/4.68G [01:35<00:32, 31.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79%|███▏| 3.70G/4.68G [01:36<00:26, 37.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79%|███▏| 3.71G/4.68G [01:36<00:23, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80%|███▏| 3.72G/4.68G [01:36<00:32, 29.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80%|███▏| 3.73G/4.68G [01:37<00:32, 29.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80%|███▏| 3.75G/4.68G [01:37<00:24, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80%|███▏| 3.76G/4.68G [01:38<00:27, 33.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81%|███▏| 3.79G/4.68G [01:38<00:25, 35.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81%|███▏| 3.80G/4.68G [01:39<00:28, 30.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82%|███▎| 3.82G/4.68G [01:39<00:25, 34.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82%|███▎| 3.83G/4.68G [01:40<00:27, 30.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82%|███▎| 3.85G/4.68G [01:40<00:22, 36.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82%|███▎| 3.86G/4.68G [01:40<00:21, 37.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83%|███▎| 3.88G/4.68G [01:41<00:23, 34.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83%|███▎| 3.89G/4.68G [01:41<00:24, 32.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84%|███▎| 3.91G/4.68G [01:42<00:20, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84%|███▎| 3.92G/4.68G [01:42<00:19, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84%|███▎| 3.94G/4.68G [01:42<00:17, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84%|███▍| 3.95G/4.68G [01:43<00:19, 36.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85%|███▍| 3.97G/4.68G [01:43<00:17, 41.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85%|███▍| 3.98G/4.68G [01:43<00:16, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86%|███▍| 4.01G/4.68G [01:44<00:13, 50.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86%|███▍| 4.02G/4.68G [01:44<00:16, 40.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86%|███▍| 4.04G/4.68G [01:45<00:15, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86%|███▍| 4.05G/4.68G [01:45<00:15, 40.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87%|███▍| 4.06G/4.68G [01:45<00:15, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87%|███▍| 4.07G/4.68G [01:46<00:18, 33.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87%|███▍| 4.09G/4.68G [01:46<00:15, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88%|███▌| 4.10G/4.68G [01:47<00:18, 31.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88%|███▌| 4.12G/4.68G [01:47<00:16, 34.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88%|███▌| 4.13G/4.68G [01:47<00:16, 34.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89%|███▌| 4.15G/4.68G [01:48<00:13, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89%|███▌| 4.16G/4.68G [01:48<00:15, 33.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89%|███▌| 4.18G/4.68G [01:49<00:12, 39.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90%|███▌| 4.19G/4.68G [01:49<00:11, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90%|███▌| 4.22G/4.68G [01:49<00:08, 53.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90%|███▌| 4.23G/4.68G [01:49<00:08, 52.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91%|███▋| 4.25G/4.68G [01:50<00:07, 61.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91%|███▋| 4.26G/4.68G [01:50<00:08, 51.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91%|███▋| 4.28G/4.68G [01:50<00:08, 47.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92%|███▋| 4.29G/4.68G [01:51<00:08, 48.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92%|███▋| 4.31G/4.68G [01:51<00:07, 50.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92%|███▋| 4.32G/4.68G [01:51<00:08, 44.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93%|███▋| 4.34G/4.68G [01:52<00:07, 45.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93%|███▋| 4.35G/4.68G [01:52<00:08, 40.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93%|███▋| 4.36G/4.68G [01:52<00:07, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93%|███▋| 4.37G/4.68G [01:53<00:08, 37.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94%|███▋| 4.38G/4.68G [01:53<00:08, 34.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94%|███▊| 4.39G/4.68G [01:54<00:11, 25.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94%|███▊| 4.40G/4.68G [01:54<00:10, 26.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95%|███▊| 4.42G/4.68G [01:55<00:07, 34.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95%|███▊| 4.44G/4.68G [01:55<00:06, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95%|███▊| 4.46G/4.68G [01:55<00:05, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95%|███▊| 4.47G/4.68G [01:56<00:06, 34.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96%|███▊| 4.49G/4.68G [01:56<00:05, 33.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96%|███▊| 4.50G/4.68G [01:57<00:05, 34.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97%|███▊| 4.52G/4.68G [01:57<00:04, 37.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97%|███▊| 4.53G/4.68G [01:57<00:03, 40.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97%|███▉| 4.55G/4.68G [01:57<00:02, 52.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97%|███▉| 4.56G/4.68G [01:58<00:02, 54.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98%|███▉| 4.58G/4.68G [01:58<00:01, 62.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98%|███▉| 4.59G/4.68G [01:58<00:02, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99%|███▉| 4.61G/4.68G [01:59<00:02, 32.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99%|███▉| 4.62G/4.68G [02:00<00:01, 29.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99%|███▉| 4.63G/4.68G [02:00<00:01, 33.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99%|███▉| 4.65G/4.68G [02:00<00:01, 30.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99%|███▉| 4.66G/4.68G [02:01<00:00, 35.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100%|███▉| 4.67G/4.68G [02:01<00:00, 35.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100%|███▉| 4.68G/4.68G [02:01<00:00, 34.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100%|████| 4.68G/4.68G [02:02<00:00, 38.4MB/s]\u001b[A\n",
            "Downloading shards:  50%|████████████            | 1/2 [02:02<02:02, 122.41s/it]\n",
            "model-00002-of-00002.safetensors:   0%|             | 0.00/1.05G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2%|     | 21.0M/1.05G [00:00<00:10, 102MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3%|    | 31.5M/1.05G [00:00<00:16, 62.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4%|▏   | 41.9M/1.05G [00:00<00:16, 59.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5%|▏   | 52.4M/1.05G [00:01<00:23, 41.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7%|▎   | 73.4M/1.05G [00:01<00:28, 34.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8%|▎   | 83.9M/1.05G [00:02<00:29, 33.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10%|▍    | 105M/1.05G [00:02<00:24, 38.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11%|▌    | 115M/1.05G [00:02<00:26, 35.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13%|▋    | 136M/1.05G [00:03<00:22, 41.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14%|▋    | 147M/1.05G [00:03<00:26, 33.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15%|▋    | 157M/1.05G [00:04<00:24, 35.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16%|▊    | 168M/1.05G [00:04<00:23, 38.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17%|▊    | 178M/1.05G [00:04<00:22, 39.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19%|▉    | 199M/1.05G [00:05<00:31, 27.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20%|▉    | 210M/1.05G [00:06<00:31, 26.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21%|█    | 220M/1.05G [00:06<00:25, 32.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22%|█    | 231M/1.05G [00:06<00:24, 33.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23%|█▏   | 241M/1.05G [00:06<00:25, 31.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25%|█▏   | 262M/1.05G [00:07<00:21, 36.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26%|█▎   | 273M/1.05G [00:07<00:22, 34.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28%|█▍   | 294M/1.05G [00:07<00:16, 47.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29%|█▍   | 304M/1.05G [00:08<00:16, 45.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31%|█▌   | 325M/1.05G [00:08<00:13, 53.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32%|█▌   | 336M/1.05G [00:08<00:12, 56.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33%|█▋   | 346M/1.05G [00:08<00:11, 61.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34%|█▋   | 357M/1.05G [00:08<00:11, 58.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36%|█▊   | 377M/1.05G [00:09<00:09, 70.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37%|█▊   | 388M/1.05G [00:09<00:10, 65.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39%|█▉   | 409M/1.05G [00:09<00:10, 59.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40%|█▉   | 419M/1.05G [00:10<00:13, 47.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41%|██   | 430M/1.05G [00:10<00:12, 50.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42%|██   | 440M/1.05G [00:10<00:19, 31.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43%|██▏  | 451M/1.05G [00:11<00:22, 26.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45%|██▏  | 472M/1.05G [00:11<00:17, 32.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46%|██▎  | 482M/1.05G [00:12<00:18, 30.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48%|██▍  | 503M/1.05G [00:12<00:14, 37.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49%|██▍  | 514M/1.05G [00:13<00:16, 33.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51%|██▌  | 535M/1.05G [00:13<00:16, 31.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52%|██▌  | 545M/1.05G [00:14<00:16, 30.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54%|██▋  | 566M/1.05G [00:14<00:15, 31.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55%|██▋  | 577M/1.05G [00:15<00:13, 34.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57%|██▊  | 598M/1.05G [00:15<00:11, 39.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58%|██▉  | 608M/1.05G [00:15<00:11, 37.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60%|██▉  | 629M/1.05G [00:15<00:07, 53.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61%|███  | 640M/1.05G [00:16<00:07, 56.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62%|███  | 650M/1.05G [00:16<00:06, 58.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63%|███▏ | 661M/1.05G [00:16<00:07, 55.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65%|███▏ | 682M/1.05G [00:16<00:05, 69.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66%|███▎ | 692M/1.05G [00:16<00:05, 61.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68%|███▍ | 713M/1.05G [00:17<00:05, 58.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69%|███▍ | 724M/1.05G [00:17<00:06, 51.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71%|███▌ | 744M/1.05G [00:17<00:04, 63.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72%|███▌ | 755M/1.05G [00:18<00:05, 54.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74%|███▋ | 776M/1.05G [00:18<00:05, 49.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75%|███▋ | 786M/1.05G [00:19<00:07, 33.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77%|███▊ | 807M/1.05G [00:19<00:06, 39.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78%|███▉ | 818M/1.05G [00:19<00:06, 37.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80%|███▉ | 839M/1.05G [00:20<00:06, 34.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81%|████ | 849M/1.05G [00:21<00:06, 31.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83%|████▏| 870M/1.05G [00:21<00:05, 31.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84%|████▏| 881M/1.05G [00:22<00:05, 28.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86%|████▎| 902M/1.05G [00:22<00:04, 33.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87%|████▎| 912M/1.05G [00:22<00:03, 35.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88%|████▍| 923M/1.05G [00:23<00:03, 36.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89%|████▍| 933M/1.05G [00:23<00:03, 30.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90%|████▍| 944M/1.05G [00:24<00:03, 30.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91%|████▌| 954M/1.05G [00:24<00:03, 31.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92%|████▌| 965M/1.05G [00:24<00:02, 30.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94%|████▋| 986M/1.05G [00:25<00:01, 36.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95%|████▋| 996M/1.05G [00:25<00:01, 35.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96%|███▊| 1.01G/1.05G [00:25<00:01, 38.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97%|███▊| 1.02G/1.05G [00:26<00:01, 32.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98%|███▉| 1.03G/1.05G [00:26<00:00, 35.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100%|████| 1.05G/1.05G [00:26<00:00, 39.4MB/s]\u001b[A\n",
            "Downloading shards: 100%|█████████████████████████| 2/2 [02:29<00:00, 74.64s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4674: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.20it/s]\n",
            "generation_config.json: 100%|███████████████████| 185/185 [00:00<00:00, 702kB/s]\n",
            "2024-08-24:12:07:00,435 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-24:12:07:00,436 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,436 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-24:12:07:00,436 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,436 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-24:12:07:00,436 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,436 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-24:12:07:00,436 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,436 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-24:12:07:00,436 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,436 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-24:12:07:00,436 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,436 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-24:12:07:00,436 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,436 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-24:12:07:00,436 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,436 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-24:12:07:00,436 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,436 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-24:12:07:00,436 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,436 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-24:12:07:00,436 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,437 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-24:12:07:00,437 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,437 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-24:12:07:00,437 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,437 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-24:12:07:00,437 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,437 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-24:12:07:00,437 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,437 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-24:12:07:00,437 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,437 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-24:12:07:00,437 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,437 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-24:12:07:00,437 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,437 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-24:12:07:00,437 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,437 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-24:12:07:00,437 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,437 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-24:12:07:00,437 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,437 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-24:12:07:00,437 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,437 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-24:12:07:00,437 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,438 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-24:12:07:00,438 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,438 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-24:12:07:00,438 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,438 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-24:12:07:00,438 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,438 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-24:12:07:00,438 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,438 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-24:12:07:00,438 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,438 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-24:12:07:00,438 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,438 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-24:12:07:00,438 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,438 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-24:12:07:00,438 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,438 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-24:12:07:00,438 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,438 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-24:12:07:00,438 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,438 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-24:12:07:00,438 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,438 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-24:12:07:00,438 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,438 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-24:12:07:00,439 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,439 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-24:12:07:00,439 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,439 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-24:12:07:00,439 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,439 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-24:12:07:00,439 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,439 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-24:12:07:00,439 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,439 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-24:12:07:00,439 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,439 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-24:12:07:00,439 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,439 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-24:12:07:00,439 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,439 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-24:12:07:00,439 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,439 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-24:12:07:00,439 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,439 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-24:12:07:00,439 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,439 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-24:12:07:00,439 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,439 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-24:12:07:00,440 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,440 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-24:12:07:00,440 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,440 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-24:12:07:00,440 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,440 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-24:12:07:00,440 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,440 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-24:12:07:00,440 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,440 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-24:12:07:00,440 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,440 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-24:12:07:00,440 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,440 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-24:12:07:00,440 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,440 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-24:12:07:00,440 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,440 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-24:12:07:00,440 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,440 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-24:12:07:00,440 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,440 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-24:12:07:00,440 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:12:07:00,440 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-24:12:07:00,449 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 561.60it/s]\n",
            "2024-08-24:12:07:00,633 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 575.63it/s]\n",
            "2024-08-24:12:07:00,874 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 582.58it/s]\n",
            "2024-08-24:12:07:01,143 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 585.13it/s]\n",
            "2024-08-24:12:07:01,396 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 586.42it/s]\n",
            "2024-08-24:12:07:01,572 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 587.73it/s]\n",
            "2024-08-24:12:07:01,747 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 586.74it/s]\n",
            "2024-08-24:12:07:01,922 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 588.37it/s]\n",
            "2024-08-24:12:07:02,101 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 586.33it/s]\n",
            "2024-08-24:12:07:02,277 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 588.46it/s]\n",
            "2024-08-24:12:07:02,687 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 585.15it/s]\n",
            "2024-08-24:12:07:02,942 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 563.40it/s]\n",
            "2024-08-24:12:07:03,631 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 643.35it/s]\n",
            "2024-08-24:12:07:04,128 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 714.90it/s]\n",
            "2024-08-24:12:07:04,421 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 711.59it/s]\n",
            "2024-08-24:12:07:04,566 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 708.52it/s]\n",
            "2024-08-24:12:07:04,957 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 705.39it/s]\n",
            "2024-08-24:12:07:05,178 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 704.41it/s]\n",
            "2024-08-24:12:07:05,493 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 699.67it/s]\n",
            "2024-08-24:12:07:05,658 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 697.15it/s]\n",
            "2024-08-24:12:07:05,805 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 701.40it/s]\n",
            "2024-08-24:12:07:06,194 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 702.61it/s]\n",
            "2024-08-24:12:07:06,447 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 696.98it/s]\n",
            "2024-08-24:12:07:06,595 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 706.03it/s]\n",
            "2024-08-24:12:07:06,920 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 707.52it/s]\n",
            "2024-08-24:12:07:07,070 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 713.24it/s]\n",
            "2024-08-24:12:07:07,407 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 712.06it/s]\n",
            "2024-08-24:12:07:07,552 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 705.64it/s]\n",
            "2024-08-24:12:07:08,847 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 708.02it/s]\n",
            "2024-08-24:12:07:09,291 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 696.61it/s]\n",
            "2024-08-24:12:07:09,708 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 698.87it/s]\n",
            "2024-08-24:12:07:10,108 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 699.46it/s]\n",
            "2024-08-24:12:07:10,353 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 697.32it/s]\n",
            "2024-08-24:12:07:10,521 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 697.64it/s]\n",
            "2024-08-24:12:07:10,813 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 699.74it/s]\n",
            "2024-08-24:12:07:11,097 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 704.64it/s]\n",
            "2024-08-24:12:07:11,666 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 705.52it/s]\n",
            "2024-08-24:12:07:12,013 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 710.52it/s]\n",
            "2024-08-24:12:07:12,802 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 710.42it/s]\n",
            "2024-08-24:12:07:12,992 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 713.04it/s]\n",
            "2024-08-24:12:07:13,874 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 715.07it/s]\n",
            "2024-08-24:12:07:14,033 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 715.49it/s]\n",
            "2024-08-24:12:07:14,385 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 714.57it/s]\n",
            "2024-08-24:12:07:14,675 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 711.32it/s]\n",
            "2024-08-24:12:07:14,819 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 705.15it/s]\n",
            "2024-08-24:12:07:15,004 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 708.05it/s]\n",
            "2024-08-24:12:07:15,244 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 702.76it/s]\n",
            "2024-08-24:12:07:15,543 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 703.58it/s]\n",
            "2024-08-24:12:07:15,890 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 711.95it/s]\n",
            "2024-08-24:12:07:16,065 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 692.08it/s]\n",
            "2024-08-24:12:07:16,226 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 710.08it/s]\n",
            "2024-08-24:12:07:16,462 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 709.67it/s]\n",
            "2024-08-24:12:07:16,963 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 611.95it/s]\n",
            "2024-08-24:12:07:18,460 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 715.27it/s]\n",
            "2024-08-24:12:07:18,908 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 712.14it/s]\n",
            "2024-08-24:12:07:19,376 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 714.43it/s]\n",
            "2024-08-24:12:07:21,582 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 715.00it/s]\n",
            "2024-08-24:12:07:21,829 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 14370.67it/s]\n",
            "2024-08-24:12:07:23,481 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1401.43it/s]\n",
            "2024-08-24:12:07:24,377 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
            "Running loglikelihood requests: 100%|███| 174850/174850 [44:22<00:00, 65.67it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-24:12:53:40,683 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=kaitchup/Meta-Llama-3.1-8B-AutoRound-GPTQ-sym-4bit), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.4957|±  |0.0146|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.5230|±  |0.0146|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.2988|±  |0.0042|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.6101|±  |0.0039|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5560|±  |0.0067|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.4603|±  |0.0446|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7515|±  |0.0337|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.7990|±  |0.0281|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.8143|±  |0.0253|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.7686|±  |0.0385|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.7407|±  |0.0424|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7546|±  |0.0338|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.6763|±  |0.0252|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2715|±  |0.0149|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.7074|±  |0.0258|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.7160|±  |0.0251|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4654|±  |0.0127|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.8129|±  |0.0299|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.6920|±  |0.0080|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.5600|±  |0.0499|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.6981|±  |0.0283|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.6358|±  |0.0367|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.3600|±  |0.0482|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.6188|±  |0.0326|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.8155|±  |0.0384|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8803|±  |0.0213|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.8200|±  |0.0386|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.8008|±  |0.0143|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.6993|±  |0.0263|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.4894|±  |0.0298|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.6875|±  |0.0282|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5241|±  |0.0389|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.7026|±  |0.0080|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.3860|±  |0.0458|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.7374|±  |0.0314|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8290|±  |0.0272|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.6026|±  |0.0248|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.6345|±  |0.0313|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.7982|±  |0.0172|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.7481|±  |0.0381|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.6569|±  |0.0192|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6364|±  |0.0461|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.6898|±  |0.0296|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.8358|±  |0.0262|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.8400|±  |0.0368|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5198|±  |0.0086|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3500|±  |0.0479|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.6370|±  |0.0415|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.7039|±  |0.0372|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.7431|±  |0.0365|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4300|±  |0.0498|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.4400|±  |0.0499|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.3100|±  |0.0465|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.4216|±  |0.0491|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.7200|±  |0.0451|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5660|±  |0.0324|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.5448|±  |0.0415|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4339|±  |0.0255|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7452|±  |0.0248|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.4483|±  |0.0350|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.6800|±  |0.0469|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3667|±  |0.0294|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.3974|±  |0.0400|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.4537|±  |0.0340|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.4286|±  |0.0470|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.6101|±  |0.0039|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5560|±  |0.0067|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.6920|±  |0.0080|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.7026|±  |0.0080|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5198|±  |0.0086|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=kaitchup/Meta-Llama-3.1-8B-AutoRound-GPTQ-sym-4bit --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a48dab11-cbc0-4a1c-a256-4111a3baa3a9",
      "metadata": {
        "id": "a48dab11-cbc0-4a1c-a256-4111a3baa3a9",
        "outputId": "1aa272c9-c59e-4243-cb23-caff8ed84d6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-25:15:46:02,156 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-25:15:46:02,250 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-25:15:46:14,968 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-25:15:46:14,970 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-25:15:46:14,970 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': './AutoRound/Meta-Llama-3.1-8B-AutoRound-GPTQ-asym-4bit'}\n",
            "2024-08-25:15:46:15,070 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-25:15:46:15,071 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "2024-08-25:15:46:15,485 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "2024-08-25:15:46:16,411 WARNING  [qlinear_cuda.py:18] CUDA extension not installed.\n",
            "2024-08-25:15:46:16,412 WARNING  [qlinear_cuda_old.py:17] CUDA extension not installed.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4709: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at ./AutoRound/Meta-Llama-3.1-8B-AutoRound-GPTQ-asym-4bit were not used when initializing LlamaForCausalLM: ['model.layers.0.mlp.down_proj.bias', 'model.layers.0.mlp.gate_proj.bias', 'model.layers.0.mlp.up_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.o_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.1.mlp.down_proj.bias', 'model.layers.1.mlp.gate_proj.bias', 'model.layers.1.mlp.up_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.o_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.10.mlp.down_proj.bias', 'model.layers.10.mlp.gate_proj.bias', 'model.layers.10.mlp.up_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.o_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.11.mlp.down_proj.bias', 'model.layers.11.mlp.gate_proj.bias', 'model.layers.11.mlp.up_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.o_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.12.mlp.down_proj.bias', 'model.layers.12.mlp.gate_proj.bias', 'model.layers.12.mlp.up_proj.bias', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.o_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.13.mlp.down_proj.bias', 'model.layers.13.mlp.gate_proj.bias', 'model.layers.13.mlp.up_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.o_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.14.mlp.down_proj.bias', 'model.layers.14.mlp.gate_proj.bias', 'model.layers.14.mlp.up_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.o_proj.bias', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.15.mlp.down_proj.bias', 'model.layers.15.mlp.gate_proj.bias', 'model.layers.15.mlp.up_proj.bias', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.o_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.16.mlp.down_proj.bias', 'model.layers.16.mlp.gate_proj.bias', 'model.layers.16.mlp.up_proj.bias', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.o_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.17.mlp.down_proj.bias', 'model.layers.17.mlp.gate_proj.bias', 'model.layers.17.mlp.up_proj.bias', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.o_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.18.mlp.down_proj.bias', 'model.layers.18.mlp.gate_proj.bias', 'model.layers.18.mlp.up_proj.bias', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.o_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.19.mlp.down_proj.bias', 'model.layers.19.mlp.gate_proj.bias', 'model.layers.19.mlp.up_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.o_proj.bias', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.2.mlp.down_proj.bias', 'model.layers.2.mlp.gate_proj.bias', 'model.layers.2.mlp.up_proj.bias', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.o_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.20.mlp.down_proj.bias', 'model.layers.20.mlp.gate_proj.bias', 'model.layers.20.mlp.up_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.o_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.21.mlp.down_proj.bias', 'model.layers.21.mlp.gate_proj.bias', 'model.layers.21.mlp.up_proj.bias', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.o_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.22.mlp.down_proj.bias', 'model.layers.22.mlp.gate_proj.bias', 'model.layers.22.mlp.up_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.o_proj.bias', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.23.mlp.down_proj.bias', 'model.layers.23.mlp.gate_proj.bias', 'model.layers.23.mlp.up_proj.bias', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.o_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.24.mlp.down_proj.bias', 'model.layers.24.mlp.gate_proj.bias', 'model.layers.24.mlp.up_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.o_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.25.mlp.down_proj.bias', 'model.layers.25.mlp.gate_proj.bias', 'model.layers.25.mlp.up_proj.bias', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.o_proj.bias', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.26.mlp.down_proj.bias', 'model.layers.26.mlp.gate_proj.bias', 'model.layers.26.mlp.up_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.o_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.27.mlp.down_proj.bias', 'model.layers.27.mlp.gate_proj.bias', 'model.layers.27.mlp.up_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.o_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.28.mlp.down_proj.bias', 'model.layers.28.mlp.gate_proj.bias', 'model.layers.28.mlp.up_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.o_proj.bias', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.29.mlp.down_proj.bias', 'model.layers.29.mlp.gate_proj.bias', 'model.layers.29.mlp.up_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.29.self_attn.o_proj.bias', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.3.mlp.down_proj.bias', 'model.layers.3.mlp.gate_proj.bias', 'model.layers.3.mlp.up_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.o_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.30.mlp.down_proj.bias', 'model.layers.30.mlp.gate_proj.bias', 'model.layers.30.mlp.up_proj.bias', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.o_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.31.mlp.down_proj.bias', 'model.layers.31.mlp.gate_proj.bias', 'model.layers.31.mlp.up_proj.bias', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.31.self_attn.o_proj.bias', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.4.mlp.down_proj.bias', 'model.layers.4.mlp.gate_proj.bias', 'model.layers.4.mlp.up_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.o_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.5.mlp.down_proj.bias', 'model.layers.5.mlp.gate_proj.bias', 'model.layers.5.mlp.up_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.o_proj.bias', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.6.mlp.down_proj.bias', 'model.layers.6.mlp.gate_proj.bias', 'model.layers.6.mlp.up_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.o_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.7.mlp.down_proj.bias', 'model.layers.7.mlp.gate_proj.bias', 'model.layers.7.mlp.up_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.o_proj.bias', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.8.mlp.down_proj.bias', 'model.layers.8.mlp.gate_proj.bias', 'model.layers.8.mlp.up_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.o_proj.bias', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.9.mlp.down_proj.bias', 'model.layers.9.mlp.gate_proj.bias', 'model.layers.9.mlp.up_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.o_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.v_proj.bias']\n",
            "- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Downloading readme: 100%|███████████████████| 9.00k/9.00k [00:00<00:00, 265kB/s]\n",
            "Downloading data: 100%|███████████████████████| 190k/190k [00:00<00:00, 788kB/s]\n",
            "Downloading data: 100%|███████████████████████| 204k/204k [00:00<00:00, 939kB/s]\n",
            "Downloading data: 100%|█████████████████████| 55.7k/55.7k [00:00<00:00, 339kB/s]\n",
            "Generating train split: 100%|████| 1119/1119 [00:00<00:00, 137447.69 examples/s]\n",
            "Generating test split: 100%|█████| 1172/1172 [00:00<00:00, 196283.51 examples/s]\n",
            "Generating validation split: 100%|██| 299/299 [00:00<00:00, 84977.43 examples/s]\n",
            "Downloading readme: 100%|███████████████████| 10.5k/10.5k [00:00<00:00, 323kB/s]\n",
            "Downloading data: 100%|████████████████████| 4.15M/4.15M [00:00<00:00, 38.1MB/s]\n",
            "Downloading data: 100%|█████████████████████| 45.3k/45.3k [00:00<00:00, 473kB/s]\n",
            "Generating test split: 100%|███| 12032/12032 [00:00<00:00, 197991.54 examples/s]\n",
            "Generating validation split: 100%|████| 70/70 [00:00<00:00, 19792.46 examples/s]\n",
            "Downloading builder script: 100%|███████████| 5.86k/5.86k [00:00<00:00, 183kB/s]\n",
            "Downloading readme: 100%|██████████████████| 1.11k/1.11k [00:00<00:00, 33.8kB/s]\n",
            "Downloading data: 100%|██████████████████████| 166M/166M [00:02<00:00, 75.4MB/s]\n",
            "Generating test split: 171 examples [00:00, 1600.45 examples/s]\n",
            "Generating validation split: 19 examples [00:00, 4202.49 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 47.60 examples/s]\n",
            "Generating test split: 1534 examples [00:00, 7632.97 examples/s]\n",
            "Generating validation split: 170 examples [00:00, 10684.04 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 50.52 examples/s]\n",
            "Generating test split: 324 examples [00:00, 2748.39 examples/s]\n",
            "Generating validation split: 35 examples [00:00, 5533.80 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.07 examples/s]\n",
            "Generating test split: 311 examples [00:00, 2809.86 examples/s]\n",
            "Generating validation split: 34 examples [00:00, 7408.12 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 50.82 examples/s]\n",
            "Generating test split: 895 examples [00:00, 6143.30 examples/s]\n",
            "Generating validation split: 100 examples [00:00, 10386.83 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.95 examples/s]\n",
            "Generating test split: 346 examples [00:00, 2994.84 examples/s]\n",
            "Generating validation split: 38 examples [00:00, 4848.91 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 50.64 examples/s]\n",
            "Generating test split: 163 examples [00:00, 1617.76 examples/s]\n",
            "Generating validation split: 18 examples [00:00, 3329.40 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 52.46 examples/s]\n",
            "Generating test split: 108 examples [00:00, 1085.48 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 1883.00 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 38.17 examples/s]\n",
            "Generating test split: 121 examples [00:00, 1201.06 examples/s]\n",
            "Generating validation split: 13 examples [00:00, 2840.34 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.43 examples/s]\n",
            "Generating test split: 237 examples [00:00, 2033.90 examples/s]\n",
            "Generating validation split: 26 examples [00:00, 3554.26 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.07 examples/s]\n",
            "Generating test split: 204 examples [00:00, 1917.08 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 3130.29 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.02 examples/s]\n",
            "Generating test split: 165 examples [00:00, 1626.22 examples/s]\n",
            "Generating validation split: 18 examples [00:00, 2662.96 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 52.10 examples/s]\n",
            "Generating test split: 126 examples [00:00, 1194.55 examples/s]\n",
            "Generating validation split: 14 examples [00:00, 3234.03 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.45 examples/s]\n",
            "Generating test split: 100 examples [00:00, 982.65 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2701.88 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.37 examples/s]\n",
            "Generating test split: 201 examples [00:00, 1972.02 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 3373.60 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.26 examples/s]\n",
            "Generating test split: 245 examples [00:00, 2339.47 examples/s]\n",
            "Generating validation split: 27 examples [00:00, 3679.21 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.85 examples/s]\n",
            "Generating test split: 110 examples [00:00, 1134.89 examples/s]\n",
            "Generating validation split: 12 examples [00:00, 2372.01 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 52.46 examples/s]\n",
            "Generating test split: 612 examples [00:00, 4848.19 examples/s]\n",
            "Generating validation split: 69 examples [00:00, 7620.59 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.31 examples/s]\n",
            "Generating test split: 131 examples [00:00, 1348.46 examples/s]\n",
            "Generating validation split: 12 examples [00:00, 2594.01 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.56 examples/s]\n",
            "Generating test split: 545 examples [00:00, 4392.11 examples/s]\n",
            "Generating validation split: 60 examples [00:00, 6909.13 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 50.80 examples/s]\n",
            "Generating test split: 238 examples [00:00, 2198.69 examples/s]\n",
            "Generating validation split: 26 examples [00:00, 4028.07 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.43 examples/s]\n",
            "Generating test split: 390 examples [00:00, 3517.33 examples/s]\n",
            "Generating validation split: 43 examples [00:00, 7194.92 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 52.92 examples/s]\n",
            "Generating test split: 193 examples [00:00, 1947.49 examples/s]\n",
            "Generating validation split: 21 examples [00:00, 5383.89 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 52.49 examples/s]\n",
            "Generating test split: 198 examples [00:00, 1877.80 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 6390.21 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 52.69 examples/s]\n",
            "Generating test split: 114 examples [00:00, 1175.32 examples/s]\n",
            "Generating validation split: 12 examples [00:00, 3021.83 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.29 examples/s]\n",
            "Generating test split: 166 examples [00:00, 1440.66 examples/s]\n",
            "Generating validation split: 18 examples [00:00, 3488.95 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.28 examples/s]\n",
            "Generating test split: 272 examples [00:00, 2430.01 examples/s]\n",
            "Generating validation split: 31 examples [00:00, 5032.45 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.90 examples/s]\n",
            "Generating test split: 282 examples [00:00, 2250.55 examples/s]\n",
            "Generating validation split: 31 examples [00:00, 4231.02 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 52.21 examples/s]\n",
            "Generating test split: 306 examples [00:00, 2804.27 examples/s]\n",
            "Generating validation split: 33 examples [00:00, 5795.18 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.27 examples/s]\n",
            "Generating test split: 783 examples [00:00, 5598.58 examples/s]\n",
            "Generating validation split: 86 examples [00:00, 10780.02 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 50.07 examples/s]\n",
            "Generating test split: 100 examples [00:00, 986.51 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3573.49 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.11 examples/s]\n",
            "Generating test split: 234 examples [00:00, 2177.10 examples/s]\n",
            "Generating validation split: 25 examples [00:00, 4281.30 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 50.26 examples/s]\n",
            "Generating test split: 103 examples [00:00, 1018.39 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2298.71 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.29 examples/s]\n",
            "Generating test split: 223 examples [00:00, 2152.80 examples/s]\n",
            "Generating validation split: 23 examples [00:00, 4251.61 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 52.52 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1042.62 examples/s]\n",
            "Generating validation split: 10 examples [00:00, 2984.21 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 50.11 examples/s]\n",
            "Generating test split: 173 examples [00:00, 1584.78 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 4901.97 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.84 examples/s]\n",
            "Generating test split: 265 examples [00:00, 2397.38 examples/s]\n",
            "Generating validation split: 29 examples [00:00, 6060.23 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.57 examples/s]\n",
            "Generating test split: 100 examples [00:00, 968.53 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3463.24 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 50.76 examples/s]\n",
            "Generating test split: 112 examples [00:00, 1163.06 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2982.18 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.70 examples/s]\n",
            "Generating test split: 216 examples [00:00, 1987.13 examples/s]\n",
            "Generating validation split: 23 examples [00:00, 4173.08 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.10 examples/s]\n",
            "Generating test split: 151 examples [00:00, 1400.45 examples/s]\n",
            "Generating validation split: 17 examples [00:00, 3543.54 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.05 examples/s]\n",
            "Generating test split: 270 examples [00:00, 2568.87 examples/s]\n",
            "Generating validation split: 29 examples [00:00, 6314.76 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.48 examples/s]\n",
            "Generating test split: 100 examples [00:00, 967.96 examples/s]\n",
            "Generating validation split: 9 examples [00:00, 3022.32 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.62 examples/s]\n",
            "Generating test split: 203 examples [00:00, 1960.36 examples/s]\n",
            "Generating validation split: 22 examples [00:00, 3801.69 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.14 examples/s]\n",
            "Generating test split: 310 examples [00:00, 2861.31 examples/s]\n",
            "Generating validation split: 32 examples [00:00, 6688.48 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 50.26 examples/s]\n",
            "Generating test split: 378 examples [00:00, 3200.92 examples/s]\n",
            "Generating validation split: 41 examples [00:00, 5983.32 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 50.50 examples/s]\n",
            "Generating test split: 145 examples [00:00, 1497.49 examples/s]\n",
            "Generating validation split: 16 examples [00:00, 4481.39 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 57.99 examples/s]\n",
            "Generating test split: 235 examples [00:00, 2235.45 examples/s]\n",
            "Generating validation split: 26 examples [00:00, 6760.81 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 50.81 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1026.23 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2426.24 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.00 examples/s]\n",
            "Generating test split: 102 examples [00:00, 1020.25 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 3108.15 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 52.22 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1006.25 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2686.62 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 52.48 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1005.74 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2170.05 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.88 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1044.93 examples/s]\n",
            "Generating validation split: 8 examples [00:00, 1474.01 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.79 examples/s]\n",
            "Generating test split: 144 examples [00:00, 1315.80 examples/s]\n",
            "Generating validation split: 16 examples [00:00, 2750.03 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.89 examples/s]\n",
            "Generating test split: 152 examples [00:00, 1556.87 examples/s]\n",
            "Generating validation split: 16 examples [00:00, 5002.15 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.58 examples/s]\n",
            "Generating test split: 135 examples [00:00, 1366.07 examples/s]\n",
            "Generating validation split: 14 examples [00:00, 4164.85 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 52.85 examples/s]\n",
            "Generating test split: 100 examples [00:00, 1021.72 examples/s]\n",
            "Generating validation split: 11 examples [00:00, 2982.76 examples/s]\n",
            "Generating dev split: 5 examples [00:00, 51.75 examples/s]\n",
            "2024-08-25:15:47:41,321 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-25:15:47:41,321 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,321 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-25:15:47:41,321 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,321 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-25:15:47:41,321 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,321 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-25:15:47:41,321 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,321 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-25:15:47:41,321 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,321 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-25:15:47:41,322 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,322 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-25:15:47:41,322 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,322 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-25:15:47:41,322 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,322 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-25:15:47:41,322 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,322 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-25:15:47:41,322 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,322 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-25:15:47:41,322 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,322 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-25:15:47:41,322 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,322 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-25:15:47:41,322 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,322 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-25:15:47:41,322 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,322 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-25:15:47:41,322 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,322 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-25:15:47:41,322 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,322 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-25:15:47:41,322 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,322 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-25:15:47:41,323 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,323 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-25:15:47:41,323 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,323 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-25:15:47:41,323 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,323 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-25:15:47:41,323 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,323 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-25:15:47:41,323 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,323 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-25:15:47:41,323 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,323 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-25:15:47:41,323 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,323 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-25:15:47:41,323 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,323 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-25:15:47:41,323 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,323 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-25:15:47:41,323 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,323 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-25:15:47:41,323 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,323 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-25:15:47:41,323 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,324 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-25:15:47:41,324 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,324 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-25:15:47:41,324 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,324 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-25:15:47:41,324 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,324 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-25:15:47:41,324 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,324 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-25:15:47:41,324 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,324 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-25:15:47:41,324 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,324 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-25:15:47:41,324 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,324 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-25:15:47:41,324 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,324 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-25:15:47:41,324 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,324 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-25:15:47:41,324 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,324 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-25:15:47:41,324 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,325 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-25:15:47:41,325 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,325 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-25:15:47:41,325 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,325 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-25:15:47:41,325 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,325 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-25:15:47:41,325 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,325 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-25:15:47:41,325 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,325 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-25:15:47:41,325 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,325 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-25:15:47:41,325 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,325 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-25:15:47:41,325 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,325 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-25:15:47:41,325 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,325 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-25:15:47:41,325 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,325 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-25:15:47:41,325 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,325 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-25:15:47:41,326 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,326 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-25:15:47:41,326 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,326 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-25:15:47:41,326 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,326 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-25:15:47:41,326 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,326 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-25:15:47:41,326 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,326 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-25:15:47:41,326 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,326 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-25:15:47:41,326 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,326 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-25:15:47:41,326 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:15:47:41,326 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-25:15:47:41,335 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 576.19it/s]\n",
            "2024-08-25:15:47:41,514 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 578.22it/s]\n",
            "2024-08-25:15:47:41,754 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 573.49it/s]\n",
            "2024-08-25:15:47:42,026 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 568.85it/s]\n",
            "2024-08-25:15:47:42,287 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 570.72it/s]\n",
            "2024-08-25:15:47:42,468 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 575.52it/s]\n",
            "2024-08-25:15:47:42,647 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 565.80it/s]\n",
            "2024-08-25:15:47:42,829 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 568.45it/s]\n",
            "2024-08-25:15:47:43,014 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 575.05it/s]\n",
            "2024-08-25:15:47:43,193 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 567.32it/s]\n",
            "2024-08-25:15:47:43,619 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 565.72it/s]\n",
            "2024-08-25:15:47:43,883 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 578.64it/s]\n",
            "2024-08-25:15:47:44,554 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 657.84it/s]\n",
            "2024-08-25:15:47:45,041 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 695.16it/s]\n",
            "2024-08-25:15:47:45,342 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 697.27it/s]\n",
            "2024-08-25:15:47:45,489 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 690.70it/s]\n",
            "2024-08-25:15:47:45,891 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 698.06it/s]\n",
            "2024-08-25:15:47:46,114 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 696.71it/s]\n",
            "2024-08-25:15:47:46,434 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 700.92it/s]\n",
            "2024-08-25:15:47:46,598 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 703.47it/s]\n",
            "2024-08-25:15:47:46,745 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 703.82it/s]\n",
            "2024-08-25:15:47:47,132 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 703.52it/s]\n",
            "2024-08-25:15:47:47,386 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 699.44it/s]\n",
            "2024-08-25:15:47:47,533 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 633.46it/s]\n",
            "2024-08-25:15:47:47,894 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 564.18it/s]\n",
            "2024-08-25:15:47:48,082 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 407.52it/s]\n",
            "2024-08-25:15:47:48,668 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 574.95it/s]\n",
            "2024-08-25:15:47:48,848 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 649.91it/s]\n",
            "2024-08-25:15:47:50,090 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 708.00it/s]\n",
            "2024-08-25:15:47:50,535 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 686.13it/s]\n",
            "2024-08-25:15:47:50,959 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 711.41it/s]\n",
            "2024-08-25:15:47:51,352 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 704.73it/s]\n",
            "2024-08-25:15:47:51,596 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 700.06it/s]\n",
            "2024-08-25:15:47:51,764 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 700.86it/s]\n",
            "2024-08-25:15:47:52,054 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 695.84it/s]\n",
            "2024-08-25:15:47:52,340 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 690.28it/s]\n",
            "2024-08-25:15:47:52,921 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 623.83it/s]\n",
            "2024-08-25:15:47:53,313 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 621.09it/s]\n",
            "2024-08-25:15:47:54,222 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 608.54it/s]\n",
            "2024-08-25:15:47:54,445 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 683.14it/s]\n",
            "2024-08-25:15:47:55,365 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 578.89it/s]\n",
            "2024-08-25:15:47:55,560 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 686.20it/s]\n",
            "2024-08-25:15:47:55,930 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 649.30it/s]\n",
            "2024-08-25:15:47:56,249 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 623.59it/s]\n",
            "2024-08-25:15:47:56,414 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 644.21it/s]\n",
            "2024-08-25:15:47:56,617 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 700.89it/s]\n",
            "2024-08-25:15:47:56,860 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 698.02it/s]\n",
            "2024-08-25:15:47:57,161 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 700.17it/s]\n",
            "2024-08-25:15:47:57,510 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 706.18it/s]\n",
            "2024-08-25:15:47:57,687 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 694.81it/s]\n",
            "2024-08-25:15:47:57,847 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 692.70it/s]\n",
            "2024-08-25:15:47:58,090 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 698.99it/s]\n",
            "2024-08-25:15:47:58,599 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 590.57it/s]\n",
            "2024-08-25:15:48:00,149 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 696.03it/s]\n",
            "2024-08-25:15:48:00,609 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 697.52it/s]\n",
            "2024-08-25:15:48:01,088 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 693.36it/s]\n",
            "2024-08-25:15:48:03,362 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 701.56it/s]\n",
            "2024-08-25:15:48:03,613 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 15032.10it/s]\n",
            "2024-08-25:15:48:05,268 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1343.90it/s]\n",
            "2024-08-25:15:48:06,201 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n",
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
            "Running loglikelihood requests: 100%|███| 174850/174850 [44:28<00:00, 65.54it/s]\n",
            "2024-08-25:16:34:39,361 WARNING  [huggingface.py:1427] Failed to get model SHA for ./AutoRound/Meta-Llama-3.1-8B-AutoRound-GPTQ-asym-4bit at revision main. Error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './AutoRound/Meta-Llama-3.1-8B-AutoRound-GPTQ-asym-4bit'. Use `repo_type` argument if needed.\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-25:16:34:40,451 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=./AutoRound/Meta-Llama-3.1-8B-AutoRound-GPTQ-asym-4bit), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.5017|±  |0.0146|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.5324|±  |0.0146|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.3013|±  |0.0042|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.6135|±  |0.0039|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5554|±  |0.0068|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.4048|±  |0.0439|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7212|±  |0.0350|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.8137|±  |0.0273|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.8186|±  |0.0251|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.7934|±  |0.0370|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.7500|±  |0.0419|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7607|±  |0.0335|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.6590|±  |0.0255|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2872|±  |0.0151|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.6688|±  |0.0267|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.7037|±  |0.0254|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4720|±  |0.0128|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.8012|±  |0.0306|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.6888|±  |0.0080|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.6000|±  |0.0492|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.6906|±  |0.0285|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.6358|±  |0.0367|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.3700|±  |0.0485|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.6368|±  |0.0323|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.8350|±  |0.0368|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8590|±  |0.0228|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.7700|±  |0.0423|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.8008|±  |0.0143|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.6993|±  |0.0263|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.4716|±  |0.0298|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.6801|±  |0.0283|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5120|±  |0.0389|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.7143|±  |0.0080|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.4035|±  |0.0462|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.7727|±  |0.0299|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8549|±  |0.0254|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.6000|±  |0.0248|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.6513|±  |0.0310|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.8183|±  |0.0165|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.7252|±  |0.0392|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.6846|±  |0.0188|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6818|±  |0.0446|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.6857|±  |0.0297|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.8010|±  |0.0282|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.8100|±  |0.0394|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5278|±  |0.0086|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3100|±  |0.0465|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.6370|±  |0.0415|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.7039|±  |0.0372|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.7708|±  |0.0351|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4500|±  |0.0500|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.4700|±  |0.0502|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.3800|±  |0.0488|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.4118|±  |0.0490|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.7200|±  |0.0451|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5447|±  |0.0326|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.5724|±  |0.0412|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4206|±  |0.0254|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7677|±  |0.0240|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.4877|±  |0.0352|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.6100|±  |0.0490|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3407|±  |0.0289|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.4238|±  |0.0403|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.5093|±  |0.0341|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.4554|±  |0.0473|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.6135|±  |0.0039|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5554|±  |0.0068|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.6888|±  |0.0080|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.7143|±  |0.0080|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5278|±  |0.0086|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=./AutoRound/Meta-Llama-3.1-8B-AutoRound-GPTQ-asym-4bit --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###nvidia/Llama-3.1-Minitron-4B-Width-Base"
      ],
      "metadata": {
        "id": "5gI1rH3SGGMC"
      },
      "id": "5gI1rH3SGGMC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1ec82f4-320b-4f40-ad8e-efce1c7a619d",
      "metadata": {
        "id": "f1ec82f4-320b-4f40-ad8e-efce1c7a619d",
        "outputId": "2dacf7e0-3d0e-4715-911c-50b2bd0b05cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-24:13:29:10,893 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-24:13:29:10,996 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-24:13:29:25,356 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-24:13:29:25,359 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-24:13:29:25,359 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'nvidia/Llama-3.1-Minitron-4B-Width-Base', 'dtype': 'float16'}\n",
            "2024-08-24:13:29:25,596 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-24:13:29:25,596 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "2024-08-24:13:29:26,467 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:15<00:00,  7.70s/it]\n",
            "2024-08-24:13:30:13,823 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-24:13:30:13,824 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,824 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-24:13:30:13,824 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,824 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-24:13:30:13,824 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,824 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-24:13:30:13,824 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,824 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-24:13:30:13,824 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,824 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-24:13:30:13,824 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,824 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-24:13:30:13,824 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,824 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-24:13:30:13,824 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,824 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-24:13:30:13,824 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,824 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-24:13:30:13,824 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,824 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-24:13:30:13,825 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,825 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-24:13:30:13,825 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,825 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-24:13:30:13,825 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,825 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-24:13:30:13,825 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,825 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-24:13:30:13,825 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,825 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-24:13:30:13,825 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,825 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-24:13:30:13,825 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,825 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-24:13:30:13,825 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,825 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-24:13:30:13,825 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,825 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-24:13:30:13,825 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,825 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-24:13:30:13,825 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,825 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-24:13:30:13,825 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,825 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-24:13:30:13,826 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,826 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-24:13:30:13,826 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,826 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-24:13:30:13,826 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,826 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-24:13:30:13,826 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,826 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-24:13:30:13,826 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,826 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-24:13:30:13,826 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,826 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-24:13:30:13,826 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,826 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-24:13:30:13,826 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,826 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-24:13:30:13,826 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,826 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-24:13:30:13,826 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,826 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-24:13:30:13,826 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,826 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-24:13:30:13,826 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,826 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-24:13:30:13,827 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,827 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-24:13:30:13,827 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,827 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-24:13:30:13,827 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,827 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-24:13:30:13,827 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,827 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-24:13:30:13,827 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,827 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-24:13:30:13,827 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,827 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-24:13:30:13,827 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,827 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-24:13:30:13,827 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,827 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-24:13:30:13,827 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,827 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-24:13:30:13,827 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,827 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-24:13:30:13,827 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,827 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-24:13:30:13,827 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,827 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-24:13:30:13,828 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,828 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-24:13:30:13,828 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,828 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-24:13:30:13,828 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,828 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-24:13:30:13,828 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,828 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-24:13:30:13,828 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,828 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-24:13:30:13,828 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,828 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-24:13:30:13,828 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,828 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-24:13:30:13,828 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,828 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-24:13:30:13,828 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,828 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-24:13:30:13,828 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,828 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-24:13:30:13,828 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,828 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-24:13:30:13,828 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,829 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-24:13:30:13,829 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:30:13,829 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-24:13:30:13,841 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 531.33it/s]\n",
            "2024-08-24:13:30:14,035 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 546.04it/s]\n",
            "2024-08-24:13:30:14,289 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 550.40it/s]\n",
            "2024-08-24:13:30:14,574 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 552.84it/s]\n",
            "2024-08-24:13:30:14,842 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 552.95it/s]\n",
            "2024-08-24:13:30:15,028 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 549.21it/s]\n",
            "2024-08-24:13:30:15,216 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 543.81it/s]\n",
            "2024-08-24:13:30:15,405 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 546.79it/s]\n",
            "2024-08-24:13:30:15,597 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 555.23it/s]\n",
            "2024-08-24:13:30:15,783 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 550.67it/s]\n",
            "2024-08-24:13:30:16,222 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 541.67it/s]\n",
            "2024-08-24:13:30:16,497 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 534.80it/s]\n",
            "2024-08-24:13:30:17,222 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 553.98it/s]\n",
            "2024-08-24:13:30:17,798 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 555.96it/s]\n",
            "2024-08-24:13:30:18,174 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 555.10it/s]\n",
            "2024-08-24:13:30:18,359 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 550.64it/s]\n",
            "2024-08-24:13:30:18,863 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 581.34it/s]\n",
            "2024-08-24:13:30:19,130 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 584.85it/s]\n",
            "2024-08-24:13:30:19,510 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 586.01it/s]\n",
            "2024-08-24:13:30:19,707 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 587.21it/s]\n",
            "2024-08-24:13:30:19,882 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 587.50it/s]\n",
            "2024-08-24:13:30:20,346 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 586.21it/s]\n",
            "2024-08-24:13:30:20,650 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 586.77it/s]\n",
            "2024-08-24:13:30:20,825 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 588.45it/s]\n",
            "2024-08-24:13:30:21,215 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 586.30it/s]\n",
            "2024-08-24:13:30:21,396 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 381.98it/s]\n",
            "2024-08-24:13:30:22,020 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 581.36it/s]\n",
            "2024-08-24:13:30:22,197 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 580.58it/s]\n",
            "2024-08-24:13:30:23,582 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 587.60it/s]\n",
            "2024-08-24:13:30:24,117 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 609.72it/s]\n",
            "2024-08-24:13:30:24,593 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 683.32it/s]\n",
            "2024-08-24:13:30:25,003 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 695.19it/s]\n",
            "2024-08-24:13:30:25,249 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 692.84it/s]\n",
            "2024-08-24:13:30:25,418 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 697.81it/s]\n",
            "2024-08-24:13:30:25,711 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 698.36it/s]\n",
            "2024-08-24:13:30:25,995 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 644.95it/s]\n",
            "2024-08-24:13:30:26,615 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 572.95it/s]\n",
            "2024-08-24:13:30:27,042 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 586.63it/s]\n",
            "2024-08-24:13:30:27,997 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 586.60it/s]\n",
            "2024-08-24:13:30:28,227 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:01<00:00, 585.13it/s]\n",
            "2024-08-24:13:30:29,301 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 585.47it/s]\n",
            "2024-08-24:13:30:29,494 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 596.57it/s]\n",
            "2024-08-24:13:30:29,917 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 697.25it/s]\n",
            "2024-08-24:13:30:30,213 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 684.74it/s]\n",
            "2024-08-24:13:30:30,364 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 685.16it/s]\n",
            "2024-08-24:13:30:30,553 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 657.27it/s]\n",
            "2024-08-24:13:30:30,812 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 690.00it/s]\n",
            "2024-08-24:13:30:31,117 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 678.91it/s]\n",
            "2024-08-24:13:30:31,476 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 694.39it/s]\n",
            "2024-08-24:13:30:31,655 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 708.35it/s]\n",
            "2024-08-24:13:30:31,813 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 709.06it/s]\n",
            "2024-08-24:13:30:32,049 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 711.32it/s]\n",
            "2024-08-24:13:30:32,549 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 589.41it/s]\n",
            "2024-08-24:13:30:34,102 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 699.04it/s]\n",
            "2024-08-24:13:30:34,560 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 679.96it/s]\n",
            "2024-08-24:13:30:35,050 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 679.43it/s]\n",
            "2024-08-24:13:30:37,370 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 685.02it/s]\n",
            "2024-08-24:13:30:37,627 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 14495.36it/s]\n",
            "2024-08-24:13:30:39,276 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1376.47it/s]\n",
            "2024-08-24:13:30:40,187 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n",
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
            "Running loglikelihood requests: 100%|██| 174850/174850 [09:50<00:00, 296.28it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-24:13:42:27,078 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=nvidia/Llama-3.1-Minitron-4B-Width-Base,dtype=float16), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.4497|±  |0.0145|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.5085|±  |0.0146|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.2673|±  |0.0040|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.5934|±  |0.0039|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5535|±  |0.0068|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.4127|±  |0.0440|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7455|±  |0.0340|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.7892|±  |0.0286|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.7806|±  |0.0269|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.7603|±  |0.0390|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.7315|±  |0.0428|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7853|±  |0.0323|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.6734|±  |0.0252|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2737|±  |0.0149|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.6752|±  |0.0266|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.6914|±  |0.0257|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4798|±  |0.0128|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.7953|±  |0.0309|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.6543|±  |0.0082|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.6000|±  |0.0492|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.6340|±  |0.0296|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.6243|±  |0.0369|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.3600|±  |0.0482|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.6413|±  |0.0322|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.7087|±  |0.0450|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8205|±  |0.0251|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.7200|±  |0.0451|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.7931|±  |0.0145|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.6699|±  |0.0269|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.4397|±  |0.0296|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.5404|±  |0.0303|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5060|±  |0.0389|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.6802|±  |0.0082|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.3596|±  |0.0451|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.7727|±  |0.0299|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8705|±  |0.0242|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.5667|±  |0.0251|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.6387|±  |0.0312|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.7817|±  |0.0177|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.6794|±  |0.0409|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.6046|±  |0.0198|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6364|±  |0.0461|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.6857|±  |0.0297|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.7811|±  |0.0292|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.7800|±  |0.0416|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5084|±  |0.0086|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.2700|±  |0.0446|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.5704|±  |0.0428|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.6711|±  |0.0382|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.7361|±  |0.0369|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4300|±  |0.0498|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.3900|±  |0.0490|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.3800|±  |0.0488|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.3431|±  |0.0472|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.7500|±  |0.0435|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5404|±  |0.0326|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.4759|±  |0.0416|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4233|±  |0.0254|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7452|±  |0.0248|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.5025|±  |0.0352|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.6000|±  |0.0492|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3630|±  |0.0293|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.3775|±  |0.0396|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.4676|±  |0.0340|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.5000|±  |0.0475|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.5934|±  |0.0039|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5535|±  |0.0068|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.6543|±  |0.0082|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.6802|±  |0.0082|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5084|±  |0.0086|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=nvidia/Llama-3.1-Minitron-4B-Width-Base,dtype=float16 --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea359eb4-3bd3-41bc-988e-6bbd3614ad52",
      "metadata": {
        "id": "ea359eb4-3bd3-41bc-988e-6bbd3614ad52",
        "outputId": "37142e27-5ece-4d5c-e7ec-8cf32e16df4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-24:13:42:33,070 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-24:13:42:33,182 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-24:13:42:46,698 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-24:13:42:46,700 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-24:13:42:46,700 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'nvidia/Llama-3.1-Minitron-4B-Width-Base', 'load_in_8bit': True}\n",
            "2024-08-24:13:42:46,933 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-24:13:42:46,934 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "2024-08-24:13:42:47,394 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:14<00:00,  7.11s/it]\n",
            "2024-08-24:13:43:02,851 WARNING  [big_modeling.py:451] You shouldn't move a model that is dispatched using accelerate hooks.\n",
            "2024-08-24:13:43:33,502 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-24:13:43:33,502 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,502 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-24:13:43:33,502 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,502 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-24:13:43:33,502 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,502 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-24:13:43:33,502 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,502 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-24:13:43:33,502 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,502 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-24:13:43:33,502 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,502 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-24:13:43:33,502 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,502 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-24:13:43:33,502 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,502 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-24:13:43:33,502 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,502 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-24:13:43:33,502 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,502 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-24:13:43:33,502 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,503 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-24:13:43:33,503 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,503 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-24:13:43:33,503 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,503 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-24:13:43:33,503 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,503 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-24:13:43:33,503 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,503 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-24:13:43:33,503 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,503 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-24:13:43:33,503 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,503 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-24:13:43:33,503 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,503 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-24:13:43:33,503 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,503 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-24:13:43:33,503 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,503 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-24:13:43:33,503 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,503 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-24:13:43:33,503 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,503 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-24:13:43:33,503 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,503 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-24:13:43:33,503 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,504 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-24:13:43:33,504 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,504 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-24:13:43:33,504 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,504 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-24:13:43:33,504 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,504 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-24:13:43:33,504 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,504 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-24:13:43:33,504 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,504 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-24:13:43:33,504 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,504 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-24:13:43:33,504 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,504 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-24:13:43:33,504 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,504 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-24:13:43:33,504 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,504 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-24:13:43:33,504 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,504 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-24:13:43:33,504 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,504 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-24:13:43:33,504 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,504 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-24:13:43:33,504 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,505 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-24:13:43:33,505 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,505 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-24:13:43:33,505 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,505 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-24:13:43:33,505 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,505 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-24:13:43:33,505 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,505 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-24:13:43:33,505 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,505 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-24:13:43:33,505 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,505 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-24:13:43:33,505 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,505 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-24:13:43:33,505 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,505 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-24:13:43:33,505 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,505 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-24:13:43:33,505 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,505 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-24:13:43:33,505 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,505 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-24:13:43:33,505 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,505 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-24:13:43:33,505 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,506 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-24:13:43:33,506 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,506 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-24:13:43:33,506 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,506 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-24:13:43:33,506 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,506 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-24:13:43:33,506 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,506 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-24:13:43:33,506 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,506 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-24:13:43:33,506 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,506 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-24:13:43:33,506 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,506 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-24:13:43:33,506 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,506 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-24:13:43:33,506 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:13:43:33,506 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-24:13:43:33,515 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 570.08it/s]\n",
            "2024-08-24:13:43:33,695 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 573.43it/s]\n",
            "2024-08-24:13:43:33,938 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 573.22it/s]\n",
            "2024-08-24:13:43:34,211 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 574.98it/s]\n",
            "2024-08-24:13:43:34,468 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 546.25it/s]\n",
            "2024-08-24:13:43:34,657 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 577.96it/s]\n",
            "2024-08-24:13:43:34,835 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 568.40it/s]\n",
            "2024-08-24:13:43:35,016 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 574.63it/s]\n",
            "2024-08-24:13:43:35,199 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 558.10it/s]\n",
            "2024-08-24:13:43:35,383 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 575.73it/s]\n",
            "2024-08-24:13:43:35,804 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 583.31it/s]\n",
            "2024-08-24:13:43:36,060 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 581.23it/s]\n",
            "2024-08-24:13:43:36,728 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 583.84it/s]\n",
            "2024-08-24:13:43:37,274 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 701.68it/s]\n",
            "2024-08-24:13:43:37,571 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 709.76it/s]\n",
            "2024-08-24:13:43:37,718 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 703.40it/s]\n",
            "2024-08-24:13:43:38,112 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 710.72it/s]\n",
            "2024-08-24:13:43:38,331 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 682.07it/s]\n",
            "2024-08-24:13:43:38,657 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 708.20it/s]\n",
            "2024-08-24:13:43:38,820 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 703.97it/s]\n",
            "2024-08-24:13:43:38,966 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 702.95it/s]\n",
            "2024-08-24:13:43:39,354 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 698.33it/s]\n",
            "2024-08-24:13:43:39,609 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 684.73it/s]\n",
            "2024-08-24:13:43:39,759 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 700.20it/s]\n",
            "2024-08-24:13:43:40,087 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 701.05it/s]\n",
            "2024-08-24:13:43:40,238 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 693.54it/s]\n",
            "2024-08-24:13:43:40,586 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 690.83it/s]\n",
            "2024-08-24:13:43:40,735 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 588.83it/s]\n",
            "2024-08-24:13:43:42,096 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 706.12it/s]\n",
            "2024-08-24:13:43:42,542 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 702.32it/s]\n",
            "2024-08-24:13:43:42,955 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 700.58it/s]\n",
            "2024-08-24:13:43:43,354 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 698.68it/s]\n",
            "2024-08-24:13:43:43,599 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 707.44it/s]\n",
            "2024-08-24:13:43:43,765 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 701.54it/s]\n",
            "2024-08-24:13:43:44,055 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 687.31it/s]\n",
            "2024-08-24:13:43:44,344 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 699.64it/s]\n",
            "2024-08-24:13:43:44,918 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 682.85it/s]\n",
            "2024-08-24:13:43:45,276 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 703.83it/s]\n",
            "2024-08-24:13:43:46,072 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 697.03it/s]\n",
            "2024-08-24:13:43:46,266 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 693.54it/s]\n",
            "2024-08-24:13:43:47,172 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 695.36it/s]\n",
            "2024-08-24:13:43:47,335 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 695.41it/s]\n",
            "2024-08-24:13:43:47,697 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 697.91it/s]\n",
            "2024-08-24:13:43:47,994 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 713.68it/s]\n",
            "2024-08-24:13:43:48,138 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 711.01it/s]\n",
            "2024-08-24:13:43:48,321 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 705.56it/s]\n",
            "2024-08-24:13:43:48,562 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 693.10it/s]\n",
            "2024-08-24:13:43:48,865 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 707.56it/s]\n",
            "2024-08-24:13:43:49,210 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 712.58it/s]\n",
            "2024-08-24:13:43:49,385 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 712.66it/s]\n",
            "2024-08-24:13:43:49,541 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 708.80it/s]\n",
            "2024-08-24:13:43:49,778 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 716.71it/s]\n",
            "2024-08-24:13:43:50,274 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 588.23it/s]\n",
            "2024-08-24:13:43:51,829 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 711.56it/s]\n",
            "2024-08-24:13:43:52,278 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 710.56it/s]\n",
            "2024-08-24:13:43:52,747 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 627.97it/s]\n",
            "2024-08-24:13:43:55,253 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 554.20it/s]\n",
            "2024-08-24:13:43:55,571 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 15380.20it/s]\n",
            "2024-08-24:13:43:57,329 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1357.09it/s]\n",
            "2024-08-24:13:43:58,255 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
            "Running loglikelihood requests: 100%|██| 174850/174850 [26:52<00:00, 108.47it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-24:14:12:45,914 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=nvidia/Llama-3.1-Minitron-4B-Width-Base,load_in_8bit=True), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.4548|±  |0.0146|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.4983|±  |0.0146|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.2608|±  |0.0040|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.5889|±  |0.0039|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5520|±  |0.0068|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.3889|±  |0.0436|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7333|±  |0.0345|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.8186|±  |0.0270|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.8017|±  |0.0260|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.7603|±  |0.0390|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.6852|±  |0.0449|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7730|±  |0.0329|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.6590|±  |0.0255|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2704|±  |0.0149|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.6817|±  |0.0265|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.6975|±  |0.0256|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4798|±  |0.0128|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.7836|±  |0.0316|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.6498|±  |0.0083|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.6200|±  |0.0488|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.6453|±  |0.0294|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.6127|±  |0.0371|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.3600|±  |0.0482|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.6413|±  |0.0322|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.7184|±  |0.0445|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8205|±  |0.0251|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.7400|±  |0.0441|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.7803|±  |0.0148|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.6601|±  |0.0271|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.4433|±  |0.0296|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.5037|±  |0.0304|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5181|±  |0.0389|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.6718|±  |0.0082|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.3421|±  |0.0446|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.7727|±  |0.0299|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8497|±  |0.0258|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.5538|±  |0.0252|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.6218|±  |0.0315|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.7798|±  |0.0178|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.6565|±  |0.0416|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.5997|±  |0.0198|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6273|±  |0.0463|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.6776|±  |0.0299|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.7711|±  |0.0297|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.7900|±  |0.0409|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5030|±  |0.0086|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3100|±  |0.0465|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.5556|±  |0.0429|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.6316|±  |0.0393|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.7292|±  |0.0372|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4300|±  |0.0498|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.4100|±  |0.0494|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.3400|±  |0.0476|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.3529|±  |0.0476|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.7500|±  |0.0435|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5149|±  |0.0327|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.4621|±  |0.0415|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4418|±  |0.0256|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7419|±  |0.0249|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.4877|±  |0.0352|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.6100|±  |0.0490|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3630|±  |0.0293|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.3576|±  |0.0391|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.4583|±  |0.0340|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.4821|±  |0.0474|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.5889|±  |0.0039|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5520|±  |0.0068|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.6498|±  |0.0083|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.6718|±  |0.0082|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5030|±  |0.0086|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=nvidia/Llama-3.1-Minitron-4B-Width-Base,load_in_8bit=True --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fa078e8-dfdb-4e20-afa4-8aefcdd754da",
      "metadata": {
        "id": "0fa078e8-dfdb-4e20-afa4-8aefcdd754da",
        "outputId": "a56c7cc0-99fa-44c2-fff2-638e7b1b82d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-24:14:42:04,039 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-24:14:42:04,131 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-24:14:42:18,942 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-24:14:42:18,944 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-24:14:42:18,944 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'nvidia/Llama-3.1-Minitron-4B-Width-Base', 'load_in_4bit': True}\n",
            "2024-08-24:14:42:19,183 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-24:14:42:19,184 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "2024-08-24:14:42:19,621 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.35s/it]\n",
            "2024-08-24:14:42:25,725 WARNING  [big_modeling.py:451] You shouldn't move a model that is dispatched using accelerate hooks.\n",
            "2024-08-24:14:42:57,104 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-24:14:42:57,105 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,105 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-24:14:42:57,105 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,105 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-24:14:42:57,105 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,105 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-24:14:42:57,105 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,105 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-24:14:42:57,105 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,105 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-24:14:42:57,105 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,105 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-24:14:42:57,105 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,105 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-24:14:42:57,105 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,105 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-24:14:42:57,105 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,105 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-24:14:42:57,105 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,105 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-24:14:42:57,105 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,105 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-24:14:42:57,105 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,105 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-24:14:42:57,105 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,105 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-24:14:42:57,105 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,106 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-24:14:42:57,106 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,106 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-24:14:42:57,106 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,106 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-24:14:42:57,106 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,106 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-24:14:42:57,106 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,106 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-24:14:42:57,106 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,106 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-24:14:42:57,106 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,106 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-24:14:42:57,106 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,106 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-24:14:42:57,106 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,106 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-24:14:42:57,106 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,106 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-24:14:42:57,106 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,106 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-24:14:42:57,106 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,106 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-24:14:42:57,106 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,106 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-24:14:42:57,106 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,106 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-24:14:42:57,107 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,107 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-24:14:42:57,107 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,107 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-24:14:42:57,107 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,107 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-24:14:42:57,107 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,107 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-24:14:42:57,107 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,107 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-24:14:42:57,107 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,107 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-24:14:42:57,107 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,107 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-24:14:42:57,107 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,107 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-24:14:42:57,107 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,107 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-24:14:42:57,107 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,107 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-24:14:42:57,107 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,107 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-24:14:42:57,107 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,108 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-24:14:42:57,108 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,108 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-24:14:42:57,108 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,108 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-24:14:42:57,108 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,108 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-24:14:42:57,108 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,108 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-24:14:42:57,108 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,108 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-24:14:42:57,108 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,108 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-24:14:42:57,108 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,108 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-24:14:42:57,108 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,108 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-24:14:42:57,108 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,108 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-24:14:42:57,108 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,108 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-24:14:42:57,108 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,109 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-24:14:42:57,109 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,109 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-24:14:42:57,109 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,109 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-24:14:42:57,109 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,109 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-24:14:42:57,109 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,109 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-24:14:42:57,109 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,109 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-24:14:42:57,109 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,109 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-24:14:42:57,109 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,109 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-24:14:42:57,109 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,109 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-24:14:42:57,109 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:42:57,109 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-24:14:42:57,119 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 568.17it/s]\n",
            "2024-08-24:14:42:57,301 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 567.73it/s]\n",
            "2024-08-24:14:42:57,546 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 562.31it/s]\n",
            "2024-08-24:14:42:57,824 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 564.94it/s]\n",
            "2024-08-24:14:42:58,087 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 568.53it/s]\n",
            "2024-08-24:14:42:58,270 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 561.55it/s]\n",
            "2024-08-24:14:42:58,453 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 577.22it/s]\n",
            "2024-08-24:14:42:58,632 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 572.58it/s]\n",
            "2024-08-24:14:42:58,816 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 569.52it/s]\n",
            "2024-08-24:14:42:58,997 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 570.83it/s]\n",
            "2024-08-24:14:42:59,421 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 577.00it/s]\n",
            "2024-08-24:14:42:59,680 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 579.70it/s]\n",
            "2024-08-24:14:43:00,351 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 583.00it/s]\n",
            "2024-08-24:14:43:00,898 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 580.92it/s]\n",
            "2024-08-24:14:43:01,258 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 579.78it/s]\n",
            "2024-08-24:14:43:01,436 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 583.02it/s]\n",
            "2024-08-24:14:43:01,912 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 579.48it/s]\n",
            "2024-08-24:14:43:02,182 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 572.97it/s]\n",
            "2024-08-24:14:43:02,570 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 564.81it/s]\n",
            "2024-08-24:14:43:02,775 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 578.85it/s]\n",
            "2024-08-24:14:43:02,953 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 574.50it/s]\n",
            "2024-08-24:14:43:03,427 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 577.25it/s]\n",
            "2024-08-24:14:43:03,736 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 572.74it/s]\n",
            "2024-08-24:14:43:03,916 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 576.96it/s]\n",
            "2024-08-24:14:43:04,314 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 579.15it/s]\n",
            "2024-08-24:14:43:04,498 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 572.21it/s]\n",
            "2024-08-24:14:43:04,918 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 583.02it/s]\n",
            "2024-08-24:14:43:05,095 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 678.28it/s]\n",
            "2024-08-24:14:43:06,448 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 690.84it/s]\n",
            "2024-08-24:14:43:06,905 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 682.17it/s]\n",
            "2024-08-24:14:43:07,331 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 679.62it/s]\n",
            "2024-08-24:14:43:07,743 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 685.74it/s]\n",
            "2024-08-24:14:43:07,992 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 688.80it/s]\n",
            "2024-08-24:14:43:08,163 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 688.77it/s]\n",
            "2024-08-24:14:43:08,459 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 680.84it/s]\n",
            "2024-08-24:14:43:08,751 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 681.35it/s]\n",
            "2024-08-24:14:43:09,340 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 667.43it/s]\n",
            "2024-08-24:14:43:09,706 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 682.42it/s]\n",
            "2024-08-24:14:43:10,528 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 682.27it/s]\n",
            "2024-08-24:14:43:10,726 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 678.79it/s]\n",
            "2024-08-24:14:43:11,653 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 678.62it/s]\n",
            "2024-08-24:14:43:11,821 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 572.75it/s]\n",
            "2024-08-24:14:43:12,260 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 582.81it/s]\n",
            "2024-08-24:14:43:12,615 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 578.74it/s]\n",
            "2024-08-24:14:43:12,793 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 577.04it/s]\n",
            "2024-08-24:14:43:13,018 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 577.89it/s]\n",
            "2024-08-24:14:43:13,313 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 577.63it/s]\n",
            "2024-08-24:14:43:13,677 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 580.22it/s]\n",
            "2024-08-24:14:43:14,098 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 579.17it/s]\n",
            "2024-08-24:14:43:14,314 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 554.67it/s]\n",
            "2024-08-24:14:43:14,515 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 582.09it/s]\n",
            "2024-08-24:14:43:14,803 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 586.96it/s]\n",
            "2024-08-24:14:43:15,410 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 516.73it/s]\n",
            "2024-08-24:14:43:17,185 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 685.33it/s]\n",
            "2024-08-24:14:43:17,652 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 688.36it/s]\n",
            "2024-08-24:14:43:18,136 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 668.55it/s]\n",
            "2024-08-24:14:43:20,494 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 647.54it/s]\n",
            "2024-08-24:14:43:20,766 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 16099.52it/s]\n",
            "2024-08-24:14:43:22,363 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1293.10it/s]\n",
            "2024-08-24:14:43:23,332 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n",
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
            "Running loglikelihood requests: 100%|██| 174850/174850 [12:23<00:00, 235.21it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-24:14:57:44,027 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=nvidia/Llama-3.1-Minitron-4B-Width-Base,load_in_4bit=True), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.4480|±  |0.0145|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.4889|±  |0.0146|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.2307|±  |0.0038|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.5550|±  |0.0040|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5080|±  |0.0068|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.3651|±  |0.0431|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.6970|±  |0.0359|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.7157|±  |0.0317|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.7595|±  |0.0278|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.7273|±  |0.0407|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.6296|±  |0.0467|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7239|±  |0.0351|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.6214|±  |0.0261|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2380|±  |0.0142|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.6527|±  |0.0270|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.6451|±  |0.0266|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4342|±  |0.0127|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.7193|±  |0.0345|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.6118|±  |0.0084|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.5800|±  |0.0496|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.5962|±  |0.0302|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.6012|±  |0.0373|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.2800|±  |0.0451|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.6054|±  |0.0328|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.6505|±  |0.0472|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8162|±  |0.0254|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.6900|±  |0.0465|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.7395|±  |0.0157|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.6209|±  |0.0278|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.4007|±  |0.0292|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.4963|±  |0.0304|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.4458|±  |0.0387|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.6493|±  |0.0084|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.3246|±  |0.0440|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.7273|±  |0.0317|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.7617|±  |0.0307|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.5385|±  |0.0253|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.6134|±  |0.0316|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.7615|±  |0.0183|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.6641|±  |0.0414|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.5833|±  |0.0199|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6091|±  |0.0467|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.6653|±  |0.0302|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.7562|±  |0.0304|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.7300|±  |0.0446|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.4770|±  |0.0086|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.2600|±  |0.0441|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.4963|±  |0.0432|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.5855|±  |0.0401|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.6458|±  |0.0400|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4100|±  |0.0494|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.3700|±  |0.0485|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.3500|±  |0.0479|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.4020|±  |0.0488|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.7300|±  |0.0446|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5277|±  |0.0326|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.4621|±  |0.0415|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.3942|±  |0.0252|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.6968|±  |0.0261|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.4828|±  |0.0352|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.5700|±  |0.0498|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3296|±  |0.0287|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.3907|±  |0.0398|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.4306|±  |0.0338|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.4464|±  |0.0472|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.5550|±  |0.0040|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5080|±  |0.0068|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.6118|±  |0.0084|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.6493|±  |0.0084|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.4770|±  |0.0086|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=nvidia/Llama-3.1-Minitron-4B-Width-Base,load_in_4bit=True --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a619287c-5cec-429c-8d04-437d85431543",
      "metadata": {
        "id": "a619287c-5cec-429c-8d04-437d85431543",
        "outputId": "5b5e3e11-6474-4744-9ab2-0cb562f5bbef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-24:14:12:51,656 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-24:14:12:51,749 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-24:14:13:04,680 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-24:14:13:04,682 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-24:14:13:04,682 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'kaitchup/Llama-3.1-Minitron-4B-Width-Base-AutoRound-GPTQ-sym-4bit'}\n",
            "2024-08-24:14:13:04,894 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-24:14:13:04,894 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "2024-08-24:14:13:05,350 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "2024-08-24:14:13:06,085 WARNING  [qlinear_cuda.py:18] CUDA extension not installed.\n",
            "2024-08-24:14:13:06,086 WARNING  [qlinear_cuda_old.py:17] CUDA extension not installed.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4709: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n",
            "generation_config.json: 100%|███████████████████| 126/126 [00:00<00:00, 662kB/s]\n",
            "2024-08-24:14:13:47,920 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-24:14:13:47,920 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,920 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-24:14:13:47,920 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,920 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-24:14:13:47,920 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,920 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-24:14:13:47,920 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,920 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-24:14:13:47,920 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,920 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-24:14:13:47,921 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,921 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-24:14:13:47,921 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,921 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-24:14:13:47,921 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,921 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-24:14:13:47,921 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,921 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-24:14:13:47,921 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,921 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-24:14:13:47,921 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,921 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-24:14:13:47,921 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,921 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-24:14:13:47,921 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,921 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-24:14:13:47,921 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,921 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-24:14:13:47,921 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,921 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-24:14:13:47,921 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,921 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-24:14:13:47,921 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,921 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-24:14:13:47,922 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,922 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-24:14:13:47,922 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,922 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-24:14:13:47,922 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,922 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-24:14:13:47,922 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,922 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-24:14:13:47,922 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,922 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-24:14:13:47,922 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,922 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-24:14:13:47,922 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,922 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-24:14:13:47,922 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,922 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-24:14:13:47,922 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,922 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-24:14:13:47,922 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,922 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-24:14:13:47,922 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,922 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-24:14:13:47,923 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,923 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-24:14:13:47,923 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,923 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-24:14:13:47,923 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,923 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-24:14:13:47,923 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,923 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-24:14:13:47,923 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,923 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-24:14:13:47,923 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,923 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-24:14:13:47,923 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,923 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-24:14:13:47,923 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,923 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-24:14:13:47,923 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,923 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-24:14:13:47,923 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,923 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-24:14:13:47,923 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,923 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-24:14:13:47,923 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,924 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-24:14:13:47,924 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,924 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-24:14:13:47,924 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,924 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-24:14:13:47,924 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,924 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-24:14:13:47,924 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,924 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-24:14:13:47,924 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,924 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-24:14:13:47,924 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,924 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-24:14:13:47,924 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,924 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-24:14:13:47,924 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,924 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-24:14:13:47,924 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,924 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-24:14:13:47,924 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,924 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-24:14:13:47,924 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,924 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-24:14:13:47,925 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,925 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-24:14:13:47,925 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,925 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-24:14:13:47,925 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,925 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-24:14:13:47,925 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,925 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-24:14:13:47,925 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,925 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-24:14:13:47,925 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,925 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-24:14:13:47,925 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,925 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-24:14:13:47,925 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:14:13:47,925 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-24:14:13:47,934 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 564.60it/s]\n",
            "2024-08-24:14:13:48,117 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 571.53it/s]\n",
            "2024-08-24:14:13:48,360 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 573.86it/s]\n",
            "2024-08-24:14:13:48,632 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 583.20it/s]\n",
            "2024-08-24:14:13:48,886 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 566.14it/s]\n",
            "2024-08-24:14:13:49,068 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 562.10it/s]\n",
            "2024-08-24:14:13:49,252 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 583.43it/s]\n",
            "2024-08-24:14:13:49,429 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 584.82it/s]\n",
            "2024-08-24:14:13:49,608 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 578.59it/s]\n",
            "2024-08-24:14:13:49,786 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 581.12it/s]\n",
            "2024-08-24:14:13:50,202 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 581.77it/s]\n",
            "2024-08-24:14:13:50,459 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 583.42it/s]\n",
            "2024-08-24:14:13:51,124 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 660.41it/s]\n",
            "2024-08-24:14:13:51,608 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 708.50it/s]\n",
            "2024-08-24:14:13:51,903 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 687.34it/s]\n",
            "2024-08-24:14:13:52,053 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 695.72it/s]\n",
            "2024-08-24:14:13:52,453 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 704.59it/s]\n",
            "2024-08-24:14:13:52,674 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 704.30it/s]\n",
            "2024-08-24:14:13:52,989 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 706.80it/s]\n",
            "2024-08-24:14:13:53,153 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 701.00it/s]\n",
            "2024-08-24:14:13:53,300 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 702.26it/s]\n",
            "2024-08-24:14:13:53,687 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 696.64it/s]\n",
            "2024-08-24:14:13:53,943 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 701.94it/s]\n",
            "2024-08-24:14:13:54,090 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 708.55it/s]\n",
            "2024-08-24:14:13:54,414 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 706.13it/s]\n",
            "2024-08-24:14:13:54,564 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 704.12it/s]\n",
            "2024-08-24:14:13:54,906 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 706.32it/s]\n",
            "2024-08-24:14:13:55,051 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 656.80it/s]\n",
            "2024-08-24:14:13:56,438 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 572.82it/s]\n",
            "2024-08-24:14:13:56,987 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 570.68it/s]\n",
            "2024-08-24:14:13:57,496 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 572.74it/s]\n",
            "2024-08-24:14:13:57,985 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 577.58it/s]\n",
            "2024-08-24:14:13:58,281 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 578.19it/s]\n",
            "2024-08-24:14:13:58,485 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 576.27it/s]\n",
            "2024-08-24:14:13:58,838 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 568.33it/s]\n",
            "2024-08-24:14:13:59,188 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 581.54it/s]\n",
            "2024-08-24:14:13:59,877 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 580.48it/s]\n",
            "2024-08-24:14:14:00,299 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 597.05it/s]\n",
            "2024-08-24:14:14:01,238 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 708.56it/s]\n",
            "2024-08-24:14:14:01,428 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 710.57it/s]\n",
            "2024-08-24:14:14:02,313 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 693.09it/s]\n",
            "2024-08-24:14:14:02,477 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 697.18it/s]\n",
            "2024-08-24:14:14:02,838 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 706.84it/s]\n",
            "2024-08-24:14:14:03,131 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 705.11it/s]\n",
            "2024-08-24:14:14:03,277 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 706.91it/s]\n",
            "2024-08-24:14:14:03,461 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 705.89it/s]\n",
            "2024-08-24:14:14:03,702 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 704.18it/s]\n",
            "2024-08-24:14:14:04,002 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 701.90it/s]\n",
            "2024-08-24:14:14:04,350 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 707.62it/s]\n",
            "2024-08-24:14:14:04,526 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 699.07it/s]\n",
            "2024-08-24:14:14:04,685 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 709.43it/s]\n",
            "2024-08-24:14:14:04,922 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 708.51it/s]\n",
            "2024-08-24:14:14:05,424 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 609.18it/s]\n",
            "2024-08-24:14:14:06,928 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 714.47it/s]\n",
            "2024-08-24:14:14:07,375 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 715.41it/s]\n",
            "2024-08-24:14:14:07,841 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 707.84it/s]\n",
            "2024-08-24:14:14:10,068 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 707.63it/s]\n",
            "2024-08-24:14:14:10,318 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 14276.79it/s]\n",
            "2024-08-24:14:14:11,974 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1391.79it/s]\n",
            "2024-08-24:14:14:12,876 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n",
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
            "Running loglikelihood requests: 100%|██| 174850/174850 [25:48<00:00, 112.90it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-24:14:41:56,935 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=kaitchup/Llama-3.1-Minitron-4B-Width-Base-AutoRound-GPTQ-sym-4bit), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.4445|±  |0.0145|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.4787|±  |0.0146|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.2419|±  |0.0039|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.5783|±  |0.0040|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5403|±  |0.0068|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.3968|±  |0.0438|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7273|±  |0.0348|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.7745|±  |0.0293|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.7806|±  |0.0269|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.7355|±  |0.0403|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.7500|±  |0.0419|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7485|±  |0.0341|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.6561|±  |0.0256|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2458|±  |0.0144|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.6688|±  |0.0267|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.6944|±  |0.0256|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4739|±  |0.0128|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.7602|±  |0.0327|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.6328|±  |0.0083|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.5600|±  |0.0499|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.6264|±  |0.0298|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.5954|±  |0.0374|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.3800|±  |0.0488|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.5874|±  |0.0330|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.7184|±  |0.0445|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8120|±  |0.0256|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.7300|±  |0.0446|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.7625|±  |0.0152|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.6634|±  |0.0271|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.4043|±  |0.0293|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.5074|±  |0.0304|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5000|±  |0.0389|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.6513|±  |0.0084|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.3158|±  |0.0437|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.7576|±  |0.0305|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8238|±  |0.0275|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.5385|±  |0.0253|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.5924|±  |0.0319|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.7706|±  |0.0180|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.6718|±  |0.0412|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.5719|±  |0.0200|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6000|±  |0.0469|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.6571|±  |0.0304|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.7313|±  |0.0313|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.7600|±  |0.0429|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5103|±  |0.0086|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3100|±  |0.0465|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.5926|±  |0.0424|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.6053|±  |0.0398|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.7083|±  |0.0380|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4200|±  |0.0496|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.4300|±  |0.0498|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.3600|±  |0.0482|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.3824|±  |0.0484|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.7300|±  |0.0446|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5234|±  |0.0327|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.5034|±  |0.0417|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4206|±  |0.0254|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7484|±  |0.0247|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.5320|±  |0.0351|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.6200|±  |0.0488|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3852|±  |0.0297|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.3709|±  |0.0394|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.4444|±  |0.0339|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.5179|±  |0.0474|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.5783|±  |0.0040|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5403|±  |0.0068|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.6328|±  |0.0083|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.6513|±  |0.0084|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5103|±  |0.0086|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=kaitchup/Llama-3.1-Minitron-4B-Width-Base-AutoRound-GPTQ-sym-4bit --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###nvidia/Llama-3.1-Minitron-4B-Depth-Base"
      ],
      "metadata": {
        "id": "UvBtckbIGKYx"
      },
      "id": "UvBtckbIGKYx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a94e02ec-2a09-4b14-b59d-da141ee75690",
      "metadata": {
        "id": "a94e02ec-2a09-4b14-b59d-da141ee75690",
        "outputId": "98e8a2d2-cfbd-417f-effa-520b014f52bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-24:14:57:49,411 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-24:14:57:49,493 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-24:14:58:02,316 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-24:14:58:02,319 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-24:14:58:02,319 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'nvidia/Llama-3.1-Minitron-4B-Depth-Base'}\n",
            "2024-08-24:14:58:02,547 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-24:14:58:02,547 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "config.json: 100%|█████████████████████████████| 883/883 [00:00<00:00, 3.47MB/s]\n",
            "tokenizer_config.json: 100%|███████████████| 50.5k/50.5k [00:00<00:00, 87.6MB/s]\n",
            "tokenizer.json: 100%|██████████████████████| 9.09M/9.09M [00:00<00:00, 65.9MB/s]\n",
            "special_tokens_map.json: 100%|█████████████████| 301/301 [00:00<00:00, 1.46MB/s]\n",
            "2024-08-24:14:58:03,516 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "model.safetensors.index.json: 100%|████████| 12.1k/12.1k [00:00<00:00, 31.8MB/s]\n",
            "Downloading shards:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0%|             | 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0%|    | 10.5M/4.98G [00:00<01:02, 79.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1%|    | 31.5M/4.98G [00:00<01:27, 56.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1%|    | 52.4M/4.98G [00:00<01:14, 66.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2%|    | 83.9M/4.98G [00:01<00:51, 94.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2%|     | 105M/4.98G [00:01<01:22, 58.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3%|▏    | 136M/4.98G [00:02<01:13, 65.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3%|▏    | 157M/4.98G [00:02<01:18, 61.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4%|▏    | 178M/4.98G [00:02<01:02, 76.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4%|▏    | 199M/4.98G [00:02<00:59, 79.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4%|▏    | 210M/4.98G [00:03<01:13, 64.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5%|▏    | 241M/4.98G [00:03<01:10, 67.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5%|▎    | 262M/4.98G [00:03<01:09, 68.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6%|▎    | 294M/4.98G [00:04<01:07, 69.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6%|▎    | 315M/4.98G [00:04<01:22, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7%|▎    | 336M/4.98G [00:04<01:06, 70.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7%|▎    | 346M/4.98G [00:05<01:19, 58.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7%|▎    | 357M/4.98G [00:05<01:13, 62.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7%|▎    | 367M/4.98G [00:05<01:49, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8%|▍    | 398M/4.98G [00:06<01:23, 54.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8%|▍    | 409M/4.98G [00:06<01:20, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8%|▍    | 419M/4.98G [00:06<01:48, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9%|▍    | 451M/4.98G [00:07<01:15, 59.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9%|▍    | 472M/4.98G [00:07<01:18, 57.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10%|▌    | 503M/4.98G [00:08<01:11, 62.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11%|▌    | 524M/4.98G [00:08<01:02, 71.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11%|▌    | 545M/4.98G [00:08<00:54, 81.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11%|▌    | 556M/4.98G [00:09<01:34, 46.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12%|▌    | 577M/4.98G [00:09<01:24, 52.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12%|▌    | 608M/4.98G [00:09<01:16, 56.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12%|▌    | 619M/4.98G [00:10<01:16, 57.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13%|▋    | 629M/4.98G [00:10<01:30, 47.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13%|▋    | 661M/4.98G [00:10<01:09, 62.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14%|▋    | 682M/4.98G [00:11<01:12, 59.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14%|▋    | 713M/4.98G [00:11<01:05, 64.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15%|▋    | 734M/4.98G [00:11<01:08, 62.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15%|▊    | 765M/4.98G [00:12<00:57, 73.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16%|▊    | 786M/4.98G [00:12<01:06, 63.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16%|▊    | 818M/4.98G [00:13<01:16, 54.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17%|▊    | 839M/4.98G [00:13<01:21, 50.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17%|▊    | 870M/4.98G [00:14<01:10, 57.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18%|▉    | 881M/4.98G [00:14<01:13, 55.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18%|▉    | 891M/4.98G [00:15<01:41, 40.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19%|▉    | 923M/4.98G [00:15<01:14, 54.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19%|▉    | 944M/4.98G [00:15<01:11, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19%|▉    | 965M/4.98G [00:15<00:58, 68.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20%|▉    | 975M/4.98G [00:16<01:12, 55.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20%|█    | 996M/4.98G [00:16<01:07, 59.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20%|▊   | 1.02G/4.98G [00:16<00:52, 75.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21%|▊   | 1.03G/4.98G [00:17<01:42, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21%|▊   | 1.05G/4.98G [00:18<01:34, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22%|▊   | 1.08G/4.98G [00:18<01:11, 54.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22%|▉   | 1.10G/4.98G [00:18<01:21, 47.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23%|▉   | 1.12G/4.98G [00:19<01:08, 56.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23%|▉   | 1.13G/4.98G [00:19<01:35, 40.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23%|▉   | 1.15G/4.98G [00:20<01:28, 43.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24%|▉   | 1.17G/4.98G [00:20<01:07, 56.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24%|▉   | 1.18G/4.98G [00:20<01:14, 50.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24%|▉   | 1.21G/4.98G [00:21<01:17, 48.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24%|▉   | 1.22G/4.98G [00:21<01:11, 52.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25%|▉   | 1.24G/4.98G [00:21<01:11, 52.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25%|█   | 1.26G/4.98G [00:22<01:11, 52.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26%|█   | 1.28G/4.98G [00:22<00:54, 67.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26%|█   | 1.29G/4.98G [00:22<01:18, 47.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26%|█   | 1.31G/4.98G [00:23<01:11, 51.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27%|█   | 1.32G/4.98G [00:23<01:11, 51.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27%|█   | 1.34G/4.98G [00:23<01:16, 47.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27%|█   | 1.36G/4.98G [00:24<01:26, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28%|█   | 1.37G/4.98G [00:24<01:20, 44.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28%|█   | 1.39G/4.98G [00:25<01:31, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28%|█▏  | 1.42G/4.98G [00:25<01:31, 39.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29%|█▏  | 1.44G/4.98G [00:25<01:08, 51.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29%|█▏  | 1.45G/4.98G [00:26<01:09, 50.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29%|█▏  | 1.47G/4.98G [00:26<01:20, 43.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30%|█▏  | 1.48G/4.98G [00:26<01:13, 47.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30%|█▏  | 1.50G/4.98G [00:27<00:59, 58.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31%|█▏  | 1.52G/4.98G [00:27<01:06, 51.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31%|█▏  | 1.54G/4.98G [00:27<00:50, 67.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31%|█▏  | 1.55G/4.98G [00:27<00:58, 58.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32%|█▎  | 1.57G/4.98G [00:28<01:13, 46.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32%|█▎  | 1.59G/4.98G [00:28<00:59, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32%|█▎  | 1.60G/4.98G [00:29<01:15, 44.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32%|█▎  | 1.61G/4.98G [00:29<01:06, 50.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33%|█▎  | 1.63G/4.98G [00:29<01:15, 44.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33%|█▎  | 1.64G/4.98G [00:29<01:19, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33%|█▎  | 1.66G/4.98G [00:30<01:28, 37.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34%|█▎  | 1.68G/4.98G [00:30<01:13, 44.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34%|█▎  | 1.70G/4.98G [00:30<00:53, 60.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34%|█▎  | 1.71G/4.98G [00:31<01:22, 39.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35%|█▍  | 1.73G/4.98G [00:32<01:15, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35%|█▍  | 1.75G/4.98G [00:32<00:57, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35%|█▍  | 1.76G/4.98G [00:32<01:08, 46.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36%|█▍  | 1.78G/4.98G [00:32<01:02, 51.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36%|█▍  | 1.79G/4.98G [00:33<00:56, 56.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36%|█▍  | 1.80G/4.98G [00:33<01:01, 51.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36%|█▍  | 1.81G/4.98G [00:33<01:24, 37.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37%|█▍  | 1.84G/4.98G [00:34<01:28, 35.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37%|█▍  | 1.86G/4.98G [00:35<01:47, 29.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38%|█▌  | 1.87G/4.98G [00:36<02:08, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38%|█▌  | 1.89G/4.98G [00:36<01:48, 28.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39%|█▌  | 1.92G/4.98G [00:37<01:21, 37.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39%|█▌  | 1.94G/4.98G [00:37<01:20, 37.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40%|█▌  | 1.97G/4.98G [00:38<01:14, 40.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40%|█▌  | 1.99G/4.98G [00:38<01:15, 39.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40%|█▌  | 2.01G/4.98G [00:39<01:01, 48.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41%|█▋  | 2.02G/4.98G [00:39<01:04, 45.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41%|█▋  | 2.04G/4.98G [00:39<01:04, 45.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42%|█▋  | 2.07G/4.98G [00:39<00:49, 59.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42%|█▋  | 2.08G/4.98G [00:40<01:05, 44.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42%|█▋  | 2.10G/4.98G [00:41<01:09, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43%|█▋  | 2.12G/4.98G [00:41<00:53, 53.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43%|█▋  | 2.13G/4.98G [00:41<01:05, 43.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43%|█▋  | 2.15G/4.98G [00:42<01:14, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44%|█▊  | 2.18G/4.98G [00:42<01:00, 46.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44%|█▊  | 2.20G/4.98G [00:43<01:22, 33.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45%|█▊  | 2.22G/4.98G [00:43<01:03, 43.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45%|█▊  | 2.23G/4.98G [00:44<01:18, 34.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45%|█▊  | 2.25G/4.98G [00:44<01:08, 39.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46%|█▊  | 2.28G/4.98G [00:45<00:53, 50.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46%|█▊  | 2.29G/4.98G [00:45<00:59, 45.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46%|█▊  | 2.31G/4.98G [00:45<00:58, 45.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47%|█▊  | 2.33G/4.98G [00:46<00:45, 58.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47%|█▉  | 2.34G/4.98G [00:46<01:09, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47%|█▉  | 2.36G/4.98G [00:47<01:01, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48%|█▉  | 2.37G/4.98G [00:47<00:53, 48.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48%|█▉  | 2.38G/4.98G [00:47<00:49, 52.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48%|█▉  | 2.39G/4.98G [00:48<01:17, 33.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48%|█▉  | 2.41G/4.98G [00:48<01:01, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49%|█▉  | 2.42G/4.98G [00:48<01:00, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49%|█▉  | 2.44G/4.98G [00:48<00:52, 48.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50%|█▉  | 2.46G/4.98G [00:49<00:46, 53.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50%|█▉  | 2.47G/4.98G [00:49<00:48, 51.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50%|█▉  | 2.49G/4.98G [00:49<00:47, 52.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50%|██  | 2.50G/4.98G [00:50<00:55, 44.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51%|██  | 2.52G/4.98G [00:50<00:59, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51%|██  | 2.54G/4.98G [00:50<00:43, 55.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51%|██  | 2.55G/4.98G [00:51<00:55, 43.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52%|██  | 2.57G/4.98G [00:51<00:52, 46.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52%|██  | 2.58G/4.98G [00:51<00:46, 51.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52%|██  | 2.59G/4.98G [00:51<00:44, 53.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52%|██  | 2.60G/4.98G [00:52<00:55, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53%|██  | 2.62G/4.98G [00:52<00:43, 54.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53%|██  | 2.64G/4.98G [00:52<00:31, 73.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53%|██▏ | 2.65G/4.98G [00:52<00:41, 56.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54%|██▏ | 2.67G/4.98G [00:53<00:45, 50.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54%|██▏ | 2.68G/4.98G [00:53<00:41, 55.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54%|██▏ | 2.69G/4.98G [00:53<00:36, 61.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54%|██▏ | 2.71G/4.98G [00:54<00:55, 41.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55%|██▏ | 2.73G/4.98G [00:54<00:52, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55%|██▏ | 2.74G/4.98G [00:54<00:48, 46.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55%|██▏ | 2.75G/4.98G [00:55<00:54, 41.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55%|██▏ | 2.76G/4.98G [00:55<01:12, 30.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56%|██▏ | 2.77G/4.98G [00:55<00:58, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56%|██▏ | 2.78G/4.98G [00:56<01:08, 31.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56%|██▎ | 2.80G/4.98G [00:56<00:44, 49.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56%|██▎ | 2.81G/4.98G [00:57<01:22, 26.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57%|██▎ | 2.82G/4.98G [00:57<01:07, 31.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57%|██▎ | 2.83G/4.98G [00:58<01:24, 25.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57%|██▎ | 2.84G/4.98G [00:58<01:08, 31.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57%|██▎ | 2.85G/4.98G [00:58<00:59, 36.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58%|██▎ | 2.86G/4.98G [00:59<01:16, 27.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58%|██▎ | 2.88G/4.98G [00:59<01:14, 28.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58%|██▎ | 2.89G/4.98G [00:59<01:01, 34.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58%|██▎ | 2.90G/4.98G [01:00<00:58, 35.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59%|██▎ | 2.92G/4.98G [01:00<00:56, 36.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59%|██▎ | 2.94G/4.98G [01:01<00:59, 34.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59%|██▍ | 2.96G/4.98G [01:01<00:49, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60%|██▍ | 2.97G/4.98G [01:01<00:51, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60%|██▍ | 2.99G/4.98G [01:02<00:50, 39.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60%|██▍ | 3.00G/4.98G [01:02<00:47, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61%|██▍ | 3.02G/4.98G [01:03<00:46, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61%|██▍ | 3.04G/4.98G [01:03<00:46, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61%|██▍ | 3.05G/4.98G [01:03<00:45, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62%|██▍ | 3.07G/4.98G [01:04<00:47, 39.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62%|██▍ | 3.09G/4.98G [01:04<00:38, 48.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63%|██▌ | 3.11G/4.98G [01:04<00:31, 58.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63%|██▌ | 3.12G/4.98G [01:05<00:48, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63%|██▌ | 3.15G/4.98G [01:05<00:38, 47.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63%|██▌ | 3.16G/4.98G [01:05<00:35, 51.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64%|██▌ | 3.17G/4.98G [01:06<00:35, 51.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64%|██▌ | 3.18G/4.98G [01:06<00:51, 35.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64%|██▌ | 3.20G/4.98G [01:07<00:41, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64%|██▌ | 3.21G/4.98G [01:07<00:38, 46.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65%|██▌ | 3.23G/4.98G [01:07<00:35, 49.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65%|██▌ | 3.25G/4.98G [01:07<00:32, 53.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66%|██▌ | 3.26G/4.98G [01:08<00:30, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66%|██▋ | 3.28G/4.98G [01:08<00:46, 36.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66%|██▋ | 3.30G/4.98G [01:09<00:42, 39.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67%|██▋ | 3.32G/4.98G [01:09<00:34, 47.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67%|██▋ | 3.33G/4.98G [01:10<00:43, 37.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67%|██▋ | 3.36G/4.98G [01:10<00:35, 45.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68%|██▋ | 3.37G/4.98G [01:10<00:35, 45.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68%|██▋ | 3.39G/4.98G [01:11<00:37, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68%|██▋ | 3.41G/4.98G [01:11<00:36, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69%|██▊ | 3.44G/4.98G [01:12<00:30, 49.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70%|██▊ | 3.46G/4.98G [01:12<00:31, 48.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70%|██▊ | 3.48G/4.98G [01:12<00:28, 53.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70%|██▊ | 3.49G/4.98G [01:13<00:29, 49.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71%|██▊ | 3.51G/4.98G [01:13<00:28, 51.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71%|██▊ | 3.52G/4.98G [01:13<00:26, 55.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71%|██▊ | 3.54G/4.98G [01:14<00:25, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72%|██▊ | 3.57G/4.98G [01:14<00:28, 50.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72%|██▊ | 3.58G/4.98G [01:14<00:27, 50.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72%|██▉ | 3.60G/4.98G [01:15<00:30, 44.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72%|██▉ | 3.61G/4.98G [01:15<00:27, 50.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73%|██▉ | 3.62G/4.98G [01:15<00:33, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73%|██▉ | 3.63G/4.98G [01:16<00:29, 45.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73%|██▉ | 3.65G/4.98G [01:16<00:35, 37.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74%|██▉ | 3.67G/4.98G [01:17<00:36, 36.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74%|██▉ | 3.68G/4.98G [01:17<00:31, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74%|██▉ | 3.70G/4.98G [01:17<00:29, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75%|██▉ | 3.71G/4.98G [01:18<00:27, 46.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75%|██▉ | 3.72G/4.98G [01:18<00:30, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75%|███ | 3.73G/4.98G [01:18<00:28, 44.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75%|███ | 3.75G/4.98G [01:18<00:22, 54.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76%|███ | 3.77G/4.98G [01:19<00:21, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76%|███ | 3.79G/4.98G [01:19<00:22, 52.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76%|███ | 3.81G/4.98G [01:20<00:27, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77%|███ | 3.82G/4.98G [01:20<00:24, 47.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77%|███ | 3.83G/4.98G [01:20<00:32, 35.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77%|███ | 3.84G/4.98G [01:21<00:31, 36.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78%|███ | 3.86G/4.98G [01:21<00:27, 40.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78%|███ | 3.87G/4.98G [01:21<00:27, 40.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78%|███ | 3.88G/4.98G [01:22<00:28, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78%|███▏| 3.89G/4.98G [01:22<00:29, 36.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78%|███▏| 3.90G/4.98G [01:22<00:24, 43.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79%|███▏| 3.91G/4.98G [01:23<00:32, 32.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79%|███▏| 3.93G/4.98G [01:23<00:26, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79%|███▏| 3.94G/4.98G [01:23<00:26, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79%|███▏| 3.95G/4.98G [01:23<00:22, 45.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80%|███▏| 3.96G/4.98G [01:24<00:22, 45.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80%|███▏| 3.97G/4.98G [01:24<00:26, 37.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80%|███▏| 3.98G/4.98G [01:25<00:33, 29.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80%|███▏| 4.00G/4.98G [01:25<00:26, 36.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81%|███▏| 4.02G/4.98G [01:25<00:27, 34.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81%|███▏| 4.04G/4.98G [01:26<00:23, 40.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82%|███▎| 4.07G/4.98G [01:26<00:17, 53.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82%|███▎| 4.08G/4.98G [01:26<00:15, 57.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82%|███▎| 4.09G/4.98G [01:27<00:20, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83%|███▎| 4.11G/4.98G [01:27<00:14, 60.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83%|███▎| 4.12G/4.98G [01:27<00:18, 45.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83%|███▎| 4.13G/4.98G [01:27<00:17, 49.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83%|███▎| 4.14G/4.98G [01:28<00:23, 35.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83%|███▎| 4.15G/4.98G [01:28<00:27, 30.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84%|███▎| 4.16G/4.98G [01:29<00:22, 36.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84%|███▎| 4.17G/4.98G [01:29<00:23, 34.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84%|███▎| 4.18G/4.98G [01:29<00:20, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84%|███▎| 4.19G/4.98G [01:30<00:24, 31.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84%|███▍| 4.20G/4.98G [01:30<00:28, 26.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85%|███▍| 4.23G/4.98G [01:31<00:26, 28.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85%|███▍| 4.24G/4.98G [01:31<00:24, 29.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85%|███▍| 4.25G/4.98G [01:31<00:24, 29.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86%|███▍| 4.26G/4.98G [01:32<00:19, 36.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86%|███▍| 4.28G/4.98G [01:32<00:19, 35.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86%|███▍| 4.29G/4.98G [01:33<00:23, 28.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86%|███▍| 4.30G/4.98G [01:33<00:24, 28.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87%|███▍| 4.31G/4.98G [01:34<00:23, 28.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87%|███▍| 4.33G/4.98G [01:34<00:19, 33.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87%|███▍| 4.34G/4.98G [01:34<00:17, 35.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87%|███▍| 4.35G/4.98G [01:34<00:16, 36.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88%|███▌| 4.37G/4.98G [01:35<00:11, 54.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88%|███▌| 4.38G/4.98G [01:35<00:13, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88%|███▌| 4.39G/4.98G [01:35<00:13, 44.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88%|███▌| 4.40G/4.98G [01:36<00:18, 30.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89%|███▌| 4.41G/4.98G [01:36<00:18, 31.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89%|███▌| 4.44G/4.98G [01:37<00:15, 34.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89%|███▌| 4.45G/4.98G [01:37<00:14, 37.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90%|███▌| 4.46G/4.98G [01:38<00:17, 29.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90%|███▌| 4.47G/4.98G [01:38<00:15, 32.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90%|███▌| 4.49G/4.98G [01:38<00:14, 34.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91%|███▌| 4.51G/4.98G [01:39<00:11, 39.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91%|███▋| 4.52G/4.98G [01:39<00:12, 36.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91%|███▋| 4.54G/4.98G [01:39<00:10, 43.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91%|███▋| 4.55G/4.98G [01:40<00:09, 44.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92%|███▋| 4.56G/4.98G [01:40<00:11, 36.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92%|███▋| 4.57G/4.98G [01:40<00:11, 34.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92%|███▋| 4.59G/4.98G [01:41<00:08, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92%|███▋| 4.60G/4.98G [01:41<00:07, 49.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93%|███▋| 4.61G/4.98G [01:41<00:10, 36.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93%|███▋| 4.62G/4.98G [01:42<00:09, 39.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93%|███▋| 4.63G/4.98G [01:42<00:09, 36.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93%|███▋| 4.65G/4.98G [01:42<00:08, 37.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94%|███▋| 4.66G/4.98G [01:42<00:06, 45.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94%|███▊| 4.67G/4.98G [01:43<00:07, 43.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94%|███▊| 4.68G/4.98G [01:43<00:05, 52.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94%|███▊| 4.69G/4.98G [01:43<00:06, 45.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94%|███▊| 4.70G/4.98G [01:43<00:06, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95%|███▊| 4.71G/4.98G [01:43<00:05, 45.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95%|███▊| 4.72G/4.98G [01:44<00:06, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95%|███▊| 4.73G/4.98G [01:44<00:05, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95%|███▊| 4.75G/4.98G [01:45<00:05, 44.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96%|███▊| 4.77G/4.98G [01:45<00:05, 39.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96%|███▊| 4.78G/4.98G [01:45<00:04, 45.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96%|███▊| 4.80G/4.98G [01:46<00:05, 30.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97%|███▉| 4.82G/4.98G [01:47<00:04, 37.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97%|███▉| 4.84G/4.98G [01:47<00:02, 46.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98%|███▉| 4.85G/4.98G [01:47<00:03, 39.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98%|███▉| 4.87G/4.98G [01:47<00:02, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98%|███▉| 4.88G/4.98G [01:48<00:02, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99%|███▉| 4.91G/4.98G [01:48<00:01, 57.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99%|███▉| 4.93G/4.98G [01:49<00:01, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99%|███▉| 4.95G/4.98G [01:49<00:00, 57.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100%|███▉| 4.96G/4.98G [01:49<00:00, 44.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100%|████| 4.98G/4.98G [01:50<00:00, 45.2MB/s]\u001b[A\n",
            "Downloading shards:  50%|████████████            | 1/2 [01:50<01:50, 110.53s/it]\n",
            "model-00002-of-00002.safetensors:   0%|             | 0.00/4.10G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1%|     | 41.9M/4.10G [00:00<00:11, 369MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2%|     | 83.9M/4.10G [00:00<00:10, 374MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3%|▏     | 126M/4.10G [00:00<00:10, 378MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4%|▏     | 168M/4.10G [00:00<00:10, 378MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5%|▎     | 210M/4.10G [00:00<00:10, 370MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6%|▎     | 252M/4.10G [00:00<00:10, 372MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7%|▍     | 294M/4.10G [00:00<00:10, 371MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8%|▍     | 336M/4.10G [00:00<00:10, 360MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9%|▌     | 377M/4.10G [00:01<00:10, 365MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10%|▌     | 419M/4.10G [00:01<00:10, 364MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11%|▋     | 461M/4.10G [00:01<00:10, 364MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12%|▋     | 503M/4.10G [00:01<00:09, 369MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13%|▊     | 545M/4.10G [00:01<00:09, 371MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14%|▊     | 587M/4.10G [00:01<00:09, 362MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15%|▉     | 629M/4.10G [00:01<00:09, 368MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16%|▉     | 671M/4.10G [00:01<00:09, 372MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17%|█     | 713M/4.10G [00:01<00:09, 372MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18%|█     | 755M/4.10G [00:02<00:09, 369MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19%|█▏    | 797M/4.10G [00:02<00:08, 373MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20%|█▏    | 839M/4.10G [00:02<00:08, 376MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21%|█▎    | 881M/4.10G [00:02<00:08, 377MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22%|█▎    | 923M/4.10G [00:02<00:08, 378MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24%|█▍    | 965M/4.10G [00:02<00:08, 376MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25%|█▏   | 1.01G/4.10G [00:02<00:08, 373MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26%|█▎   | 1.05G/4.10G [00:02<00:08, 376MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27%|█▎   | 1.09G/4.10G [00:02<00:08, 366MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28%|█▍   | 1.13G/4.10G [00:03<00:08, 345MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29%|█▍   | 1.17G/4.10G [00:03<00:08, 345MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30%|█▍   | 1.22G/4.10G [00:03<00:08, 353MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31%|█▌   | 1.26G/4.10G [00:03<00:07, 360MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32%|█▌   | 1.30G/4.10G [00:03<00:07, 366MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33%|█▋   | 1.34G/4.10G [00:03<00:07, 371MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34%|█▋   | 1.38G/4.10G [00:03<00:07, 358MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35%|█▋   | 1.43G/4.10G [00:03<00:07, 364MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36%|█▊   | 1.47G/4.10G [00:03<00:07, 365MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37%|█▊   | 1.51G/4.10G [00:04<00:07, 370MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38%|█▉   | 1.55G/4.10G [00:04<00:06, 374MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39%|█▉   | 1.59G/4.10G [00:04<00:06, 376MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40%|█▉   | 1.64G/4.10G [00:04<00:06, 376MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41%|██   | 1.68G/4.10G [00:04<00:06, 378MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42%|██   | 1.72G/4.10G [00:04<00:06, 372MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43%|██▏  | 1.76G/4.10G [00:04<00:06, 372MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44%|██▏  | 1.80G/4.10G [00:04<00:06, 372MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45%|██▏  | 1.85G/4.10G [00:05<00:06, 375MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46%|██▎  | 1.89G/4.10G [00:05<00:05, 375MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47%|██▎  | 1.93G/4.10G [00:05<00:05, 374MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48%|██▍  | 1.97G/4.10G [00:05<00:05, 374MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49%|██▍  | 2.01G/4.10G [00:05<00:05, 379MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50%|██▌  | 2.06G/4.10G [00:05<00:05, 376MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51%|██▌  | 2.10G/4.10G [00:05<00:05, 376MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52%|██▌  | 2.14G/4.10G [00:05<00:05, 378MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53%|██▋  | 2.18G/4.10G [00:05<00:05, 377MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54%|██▋  | 2.22G/4.10G [00:06<00:05, 366MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55%|██▊  | 2.26G/4.10G [00:06<00:05, 362MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56%|██▊  | 2.31G/4.10G [00:06<00:04, 367MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57%|██▊  | 2.35G/4.10G [00:06<00:04, 372MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58%|██▉  | 2.39G/4.10G [00:06<00:04, 366MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59%|██▉  | 2.43G/4.10G [00:06<00:04, 368MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60%|███  | 2.47G/4.10G [00:06<00:04, 371MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61%|███  | 2.52G/4.10G [00:06<00:04, 350MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62%|███  | 2.56G/4.10G [00:06<00:04, 344MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63%|███▏ | 2.60G/4.10G [00:07<00:04, 348MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64%|███▏ | 2.64G/4.10G [00:07<00:04, 349MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65%|███▎ | 2.68G/4.10G [00:07<00:04, 347MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66%|███▎ | 2.73G/4.10G [00:07<00:03, 347MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67%|███▎ | 2.77G/4.10G [00:07<00:03, 350MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68%|███▍ | 2.81G/4.10G [00:07<00:03, 353MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69%|███▍ | 2.85G/4.10G [00:07<00:03, 355MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71%|███▌ | 2.89G/4.10G [00:07<00:03, 365MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72%|███▌ | 2.94G/4.10G [00:08<00:03, 370MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73%|███▋ | 2.98G/4.10G [00:08<00:03, 363MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74%|███▋ | 3.02G/4.10G [00:08<00:03, 357MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75%|███▋ | 3.06G/4.10G [00:08<00:02, 369MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76%|███▊ | 3.10G/4.10G [00:08<00:02, 370MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77%|███▊ | 3.15G/4.10G [00:08<00:02, 374MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78%|███▉ | 3.19G/4.10G [00:08<00:02, 372MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79%|███▉ | 3.23G/4.10G [00:08<00:02, 369MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80%|███▉ | 3.27G/4.10G [00:08<00:02, 370MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81%|████ | 3.31G/4.10G [00:09<00:02, 373MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82%|████ | 3.36G/4.10G [00:09<00:01, 375MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83%|████▏| 3.40G/4.10G [00:09<00:01, 374MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84%|████▏| 3.44G/4.10G [00:09<00:01, 376MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85%|████▏| 3.48G/4.10G [00:09<00:01, 362MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86%|████▎| 3.52G/4.10G [00:09<00:01, 370MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87%|████▎| 3.57G/4.10G [00:09<00:01, 360MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88%|████▍| 3.61G/4.10G [00:09<00:01, 364MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89%|████▍| 3.65G/4.10G [00:09<00:01, 362MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90%|████▍| 3.69G/4.10G [00:10<00:01, 261MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91%|████▌| 3.72G/4.10G [00:10<00:01, 236MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91%|████▌| 3.75G/4.10G [00:10<00:01, 178MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92%|████▌| 3.79G/4.10G [00:10<00:01, 173MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93%|████▋| 3.81G/4.10G [00:11<00:02, 146MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93%|████▋| 3.83G/4.10G [00:11<00:02, 121MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94%|████▋| 3.85G/4.10G [00:11<00:02, 118MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94%|████▋| 3.87G/4.10G [00:11<00:02, 112MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95%|████▊| 3.90G/4.10G [00:11<00:01, 139MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96%|████▊| 3.93G/4.10G [00:12<00:01, 154MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96%|████▊| 3.95G/4.10G [00:12<00:00, 151MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97%|████▊| 3.97G/4.10G [00:12<00:00, 159MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97%|████▊| 4.00G/4.10G [00:12<00:00, 138MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98%|████▉| 4.03G/4.10G [00:12<00:00, 165MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99%|████▉| 4.05G/4.10G [00:12<00:00, 169MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99%|████▉| 4.07G/4.10G [00:13<00:00, 142MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100%|█████| 4.10G/4.10G [00:13<00:00, 309MB/s]\u001b[A\n",
            "Downloading shards: 100%|█████████████████████████| 2/2 [02:03<00:00, 61.98s/it]\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.06s/it]\n",
            "generation_config.json: 100%|███████████████████| 121/121 [00:00<00:00, 512kB/s]\n",
            "2024-08-24:15:00:39,032 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-24:15:00:39,032 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,032 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-24:15:00:39,032 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,032 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-24:15:00:39,032 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,032 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-24:15:00:39,032 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,032 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-24:15:00:39,032 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,032 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-24:15:00:39,032 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,032 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-24:15:00:39,032 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,032 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-24:15:00:39,032 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,032 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-24:15:00:39,033 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,033 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-24:15:00:39,033 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,033 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-24:15:00:39,033 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,033 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-24:15:00:39,033 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,033 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-24:15:00:39,033 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,033 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-24:15:00:39,033 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,033 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-24:15:00:39,033 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,033 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-24:15:00:39,033 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,033 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-24:15:00:39,033 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,033 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-24:15:00:39,033 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,033 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-24:15:00:39,033 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,033 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-24:15:00:39,033 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,033 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-24:15:00:39,033 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,033 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-24:15:00:39,033 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,033 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-24:15:00:39,033 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,034 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-24:15:00:39,034 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,034 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-24:15:00:39,034 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,034 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-24:15:00:39,034 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,034 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-24:15:00:39,034 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,034 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-24:15:00:39,034 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,034 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-24:15:00:39,034 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,034 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-24:15:00:39,034 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,034 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-24:15:00:39,034 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,034 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-24:15:00:39,034 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,034 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-24:15:00:39,034 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,034 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-24:15:00:39,034 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,034 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-24:15:00:39,034 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,034 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-24:15:00:39,034 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,034 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-24:15:00:39,035 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,035 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-24:15:00:39,035 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,035 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-24:15:00:39,035 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,035 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-24:15:00:39,035 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,035 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-24:15:00:39,035 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,035 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-24:15:00:39,035 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,035 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-24:15:00:39,035 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,035 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-24:15:00:39,035 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,035 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-24:15:00:39,035 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,035 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-24:15:00:39,035 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,035 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-24:15:00:39,035 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,035 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-24:15:00:39,035 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,035 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-24:15:00:39,035 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,035 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-24:15:00:39,036 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,036 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-24:15:00:39,036 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,036 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-24:15:00:39,036 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,036 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-24:15:00:39,036 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,036 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-24:15:00:39,036 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,036 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-24:15:00:39,036 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,036 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-24:15:00:39,036 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,036 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-24:15:00:39,036 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,036 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-24:15:00:39,036 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,036 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-24:15:00:39,036 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:00:39,036 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-24:15:00:39,045 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 564.88it/s]\n",
            "2024-08-24:15:00:39,227 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 568.34it/s]\n",
            "2024-08-24:15:00:39,473 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 574.19it/s]\n",
            "2024-08-24:15:00:39,745 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 577.51it/s]\n",
            "2024-08-24:15:00:40,002 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 552.31it/s]\n",
            "2024-08-24:15:00:40,188 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 582.40it/s]\n",
            "2024-08-24:15:00:40,365 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 575.31it/s]\n",
            "2024-08-24:15:00:40,544 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 577.54it/s]\n",
            "2024-08-24:15:00:40,726 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 566.83it/s]\n",
            "2024-08-24:15:00:40,908 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 576.02it/s]\n",
            "2024-08-24:15:00:41,328 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 570.70it/s]\n",
            "2024-08-24:15:00:41,590 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 648.18it/s]\n",
            "2024-08-24:15:00:42,192 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 698.74it/s]\n",
            "2024-08-24:15:00:42,648 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 702.42it/s]\n",
            "2024-08-24:15:00:42,945 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 702.66it/s]\n",
            "2024-08-24:15:00:43,092 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 692.68it/s]\n",
            "2024-08-24:15:00:43,493 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 704.47it/s]\n",
            "2024-08-24:15:00:43,713 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 694.05it/s]\n",
            "2024-08-24:15:00:44,033 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 695.16it/s]\n",
            "2024-08-24:15:00:44,199 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 696.75it/s]\n",
            "2024-08-24:15:00:44,347 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 699.61it/s]\n",
            "2024-08-24:15:00:44,737 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 692.45it/s]\n",
            "2024-08-24:15:00:44,994 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 690.38it/s]\n",
            "2024-08-24:15:00:45,143 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 692.24it/s]\n",
            "2024-08-24:15:00:45,474 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 698.65it/s]\n",
            "2024-08-24:15:00:45,626 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 484.53it/s]\n",
            "2024-08-24:15:00:46,119 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 689.16it/s]\n",
            "2024-08-24:15:00:46,269 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 697.35it/s]\n",
            "2024-08-24:15:00:47,422 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 702.76it/s]\n",
            "2024-08-24:15:00:47,870 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 695.55it/s]\n",
            "2024-08-24:15:00:48,287 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 690.37it/s]\n",
            "2024-08-24:15:00:48,693 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 699.00it/s]\n",
            "2024-08-24:15:00:48,937 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 694.47it/s]\n",
            "2024-08-24:15:00:49,106 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 696.49it/s]\n",
            "2024-08-24:15:00:49,399 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 696.42it/s]\n",
            "2024-08-24:15:00:49,684 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 697.94it/s]\n",
            "2024-08-24:15:00:50,258 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 688.97it/s]\n",
            "2024-08-24:15:00:50,613 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 696.47it/s]\n",
            "2024-08-24:15:00:51,417 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 696.59it/s]\n",
            "2024-08-24:15:00:51,611 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 696.29it/s]\n",
            "2024-08-24:15:00:52,514 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 692.48it/s]\n",
            "2024-08-24:15:00:52,678 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 690.51it/s]\n",
            "2024-08-24:15:00:53,044 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 693.15it/s]\n",
            "2024-08-24:15:00:53,342 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 691.64it/s]\n",
            "2024-08-24:15:00:53,491 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 686.29it/s]\n",
            "2024-08-24:15:00:53,681 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 691.71it/s]\n",
            "2024-08-24:15:00:53,926 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 683.73it/s]\n",
            "2024-08-24:15:00:54,234 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 687.70it/s]\n",
            "2024-08-24:15:00:54,589 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 697.45it/s]\n",
            "2024-08-24:15:00:54,768 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 696.82it/s]\n",
            "2024-08-24:15:00:54,928 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 697.18it/s]\n",
            "2024-08-24:15:00:55,169 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 697.77it/s]\n",
            "2024-08-24:15:00:55,678 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 617.18it/s]\n",
            "2024-08-24:15:00:57,164 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 697.04it/s]\n",
            "2024-08-24:15:00:57,623 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 699.43it/s]\n",
            "2024-08-24:15:00:58,099 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 688.14it/s]\n",
            "2024-08-24:15:01:00,390 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 701.46it/s]\n",
            "2024-08-24:15:01:00,641 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 16688.39it/s]\n",
            "2024-08-24:15:01:02,183 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1379.33it/s]\n",
            "2024-08-24:15:01:03,093 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n",
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
            "Running loglikelihood requests: 100%|██| 174850/174850 [08:18<00:00, 350.76it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-24:15:11:14,520 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=nvidia/Llama-3.1-Minitron-4B-Depth-Base), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.4164|±  |0.0144|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.4573|±  |0.0146|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.2420|±  |0.0039|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.6076|±  |0.0039|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5564|±  |0.0067|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.4048|±  |0.0439|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7576|±  |0.0335|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.7990|±  |0.0281|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.8017|±  |0.0260|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.7603|±  |0.0390|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.6852|±  |0.0449|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7117|±  |0.0356|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.6850|±  |0.0250|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2514|±  |0.0145|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.7074|±  |0.0258|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.7253|±  |0.0248|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4928|±  |0.0128|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.7836|±  |0.0316|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.6791|±  |0.0081|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.6200|±  |0.0488|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.6792|±  |0.0287|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.6185|±  |0.0370|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.3400|±  |0.0476|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.6726|±  |0.0315|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.7573|±  |0.0425|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8376|±  |0.0242|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.7000|±  |0.0461|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.7957|±  |0.0144|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.7092|±  |0.0260|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.4397|±  |0.0296|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.6471|±  |0.0290|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5602|±  |0.0386|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.6984|±  |0.0080|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.4211|±  |0.0464|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.8030|±  |0.0283|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8497|±  |0.0258|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.5718|±  |0.0251|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.6092|±  |0.0317|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.8147|±  |0.0167|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.6412|±  |0.0421|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.6356|±  |0.0195|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6636|±  |0.0453|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.6694|±  |0.0301|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.8308|±  |0.0265|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.8900|±  |0.0314|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5249|±  |0.0087|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3500|±  |0.0479|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.6222|±  |0.0419|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.6908|±  |0.0376|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.7431|±  |0.0365|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4600|±  |0.0501|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.4500|±  |0.0500|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.3500|±  |0.0479|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.4608|±  |0.0496|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.6700|±  |0.0473|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5234|±  |0.0327|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.5448|±  |0.0415|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4788|±  |0.0257|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7161|±  |0.0256|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.4975|±  |0.0352|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.6200|±  |0.0488|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3926|±  |0.0298|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.4106|±  |0.0402|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.4815|±  |0.0341|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.3929|±  |0.0464|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.6076|±  |0.0039|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5564|±  |0.0067|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.6791|±  |0.0081|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.6984|±  |0.0080|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5249|±  |0.0087|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=nvidia/Llama-3.1-Minitron-4B-Depth-Base --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a30e063-471d-426c-a51e-42ef10161c84",
      "metadata": {
        "id": "5a30e063-471d-426c-a51e-42ef10161c84",
        "outputId": "1b649e3c-7e00-4efc-9e28-ff5c82e8bb98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-24:15:11:20,152 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-24:15:11:20,264 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-24:15:11:33,454 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-24:15:11:33,455 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-24:15:11:33,455 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'nvidia/Llama-3.1-Minitron-4B-Depth-Base', 'load_in_8bit': True}\n",
            "2024-08-24:15:11:33,690 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-24:15:11:33,690 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "2024-08-24:15:11:34,135 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:10<00:00,  5.43s/it]\n",
            "2024-08-24:15:11:46,142 WARNING  [big_modeling.py:451] You shouldn't move a model that is dispatched using accelerate hooks.\n",
            "2024-08-24:15:12:14,701 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-24:15:12:14,701 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,701 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-24:15:12:14,701 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,701 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-24:15:12:14,701 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,701 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-24:15:12:14,701 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,701 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-24:15:12:14,701 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,701 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-24:15:12:14,701 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,701 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-24:15:12:14,701 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,701 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-24:15:12:14,701 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,701 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-24:15:12:14,701 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,701 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-24:15:12:14,701 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,701 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-24:15:12:14,701 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,701 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-24:15:12:14,702 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,702 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-24:15:12:14,702 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,702 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-24:15:12:14,702 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,702 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-24:15:12:14,702 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,702 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-24:15:12:14,702 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,702 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-24:15:12:14,702 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,702 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-24:15:12:14,702 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,702 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-24:15:12:14,702 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,702 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-24:15:12:14,702 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,702 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-24:15:12:14,702 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,702 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-24:15:12:14,702 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,702 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-24:15:12:14,702 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,702 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-24:15:12:14,702 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,702 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-24:15:12:14,702 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,702 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-24:15:12:14,703 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,703 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-24:15:12:14,703 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,703 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-24:15:12:14,703 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,703 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-24:15:12:14,703 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,703 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-24:15:12:14,703 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,703 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-24:15:12:14,703 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,703 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-24:15:12:14,703 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,703 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-24:15:12:14,703 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,703 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-24:15:12:14,703 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,703 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-24:15:12:14,703 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,703 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-24:15:12:14,703 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,703 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-24:15:12:14,703 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,703 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-24:15:12:14,703 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,703 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-24:15:12:14,703 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,703 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-24:15:12:14,703 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,704 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-24:15:12:14,704 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,704 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-24:15:12:14,704 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,704 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-24:15:12:14,704 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,704 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-24:15:12:14,704 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,704 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-24:15:12:14,704 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,704 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-24:15:12:14,704 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,704 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-24:15:12:14,704 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,704 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-24:15:12:14,704 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,704 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-24:15:12:14,704 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,704 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-24:15:12:14,704 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,704 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-24:15:12:14,704 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,704 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-24:15:12:14,704 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,704 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-24:15:12:14,704 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,704 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-24:15:12:14,704 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,704 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-24:15:12:14,705 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,705 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-24:15:12:14,705 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,705 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-24:15:12:14,705 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,705 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-24:15:12:14,705 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,705 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-24:15:12:14,705 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:12:14,705 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-24:15:12:14,713 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 574.01it/s]\n",
            "2024-08-24:15:12:14,893 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 579.65it/s]\n",
            "2024-08-24:15:12:15,133 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 580.73it/s]\n",
            "2024-08-24:15:12:15,403 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 585.42it/s]\n",
            "2024-08-24:15:12:15,656 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 584.76it/s]\n",
            "2024-08-24:15:12:15,832 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 583.10it/s]\n",
            "2024-08-24:15:12:16,009 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 584.11it/s]\n",
            "2024-08-24:15:12:16,186 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 579.79it/s]\n",
            "2024-08-24:15:12:16,367 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 585.81it/s]\n",
            "2024-08-24:15:12:16,543 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 576.61it/s]\n",
            "2024-08-24:15:12:16,962 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 647.49it/s]\n",
            "2024-08-24:15:12:17,193 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 700.11it/s]\n",
            "2024-08-24:15:12:17,748 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 696.60it/s]\n",
            "2024-08-24:15:12:18,206 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 701.12it/s]\n",
            "2024-08-24:15:12:18,504 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 701.60it/s]\n",
            "2024-08-24:15:12:18,651 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 688.82it/s]\n",
            "2024-08-24:15:12:19,054 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 705.35it/s]\n",
            "2024-08-24:15:12:19,274 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 703.90it/s]\n",
            "2024-08-24:15:12:19,590 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 697.95it/s]\n",
            "2024-08-24:15:12:19,756 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 698.88it/s]\n",
            "2024-08-24:15:12:19,903 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 696.12it/s]\n",
            "2024-08-24:15:12:20,295 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 689.16it/s]\n",
            "2024-08-24:15:12:20,553 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 695.47it/s]\n",
            "2024-08-24:15:12:20,701 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 689.38it/s]\n",
            "2024-08-24:15:12:21,034 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 685.58it/s]\n",
            "2024-08-24:15:12:21,189 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 699.84it/s]\n",
            "2024-08-24:15:12:21,533 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 333.27it/s]\n",
            "2024-08-24:15:12:21,838 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 693.86it/s]\n",
            "2024-08-24:15:12:22,997 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 700.12it/s]\n",
            "2024-08-24:15:12:23,447 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 696.24it/s]\n",
            "2024-08-24:15:12:23,863 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 691.96it/s]\n",
            "2024-08-24:15:12:24,268 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 690.30it/s]\n",
            "2024-08-24:15:12:24,516 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 701.39it/s]\n",
            "2024-08-24:15:12:24,683 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 698.69it/s]\n",
            "2024-08-24:15:12:24,975 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 704.35it/s]\n",
            "2024-08-24:15:12:25,257 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 705.53it/s]\n",
            "2024-08-24:15:12:25,825 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 688.73it/s]\n",
            "2024-08-24:15:12:26,180 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 704.75it/s]\n",
            "2024-08-24:15:12:26,975 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 704.32it/s]\n",
            "2024-08-24:15:12:27,167 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 700.55it/s]\n",
            "2024-08-24:15:12:28,065 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 704.74it/s]\n",
            "2024-08-24:15:12:28,226 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 703.48it/s]\n",
            "2024-08-24:15:12:28,585 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 704.56it/s]\n",
            "2024-08-24:15:12:28,878 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 693.77it/s]\n",
            "2024-08-24:15:12:29,027 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 698.80it/s]\n",
            "2024-08-24:15:12:29,213 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 705.02it/s]\n",
            "2024-08-24:15:12:29,454 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 703.77it/s]\n",
            "2024-08-24:15:12:29,753 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 697.27it/s]\n",
            "2024-08-24:15:12:30,103 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 703.49it/s]\n",
            "2024-08-24:15:12:30,280 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 701.35it/s]\n",
            "2024-08-24:15:12:30,439 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 696.49it/s]\n",
            "2024-08-24:15:12:30,680 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 707.43it/s]\n",
            "2024-08-24:15:12:31,183 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 611.62it/s]\n",
            "2024-08-24:15:12:32,688 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 705.94it/s]\n",
            "2024-08-24:15:12:33,141 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 708.40it/s]\n",
            "2024-08-24:15:12:33,612 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 705.24it/s]\n",
            "2024-08-24:15:12:35,847 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 705.37it/s]\n",
            "2024-08-24:15:12:36,097 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 16212.59it/s]\n",
            "2024-08-24:15:12:37,661 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1359.66it/s]\n",
            "2024-08-24:15:12:38,582 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
            "Running loglikelihood requests: 100%|██| 174850/174850 [15:44<00:00, 185.11it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-24:15:30:17,598 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=nvidia/Llama-3.1-Minitron-4B-Depth-Base,load_in_8bit=True), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.4070|±  |0.0144|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.4556|±  |0.0146|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.2381|±  |0.0039|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.6044|±  |0.0039|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5532|±  |0.0067|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.4206|±  |0.0442|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7636|±  |0.0332|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.7892|±  |0.0286|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.7975|±  |0.0262|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.7521|±  |0.0394|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.6852|±  |0.0449|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7117|±  |0.0356|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.6850|±  |0.0250|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2603|±  |0.0147|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.6945|±  |0.0262|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.7037|±  |0.0254|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4863|±  |0.0128|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.7778|±  |0.0319|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.6756|±  |0.0081|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.6200|±  |0.0488|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.6566|±  |0.0292|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.6185|±  |0.0370|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.3200|±  |0.0469|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.6726|±  |0.0315|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.7767|±  |0.0412|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8205|±  |0.0251|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.6700|±  |0.0473|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.7957|±  |0.0144|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.7124|±  |0.0259|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.4504|±  |0.0297|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.6471|±  |0.0290|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5482|±  |0.0387|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.6978|±  |0.0080|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.3947|±  |0.0460|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.8030|±  |0.0283|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8446|±  |0.0261|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.5718|±  |0.0251|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.6092|±  |0.0317|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.8055|±  |0.0170|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.6718|±  |0.0412|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.6340|±  |0.0195|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6455|±  |0.0458|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.6939|±  |0.0295|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.8358|±  |0.0262|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.8800|±  |0.0327|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5195|±  |0.0087|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3600|±  |0.0482|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.6148|±  |0.0420|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.6645|±  |0.0384|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.7431|±  |0.0365|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4600|±  |0.0501|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.4900|±  |0.0502|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.3500|±  |0.0479|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.4510|±  |0.0495|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.6800|±  |0.0469|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5149|±  |0.0327|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.5310|±  |0.0416|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4471|±  |0.0256|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7161|±  |0.0256|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.4975|±  |0.0352|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.5900|±  |0.0494|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.4000|±  |0.0299|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.3974|±  |0.0400|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.4861|±  |0.0341|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.4018|±  |0.0465|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.6044|±  |0.0039|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5532|±  |0.0067|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.6756|±  |0.0081|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.6978|±  |0.0080|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5195|±  |0.0087|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=nvidia/Llama-3.1-Minitron-4B-Depth-Base,load_in_8bit=True --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1a895a8-a8ea-4694-9154-624ff642099c",
      "metadata": {
        "id": "e1a895a8-a8ea-4694-9154-624ff642099c",
        "outputId": "d8f1d8b3-ff5a-4764-bf66-91ba6c2fe222"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-24:15:30:23,758 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-24:15:30:23,843 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-24:15:30:37,144 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-24:15:30:37,146 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-24:15:30:37,147 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'nvidia/Llama-3.1-Minitron-4B-Depth-Base', 'load_in_4bit': True}\n",
            "2024-08-24:15:30:37,383 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-24:15:30:37,383 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "2024-08-24:15:30:37,806 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:02<00:00,  1.23s/it]\n",
            "2024-08-24:15:30:41,425 WARNING  [big_modeling.py:451] You shouldn't move a model that is dispatched using accelerate hooks.\n",
            "2024-08-24:15:31:15,055 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-24:15:31:15,055 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,055 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-24:15:31:15,055 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,055 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-24:15:31:15,056 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,056 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-24:15:31:15,056 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,056 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-24:15:31:15,056 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,056 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-24:15:31:15,056 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,056 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-24:15:31:15,056 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,056 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-24:15:31:15,056 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,056 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-24:15:31:15,056 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,056 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-24:15:31:15,056 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,056 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-24:15:31:15,056 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,056 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-24:15:31:15,056 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,056 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-24:15:31:15,056 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,056 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-24:15:31:15,056 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,056 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-24:15:31:15,056 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,057 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-24:15:31:15,057 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,057 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-24:15:31:15,057 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,057 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-24:15:31:15,057 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,057 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-24:15:31:15,057 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,057 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-24:15:31:15,057 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,057 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-24:15:31:15,057 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,057 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-24:15:31:15,057 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,057 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-24:15:31:15,057 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,057 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-24:15:31:15,057 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,057 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-24:15:31:15,057 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,057 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-24:15:31:15,057 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,057 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-24:15:31:15,057 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,057 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-24:15:31:15,058 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,058 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-24:15:31:15,058 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,058 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-24:15:31:15,058 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,058 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-24:15:31:15,058 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,058 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-24:15:31:15,058 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,058 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-24:15:31:15,058 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,058 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-24:15:31:15,058 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,058 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-24:15:31:15,058 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,058 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-24:15:31:15,058 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,058 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-24:15:31:15,058 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,058 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-24:15:31:15,058 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,058 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-24:15:31:15,058 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,058 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-24:15:31:15,059 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,059 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-24:15:31:15,059 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,059 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-24:15:31:15,059 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,059 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-24:15:31:15,059 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,059 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-24:15:31:15,059 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,059 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-24:15:31:15,059 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,059 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-24:15:31:15,059 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,059 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-24:15:31:15,059 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,059 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-24:15:31:15,059 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,059 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-24:15:31:15,059 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,059 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-24:15:31:15,059 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,059 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-24:15:31:15,059 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,059 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-24:15:31:15,059 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,059 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-24:15:31:15,060 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,060 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-24:15:31:15,060 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,060 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-24:15:31:15,060 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,060 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-24:15:31:15,060 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,060 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-24:15:31:15,060 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,060 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-24:15:31:15,060 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,060 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-24:15:31:15,060 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:31:15,060 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-24:15:31:15,068 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 575.74it/s]\n",
            "2024-08-24:15:31:15,247 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 572.40it/s]\n",
            "2024-08-24:15:31:15,490 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 578.94it/s]\n",
            "2024-08-24:15:31:15,760 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 584.13it/s]\n",
            "2024-08-24:15:31:16,014 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 576.40it/s]\n",
            "2024-08-24:15:31:16,192 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 584.33it/s]\n",
            "2024-08-24:15:31:16,369 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 584.73it/s]\n",
            "2024-08-24:15:31:16,545 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 580.42it/s]\n",
            "2024-08-24:15:31:16,726 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 584.25it/s]\n",
            "2024-08-24:15:31:16,902 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 582.06it/s]\n",
            "2024-08-24:15:31:17,317 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 648.59it/s]\n",
            "2024-08-24:15:31:17,548 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 696.85it/s]\n",
            "2024-08-24:15:31:18,106 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 704.77it/s]\n",
            "2024-08-24:15:31:18,558 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 700.43it/s]\n",
            "2024-08-24:15:31:18,856 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 704.43it/s]\n",
            "2024-08-24:15:31:19,002 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 696.06it/s]\n",
            "2024-08-24:15:31:19,401 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 699.12it/s]\n",
            "2024-08-24:15:31:19,623 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 700.73it/s]\n",
            "2024-08-24:15:31:19,940 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 706.26it/s]\n",
            "2024-08-24:15:31:20,104 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 707.11it/s]\n",
            "2024-08-24:15:31:20,249 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 705.16it/s]\n",
            "2024-08-24:15:31:20,635 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 696.65it/s]\n",
            "2024-08-24:15:31:20,891 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 700.81it/s]\n",
            "2024-08-24:15:31:21,038 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 693.95it/s]\n",
            "2024-08-24:15:31:21,368 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 698.86it/s]\n",
            "2024-08-24:15:31:21,520 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 695.51it/s]\n",
            "2024-08-24:15:31:21,866 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 693.14it/s]\n",
            "2024-08-24:15:31:22,015 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 613.98it/s]\n",
            "2024-08-24:15:31:23,323 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 700.83it/s]\n",
            "2024-08-24:15:31:23,772 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 697.67it/s]\n",
            "2024-08-24:15:31:24,188 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 699.81it/s]\n",
            "2024-08-24:15:31:24,588 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 697.98it/s]\n",
            "2024-08-24:15:31:24,832 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 707.82it/s]\n",
            "2024-08-24:15:31:24,999 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 703.05it/s]\n",
            "2024-08-24:15:31:25,288 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 704.07it/s]\n",
            "2024-08-24:15:31:25,570 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 704.45it/s]\n",
            "2024-08-24:15:31:26,139 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 700.58it/s]\n",
            "2024-08-24:15:31:26,488 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 692.71it/s]\n",
            "2024-08-24:15:31:27,296 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 704.13it/s]\n",
            "2024-08-24:15:31:27,488 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 702.75it/s]\n",
            "2024-08-24:15:31:28,383 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 699.89it/s]\n",
            "2024-08-24:15:31:28,544 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 702.48it/s]\n",
            "2024-08-24:15:31:28,903 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 704.16it/s]\n",
            "2024-08-24:15:31:29,197 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 703.66it/s]\n",
            "2024-08-24:15:31:29,343 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 703.94it/s]\n",
            "2024-08-24:15:31:29,528 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 678.90it/s]\n",
            "2024-08-24:15:31:29,778 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 676.92it/s]\n",
            "2024-08-24:15:31:30,088 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 687.43it/s]\n",
            "2024-08-24:15:31:30,444 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 699.54it/s]\n",
            "2024-08-24:15:31:30,623 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 702.57it/s]\n",
            "2024-08-24:15:31:30,781 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 679.61it/s]\n",
            "2024-08-24:15:31:31,028 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 704.19it/s]\n",
            "2024-08-24:15:31:31,534 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 608.51it/s]\n",
            "2024-08-24:15:31:33,039 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 692.42it/s]\n",
            "2024-08-24:15:31:33,501 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 701.08it/s]\n",
            "2024-08-24:15:31:33,977 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 696.08it/s]\n",
            "2024-08-24:15:31:36,243 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 692.28it/s]\n",
            "2024-08-24:15:31:36,498 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 15749.86it/s]\n",
            "2024-08-24:15:31:38,078 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1380.09it/s]\n",
            "2024-08-24:15:31:38,986 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n",
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
            "Running loglikelihood requests: 100%|██| 174850/174850 [10:21<00:00, 281.51it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-24:15:43:50,089 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=nvidia/Llama-3.1-Minitron-4B-Depth-Base,load_in_4bit=True), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.4070|±  |0.0144|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.4548|±  |0.0146|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.2199|±  |0.0038|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.5746|±  |0.0040|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5207|±  |0.0068|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.3571|±  |0.0429|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7152|±  |0.0352|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.7353|±  |0.0310|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.7764|±  |0.0271|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.6942|±  |0.0421|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.6944|±  |0.0445|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.6810|±  |0.0366|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.6387|±  |0.0259|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2480|±  |0.0144|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.6688|±  |0.0267|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.6667|±  |0.0262|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4459|±  |0.0127|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.7719|±  |0.0322|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.6476|±  |0.0083|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.5600|±  |0.0499|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.6642|±  |0.0291|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.5954|±  |0.0374|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.3800|±  |0.0488|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.6861|±  |0.0311|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.7670|±  |0.0419|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8120|±  |0.0256|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.6300|±  |0.0485|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.7727|±  |0.0150|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.6307|±  |0.0276|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.4184|±  |0.0294|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.5441|±  |0.0303|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5422|±  |0.0388|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.6679|±  |0.0083|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.3596|±  |0.0451|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.7424|±  |0.0312|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.7979|±  |0.0290|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.5538|±  |0.0252|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.5714|±  |0.0321|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.8000|±  |0.0171|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.6183|±  |0.0426|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.6111|±  |0.0197|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6636|±  |0.0453|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.6531|±  |0.0305|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.7612|±  |0.0301|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.8400|±  |0.0368|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.4919|±  |0.0087|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.2900|±  |0.0456|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.5704|±  |0.0428|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.6382|±  |0.0391|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.6944|±  |0.0385|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4500|±  |0.0500|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.4500|±  |0.0500|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.3800|±  |0.0488|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.3529|±  |0.0476|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.6700|±  |0.0473|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5106|±  |0.0327|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.5103|±  |0.0417|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4418|±  |0.0256|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7000|±  |0.0261|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.4236|±  |0.0348|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.5200|±  |0.0502|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3519|±  |0.0291|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.3510|±  |0.0390|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.4491|±  |0.0339|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.5000|±  |0.0475|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.5746|±  |0.0040|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5207|±  |0.0068|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.6476|±  |0.0083|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.6679|±  |0.0083|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.4919|±  |0.0087|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=nvidia/Llama-3.1-Minitron-4B-Depth-Base,load_in_4bit=True --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32a4b560-2a0a-4114-8be4-e181585eb1ec",
      "metadata": {
        "id": "32a4b560-2a0a-4114-8be4-e181585eb1ec",
        "outputId": "c90094f8-ef2e-418d-88c1-560613b3c841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-24:15:43:55,554 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-24:15:43:55,639 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-24:15:44:07,383 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-24:15:44:07,385 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-24:15:44:07,385 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': 'kaitchup/Llama-3.1-Minitron-4B-Depth-Base-AutoRound-GPTQ-sym-4bit'}\n",
            "2024-08-24:15:44:07,664 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-24:15:44:07,665 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "config.json: 100%|█████████████████████████| 1.54k/1.54k [00:00<00:00, 5.24MB/s]\n",
            "tokenizer_config.json: 100%|███████████████| 50.6k/50.6k [00:00<00:00, 99.3MB/s]\n",
            "tokenizer.json: 100%|██████████████████████| 9.09M/9.09M [00:00<00:00, 33.6MB/s]\n",
            "special_tokens_map.json: 100%|█████████████████| 301/301 [00:00<00:00, 1.14MB/s]\n",
            "2024-08-24:15:44:08,707 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "2024-08-24:15:44:09,593 WARNING  [qlinear_cuda.py:18] CUDA extension not installed.\n",
            "2024-08-24:15:44:09,593 WARNING  [qlinear_cuda_old.py:17] CUDA extension not installed.\n",
            "model.safetensors: 100%|███████████████████| 3.92G/3.92G [01:18<00:00, 50.0MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4709: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n",
            "generation_config.json: 100%|███████████████████| 126/126 [00:00<00:00, 514kB/s]\n",
            "2024-08-24:15:46:01,088 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-24:15:46:01,088 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,088 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-24:15:46:01,088 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,088 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-24:15:46:01,088 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,088 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-24:15:46:01,088 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,088 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-24:15:46:01,088 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,088 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-24:15:46:01,088 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,089 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-24:15:46:01,089 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,089 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-24:15:46:01,089 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,089 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-24:15:46:01,089 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,089 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-24:15:46:01,089 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,089 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-24:15:46:01,089 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,089 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-24:15:46:01,089 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,089 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-24:15:46:01,089 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,089 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-24:15:46:01,089 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,089 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-24:15:46:01,089 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,089 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-24:15:46:01,089 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,089 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-24:15:46:01,089 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,089 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-24:15:46:01,089 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,089 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-24:15:46:01,089 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,089 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-24:15:46:01,089 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,090 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-24:15:46:01,090 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,090 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-24:15:46:01,090 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,090 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-24:15:46:01,090 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,090 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-24:15:46:01,090 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,090 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-24:15:46:01,090 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,090 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-24:15:46:01,090 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,090 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-24:15:46:01,090 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,090 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-24:15:46:01,090 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,090 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-24:15:46:01,090 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,090 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-24:15:46:01,090 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,090 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-24:15:46:01,090 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,090 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-24:15:46:01,090 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,090 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-24:15:46:01,090 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,090 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-24:15:46:01,091 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,091 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-24:15:46:01,091 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,091 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-24:15:46:01,091 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,091 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-24:15:46:01,091 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,091 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-24:15:46:01,091 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,091 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-24:15:46:01,091 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,091 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-24:15:46:01,091 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,091 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-24:15:46:01,091 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,091 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-24:15:46:01,091 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,091 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-24:15:46:01,091 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,091 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-24:15:46:01,091 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,091 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-24:15:46:01,091 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,091 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-24:15:46:01,091 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,091 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-24:15:46:01,091 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,092 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-24:15:46:01,092 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,092 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-24:15:46:01,092 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,092 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-24:15:46:01,092 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,092 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-24:15:46:01,092 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,092 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-24:15:46:01,092 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,092 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-24:15:46:01,092 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,092 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-24:15:46:01,092 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,092 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-24:15:46:01,092 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,092 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-24:15:46:01,092 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,092 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-24:15:46:01,092 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,092 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-24:15:46:01,092 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,092 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-24:15:46:01,092 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-24:15:46:01,092 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-24:15:46:01,101 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 553.84it/s]\n",
            "2024-08-24:15:46:01,286 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 562.92it/s]\n",
            "2024-08-24:15:46:01,533 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 558.35it/s]\n",
            "2024-08-24:15:46:01,813 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 571.10it/s]\n",
            "2024-08-24:15:46:02,072 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 565.46it/s]\n",
            "2024-08-24:15:46:02,255 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 575.03it/s]\n",
            "2024-08-24:15:46:02,434 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 578.02it/s]\n",
            "2024-08-24:15:46:02,612 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 567.57it/s]\n",
            "2024-08-24:15:46:02,797 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 568.31it/s]\n",
            "2024-08-24:15:46:02,979 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 571.07it/s]\n",
            "2024-08-24:15:46:03,401 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 573.11it/s]\n",
            "2024-08-24:15:46:03,662 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 573.91it/s]\n",
            "2024-08-24:15:46:04,338 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 571.59it/s]\n",
            "2024-08-24:15:46:04,895 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 576.83it/s]\n",
            "2024-08-24:15:46:05,258 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 573.60it/s]\n",
            "2024-08-24:15:46:05,437 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 668.86it/s]\n",
            "2024-08-24:15:46:05,854 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 705.04it/s]\n",
            "2024-08-24:15:46:06,075 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 686.87it/s]\n",
            "2024-08-24:15:46:06,398 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 698.95it/s]\n",
            "2024-08-24:15:46:06,563 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 713.29it/s]\n",
            "2024-08-24:15:46:06,708 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 702.12it/s]\n",
            "2024-08-24:15:46:07,096 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 703.75it/s]\n",
            "2024-08-24:15:46:07,349 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 686.52it/s]\n",
            "2024-08-24:15:46:07,499 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 706.14it/s]\n",
            "2024-08-24:15:46:07,823 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 691.56it/s]\n",
            "2024-08-24:15:46:07,977 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 707.16it/s]\n",
            "2024-08-24:15:46:08,317 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 707.73it/s]\n",
            "2024-08-24:15:46:08,463 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 698.26it/s]\n",
            "2024-08-24:15:46:09,767 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 712.16it/s]\n",
            "2024-08-24:15:46:10,209 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 716.20it/s]\n",
            "2024-08-24:15:46:10,614 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 713.78it/s]\n",
            "2024-08-24:15:46:11,006 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 703.29it/s]\n",
            "2024-08-24:15:46:11,249 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 715.14it/s]\n",
            "2024-08-24:15:46:11,413 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 715.11it/s]\n",
            "2024-08-24:15:46:11,698 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 709.22it/s]\n",
            "2024-08-24:15:46:11,978 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 701.44it/s]\n",
            "2024-08-24:15:46:12,549 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 707.33it/s]\n",
            "2024-08-24:15:46:12,895 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 688.96it/s]\n",
            "2024-08-24:15:46:13,707 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 667.52it/s]\n",
            "2024-08-24:15:46:13,910 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 701.53it/s]\n",
            "2024-08-24:15:46:14,820 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 698.23it/s]\n",
            "2024-08-24:15:46:14,982 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 697.47it/s]\n",
            "2024-08-24:15:46:15,344 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 710.17it/s]\n",
            "2024-08-24:15:46:15,635 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 696.26it/s]\n",
            "2024-08-24:15:46:15,783 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 715.75it/s]\n",
            "2024-08-24:15:46:15,965 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 705.09it/s]\n",
            "2024-08-24:15:46:16,206 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 675.62it/s]\n",
            "2024-08-24:15:46:16,516 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 683.09it/s]\n",
            "2024-08-24:15:46:16,873 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 668.27it/s]\n",
            "2024-08-24:15:46:17,059 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 669.19it/s]\n",
            "2024-08-24:15:46:17,225 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 679.64it/s]\n",
            "2024-08-24:15:46:17,473 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 717.66it/s]\n",
            "2024-08-24:15:46:17,969 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 617.17it/s]\n",
            "2024-08-24:15:46:19,452 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 717.57it/s]\n",
            "2024-08-24:15:46:19,898 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 717.01it/s]\n",
            "2024-08-24:15:46:20,362 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 707.64it/s]\n",
            "2024-08-24:15:46:22,587 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 720.75it/s]\n",
            "2024-08-24:15:46:22,831 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 16010.22it/s]\n",
            "2024-08-24:15:46:24,368 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1382.38it/s]\n",
            "2024-08-24:15:46:25,275 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n",
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
            "Running loglikelihood requests: 100%|██| 174850/174850 [22:57<00:00, 126.96it/s]\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-24:16:11:15,862 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=kaitchup/Llama-3.1-Minitron-4B-Depth-Base-AutoRound-GPTQ-sym-4bit), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.4061|±  |0.0144|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.4497|±  |0.0145|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.2323|±  |0.0039|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.5888|±  |0.0039|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5392|±  |0.0068|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.3651|±  |0.0431|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7212|±  |0.0350|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.7549|±  |0.0302|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.8186|±  |0.0251|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.7438|±  |0.0398|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.6667|±  |0.0456|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7055|±  |0.0358|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.6676|±  |0.0254|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2525|±  |0.0145|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.6849|±  |0.0264|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.6852|±  |0.0258|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4694|±  |0.0127|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.7895|±  |0.0313|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.6585|±  |0.0082|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.6300|±  |0.0485|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.6642|±  |0.0291|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.5607|±  |0.0378|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.3300|±  |0.0473|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.6457|±  |0.0321|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.7184|±  |0.0445|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8376|±  |0.0242|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.6800|±  |0.0469|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.7880|±  |0.0146|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.6536|±  |0.0272|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.4539|±  |0.0297|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.6029|±  |0.0297|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5181|±  |0.0389|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.6809|±  |0.0082|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.3684|±  |0.0454|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.8030|±  |0.0283|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8031|±  |0.0287|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.5744|±  |0.0251|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.5924|±  |0.0319|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.7798|±  |0.0178|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.6870|±  |0.0407|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.6176|±  |0.0197|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6727|±  |0.0449|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.6776|±  |0.0299|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.7910|±  |0.0287|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.8200|±  |0.0386|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5043|±  |0.0087|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3700|±  |0.0485|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.6000|±  |0.0423|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.6645|±  |0.0384|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.6944|±  |0.0385|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4600|±  |0.0501|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.4700|±  |0.0502|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.3400|±  |0.0476|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.3824|±  |0.0484|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.6500|±  |0.0479|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.4638|±  |0.0326|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.5655|±  |0.0413|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4339|±  |0.0255|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7000|±  |0.0261|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.4828|±  |0.0352|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.6600|±  |0.0476|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3704|±  |0.0294|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.4503|±  |0.0406|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.4306|±  |0.0338|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.3839|±  |0.0462|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.5888|±  |0.0039|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5392|±  |0.0068|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.6585|±  |0.0082|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.6809|±  |0.0082|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5043|±  |0.0087|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=kaitchup/Llama-3.1-Minitron-4B-Depth-Base-AutoRound-GPTQ-sym-4bit --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1ab3393-a5d8-4544-8f6e-e84b960f014a",
      "metadata": {
        "id": "f1ab3393-a5d8-4544-8f6e-e84b960f014a",
        "outputId": "d4f11ad7-4898-453b-8fa8-cf7704463573"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-25:17:47:23,329 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-25:17:47:23,627 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-25:17:47:35,634 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-25:17:47:35,636 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-25:17:47:35,636 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': './AutoRound/Llama-3.1-Minitron-4B-Depth-Base-AutoRound-GPTQ-asym-4bit'}\n",
            "2024-08-25:17:47:35,715 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-25:17:47:35,715 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "2024-08-25:17:47:36,097 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "2024-08-25:17:47:36,919 WARNING  [qlinear_cuda.py:18] CUDA extension not installed.\n",
            "2024-08-25:17:47:36,920 WARNING  [qlinear_cuda_old.py:17] CUDA extension not installed.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4709: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at ./AutoRound/Llama-3.1-Minitron-4B-Depth-Base-AutoRound-GPTQ-asym-4bit were not used when initializing LlamaForCausalLM: ['model.layers.0.mlp.down_proj.bias', 'model.layers.0.mlp.gate_proj.bias', 'model.layers.0.mlp.up_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.o_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.1.mlp.down_proj.bias', 'model.layers.1.mlp.gate_proj.bias', 'model.layers.1.mlp.up_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.o_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.10.mlp.down_proj.bias', 'model.layers.10.mlp.gate_proj.bias', 'model.layers.10.mlp.up_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.o_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.11.mlp.down_proj.bias', 'model.layers.11.mlp.gate_proj.bias', 'model.layers.11.mlp.up_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.o_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.12.mlp.down_proj.bias', 'model.layers.12.mlp.gate_proj.bias', 'model.layers.12.mlp.up_proj.bias', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.o_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.13.mlp.down_proj.bias', 'model.layers.13.mlp.gate_proj.bias', 'model.layers.13.mlp.up_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.o_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.14.mlp.down_proj.bias', 'model.layers.14.mlp.gate_proj.bias', 'model.layers.14.mlp.up_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.o_proj.bias', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.15.mlp.down_proj.bias', 'model.layers.15.mlp.gate_proj.bias', 'model.layers.15.mlp.up_proj.bias', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.o_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.2.mlp.down_proj.bias', 'model.layers.2.mlp.gate_proj.bias', 'model.layers.2.mlp.up_proj.bias', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.o_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.3.mlp.down_proj.bias', 'model.layers.3.mlp.gate_proj.bias', 'model.layers.3.mlp.up_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.o_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.4.mlp.down_proj.bias', 'model.layers.4.mlp.gate_proj.bias', 'model.layers.4.mlp.up_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.o_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.5.mlp.down_proj.bias', 'model.layers.5.mlp.gate_proj.bias', 'model.layers.5.mlp.up_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.o_proj.bias', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.6.mlp.down_proj.bias', 'model.layers.6.mlp.gate_proj.bias', 'model.layers.6.mlp.up_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.o_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.7.mlp.down_proj.bias', 'model.layers.7.mlp.gate_proj.bias', 'model.layers.7.mlp.up_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.o_proj.bias', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.8.mlp.down_proj.bias', 'model.layers.8.mlp.gate_proj.bias', 'model.layers.8.mlp.up_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.o_proj.bias', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.9.mlp.down_proj.bias', 'model.layers.9.mlp.gate_proj.bias', 'model.layers.9.mlp.up_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.o_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.v_proj.bias']\n",
            "- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "2024-08-25:17:48:28,440 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-25:17:48:28,440 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,440 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-25:17:48:28,440 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,440 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-25:17:48:28,440 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,440 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-25:17:48:28,440 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,440 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-25:17:48:28,441 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,441 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-25:17:48:28,441 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,441 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-25:17:48:28,441 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,441 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-25:17:48:28,441 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,441 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-25:17:48:28,441 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,441 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-25:17:48:28,441 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,441 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-25:17:48:28,441 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,441 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-25:17:48:28,441 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,441 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-25:17:48:28,441 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,441 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-25:17:48:28,441 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,441 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-25:17:48:28,441 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,441 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-25:17:48:28,441 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,441 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-25:17:48:28,441 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,441 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-25:17:48:28,441 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,441 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-25:17:48:28,442 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,442 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-25:17:48:28,442 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,442 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-25:17:48:28,442 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,442 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-25:17:48:28,442 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,442 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-25:17:48:28,442 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,442 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-25:17:48:28,442 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,442 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-25:17:48:28,442 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,442 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-25:17:48:28,442 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,442 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-25:17:48:28,442 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,442 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-25:17:48:28,442 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,442 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-25:17:48:28,442 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,442 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-25:17:48:28,442 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,442 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-25:17:48:28,442 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,442 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-25:17:48:28,442 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,442 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-25:17:48:28,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-25:17:48:28,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-25:17:48:28,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-25:17:48:28,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-25:17:48:28,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-25:17:48:28,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-25:17:48:28,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-25:17:48:28,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-25:17:48:28,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-25:17:48:28,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-25:17:48:28,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-25:17:48:28,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-25:17:48:28,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-25:17:48:28,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,443 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-25:17:48:28,443 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-25:17:48:28,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-25:17:48:28,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-25:17:48:28,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-25:17:48:28,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-25:17:48:28,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-25:17:48:28,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-25:17:48:28,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-25:17:48:28,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-25:17:48:28,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-25:17:48:28,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-25:17:48:28,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,444 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-25:17:48:28,444 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:17:48:28,444 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-25:17:48:28,452 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 567.24it/s]\n",
            "2024-08-25:17:48:28,636 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 576.21it/s]\n",
            "2024-08-25:17:48:28,877 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 575.79it/s]\n",
            "2024-08-25:17:48:29,149 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 572.05it/s]\n",
            "2024-08-25:17:48:29,408 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 570.61it/s]\n",
            "2024-08-25:17:48:29,589 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 572.70it/s]\n",
            "2024-08-25:17:48:29,769 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 576.48it/s]\n",
            "2024-08-25:17:48:29,948 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 559.72it/s]\n",
            "2024-08-25:17:48:30,135 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 571.05it/s]\n",
            "2024-08-25:17:48:30,316 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 515.30it/s]\n",
            "2024-08-25:17:48:30,787 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 580.12it/s]\n",
            "2024-08-25:17:48:31,045 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 680.07it/s]\n",
            "2024-08-25:17:48:31,618 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 702.80it/s]\n",
            "2024-08-25:17:48:32,072 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 704.36it/s]\n",
            "2024-08-25:17:48:32,368 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 698.61it/s]\n",
            "2024-08-25:17:48:32,517 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 704.76it/s]\n",
            "2024-08-25:17:48:32,911 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 694.06it/s]\n",
            "2024-08-25:17:48:33,135 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 707.29it/s]\n",
            "2024-08-25:17:48:33,449 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 686.68it/s]\n",
            "2024-08-25:17:48:33,617 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 708.87it/s]\n",
            "2024-08-25:17:48:33,762 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 709.52it/s]\n",
            "2024-08-25:17:48:34,146 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 704.94it/s]\n",
            "2024-08-25:17:48:34,399 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 711.10it/s]\n",
            "2024-08-25:17:48:34,543 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 698.99it/s]\n",
            "2024-08-25:17:48:34,871 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 702.96it/s]\n",
            "2024-08-25:17:48:35,023 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 696.32it/s]\n",
            "2024-08-25:17:48:35,369 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 696.49it/s]\n",
            "2024-08-25:17:48:35,517 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 704.71it/s]\n",
            "2024-08-25:17:48:36,812 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 708.11it/s]\n",
            "2024-08-25:17:48:37,256 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 711.13it/s]\n",
            "2024-08-25:17:48:37,664 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 705.48it/s]\n",
            "2024-08-25:17:48:38,061 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 703.67it/s]\n",
            "2024-08-25:17:48:38,303 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 709.30it/s]\n",
            "2024-08-25:17:48:38,469 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 709.86it/s]\n",
            "2024-08-25:17:48:38,756 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 715.56it/s]\n",
            "2024-08-25:17:48:39,033 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 712.85it/s]\n",
            "2024-08-25:17:48:39,595 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 716.12it/s]\n",
            "2024-08-25:17:48:39,937 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 716.37it/s]\n",
            "2024-08-25:17:48:40,718 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 716.92it/s]\n",
            "2024-08-25:17:48:40,906 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 716.88it/s]\n",
            "2024-08-25:17:48:41,782 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 716.90it/s]\n",
            "2024-08-25:17:48:41,941 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 720.84it/s]\n",
            "2024-08-25:17:48:42,290 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 720.16it/s]\n",
            "2024-08-25:17:48:42,577 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 718.20it/s]\n",
            "2024-08-25:17:48:42,721 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 715.03it/s]\n",
            "2024-08-25:17:48:42,902 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 709.73it/s]\n",
            "2024-08-25:17:48:43,141 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 705.60it/s]\n",
            "2024-08-25:17:48:43,439 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 709.05it/s]\n",
            "2024-08-25:17:48:43,783 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 714.80it/s]\n",
            "2024-08-25:17:48:43,957 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 704.14it/s]\n",
            "2024-08-25:17:48:44,115 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 701.87it/s]\n",
            "2024-08-25:17:48:44,354 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 698.57it/s]\n",
            "2024-08-25:17:48:44,864 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 607.57it/s]\n",
            "2024-08-25:17:48:46,371 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 711.54it/s]\n",
            "2024-08-25:17:48:46,821 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 710.52it/s]\n",
            "2024-08-25:17:48:47,289 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 708.63it/s]\n",
            "2024-08-25:17:48:49,514 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 708.02it/s]\n",
            "2024-08-25:17:48:49,762 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 15470.02it/s]\n",
            "2024-08-25:17:48:51,356 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1375.79it/s]\n",
            "2024-08-25:17:48:52,269 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n",
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
            "Running loglikelihood requests: 100%|██| 174850/174850 [22:56<00:00, 127.00it/s]\n",
            "2024-08-25:18:13:40,919 WARNING  [huggingface.py:1427] Failed to get model SHA for ./AutoRound/Llama-3.1-Minitron-4B-Depth-Base-AutoRound-GPTQ-asym-4bit at revision main. Error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './AutoRound/Llama-3.1-Minitron-4B-Depth-Base-AutoRound-GPTQ-asym-4bit'. Use `repo_type` argument if needed.\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-25:18:13:42,220 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=./AutoRound/Llama-3.1-Minitron-4B-Depth-Base-AutoRound-GPTQ-asym-4bit), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.4113|±  |0.0144|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.4386|±  |0.0145|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.2360|±  |0.0039|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.5960|±  |0.0039|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5439|±  |0.0068|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.4127|±  |0.0440|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7515|±  |0.0337|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.7255|±  |0.0313|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.7975|±  |0.0262|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.7438|±  |0.0398|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.6852|±  |0.0449|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.6994|±  |0.0360|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.6618|±  |0.0255|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2648|±  |0.0148|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.6752|±  |0.0266|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.7006|±  |0.0255|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4739|±  |0.0128|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.8070|±  |0.0303|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.6678|±  |0.0082|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.6500|±  |0.0479|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.6830|±  |0.0286|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.6069|±  |0.0372|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.4100|±  |0.0494|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.6547|±  |0.0319|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.7670|±  |0.0419|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8077|±  |0.0258|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.6700|±  |0.0473|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.7918|±  |0.0145|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.6438|±  |0.0274|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.4504|±  |0.0297|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.6287|±  |0.0293|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.5241|±  |0.0389|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.6822|±  |0.0081|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.3947|±  |0.0460|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.7828|±  |0.0294|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8394|±  |0.0265|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.5564|±  |0.0252|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.5588|±  |0.0323|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.7963|±  |0.0173|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.6718|±  |0.0412|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.6160|±  |0.0197|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6455|±  |0.0458|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.6776|±  |0.0299|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.8159|±  |0.0274|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.8700|±  |0.0338|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5189|±  |0.0087|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.3400|±  |0.0476|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.6444|±  |0.0414|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.6842|±  |0.0378|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.7222|±  |0.0375|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4100|±  |0.0494|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.4700|±  |0.0502|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.3700|±  |0.0485|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.4314|±  |0.0493|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.6700|±  |0.0473|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5191|±  |0.0327|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.5517|±  |0.0414|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4630|±  |0.0257|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7161|±  |0.0256|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.5074|±  |0.0352|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.6300|±  |0.0485|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3556|±  |0.0292|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.4371|±  |0.0405|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.4583|±  |0.0340|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.4018|±  |0.0465|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.5960|±  |0.0039|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5439|±  |0.0068|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.6678|±  |0.0082|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.6822|±  |0.0081|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5189|±  |0.0087|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=./AutoRound/Llama-3.1-Minitron-4B-Depth-Base-AutoRound-GPTQ-asym-4bit --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3428e811-a5e4-4bae-8509-a7b2634bc70c",
      "metadata": {
        "id": "3428e811-a5e4-4bae-8509-a7b2634bc70c",
        "outputId": "e534a503-91fb-49d5-c363-f72de3ce0ba5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-08-25:18:13:49,567 INFO     [__main__.py:279] Verbosity set to INFO\n",
            "2024-08-25:18:13:49,669 INFO     [__init__.py:491] `group` and `group_alias` keys in tasks' configs will no longer be used in the next release of lm-eval. `tag` will be used to allow to call a collection of tasks just like `group`. `group` will be removed in order to not cause confusion with the new ConfigurableGroup which will be the official way to create groups with addition of group-wide configurations.\n",
            "2024-08-25:18:14:03,823 INFO     [__main__.py:383] Selected Tasks: ['arc_challenge', 'leaderboard_mmlu_pro', 'mmlu']\n",
            "2024-08-25:18:14:03,826 INFO     [evaluator.py:161] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
            "2024-08-25:18:14:03,826 INFO     [evaluator.py:198] Initializing hf model, with arguments: {'pretrained': './AutoRound/Llama-3.1-Minitron-4B-Width-Base-AutoRound-GPTQ-asym-4bit'}\n",
            "2024-08-25:18:14:03,928 WARNING  [other.py:349] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
            "2024-08-25:18:14:03,928 INFO     [huggingface.py:130] Using device 'cuda:0'\n",
            "2024-08-25:18:14:04,313 INFO     [huggingface.py:366] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}\n",
            "2024-08-25:18:14:05,154 WARNING  [qlinear_cuda.py:18] CUDA extension not installed.\n",
            "2024-08-25:18:14:05,155 WARNING  [qlinear_cuda_old.py:17] CUDA extension not installed.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4709: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at ./AutoRound/Llama-3.1-Minitron-4B-Width-Base-AutoRound-GPTQ-asym-4bit were not used when initializing LlamaForCausalLM: ['model.layers.0.mlp.down_proj.bias', 'model.layers.0.mlp.gate_proj.bias', 'model.layers.0.mlp.up_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.o_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.1.mlp.down_proj.bias', 'model.layers.1.mlp.gate_proj.bias', 'model.layers.1.mlp.up_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.o_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.10.mlp.down_proj.bias', 'model.layers.10.mlp.gate_proj.bias', 'model.layers.10.mlp.up_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.o_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.11.mlp.down_proj.bias', 'model.layers.11.mlp.gate_proj.bias', 'model.layers.11.mlp.up_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.o_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.12.mlp.down_proj.bias', 'model.layers.12.mlp.gate_proj.bias', 'model.layers.12.mlp.up_proj.bias', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.o_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.13.mlp.down_proj.bias', 'model.layers.13.mlp.gate_proj.bias', 'model.layers.13.mlp.up_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.o_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.14.mlp.down_proj.bias', 'model.layers.14.mlp.gate_proj.bias', 'model.layers.14.mlp.up_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.o_proj.bias', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.15.mlp.down_proj.bias', 'model.layers.15.mlp.gate_proj.bias', 'model.layers.15.mlp.up_proj.bias', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.o_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.16.mlp.down_proj.bias', 'model.layers.16.mlp.gate_proj.bias', 'model.layers.16.mlp.up_proj.bias', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.o_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.17.mlp.down_proj.bias', 'model.layers.17.mlp.gate_proj.bias', 'model.layers.17.mlp.up_proj.bias', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.o_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.18.mlp.down_proj.bias', 'model.layers.18.mlp.gate_proj.bias', 'model.layers.18.mlp.up_proj.bias', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.o_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.19.mlp.down_proj.bias', 'model.layers.19.mlp.gate_proj.bias', 'model.layers.19.mlp.up_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.o_proj.bias', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.2.mlp.down_proj.bias', 'model.layers.2.mlp.gate_proj.bias', 'model.layers.2.mlp.up_proj.bias', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.o_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.20.mlp.down_proj.bias', 'model.layers.20.mlp.gate_proj.bias', 'model.layers.20.mlp.up_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.o_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.21.mlp.down_proj.bias', 'model.layers.21.mlp.gate_proj.bias', 'model.layers.21.mlp.up_proj.bias', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.o_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.22.mlp.down_proj.bias', 'model.layers.22.mlp.gate_proj.bias', 'model.layers.22.mlp.up_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.o_proj.bias', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.23.mlp.down_proj.bias', 'model.layers.23.mlp.gate_proj.bias', 'model.layers.23.mlp.up_proj.bias', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.o_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.24.mlp.down_proj.bias', 'model.layers.24.mlp.gate_proj.bias', 'model.layers.24.mlp.up_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.o_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.25.mlp.down_proj.bias', 'model.layers.25.mlp.gate_proj.bias', 'model.layers.25.mlp.up_proj.bias', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.o_proj.bias', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.26.mlp.down_proj.bias', 'model.layers.26.mlp.gate_proj.bias', 'model.layers.26.mlp.up_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.o_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.27.mlp.down_proj.bias', 'model.layers.27.mlp.gate_proj.bias', 'model.layers.27.mlp.up_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.o_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.28.mlp.down_proj.bias', 'model.layers.28.mlp.gate_proj.bias', 'model.layers.28.mlp.up_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.o_proj.bias', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.29.mlp.down_proj.bias', 'model.layers.29.mlp.gate_proj.bias', 'model.layers.29.mlp.up_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.29.self_attn.o_proj.bias', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.3.mlp.down_proj.bias', 'model.layers.3.mlp.gate_proj.bias', 'model.layers.3.mlp.up_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.o_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.30.mlp.down_proj.bias', 'model.layers.30.mlp.gate_proj.bias', 'model.layers.30.mlp.up_proj.bias', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.o_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.31.mlp.down_proj.bias', 'model.layers.31.mlp.gate_proj.bias', 'model.layers.31.mlp.up_proj.bias', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.31.self_attn.o_proj.bias', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.4.mlp.down_proj.bias', 'model.layers.4.mlp.gate_proj.bias', 'model.layers.4.mlp.up_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.o_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.5.mlp.down_proj.bias', 'model.layers.5.mlp.gate_proj.bias', 'model.layers.5.mlp.up_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.o_proj.bias', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.6.mlp.down_proj.bias', 'model.layers.6.mlp.gate_proj.bias', 'model.layers.6.mlp.up_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.o_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.7.mlp.down_proj.bias', 'model.layers.7.mlp.gate_proj.bias', 'model.layers.7.mlp.up_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.o_proj.bias', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.8.mlp.down_proj.bias', 'model.layers.8.mlp.gate_proj.bias', 'model.layers.8.mlp.up_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.o_proj.bias', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.9.mlp.down_proj.bias', 'model.layers.9.mlp.gate_proj.bias', 'model.layers.9.mlp.up_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.o_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.v_proj.bias']\n",
            "- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "2024-08-25:18:15:11,937 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0\n",
            "2024-08-25:18:15:11,937 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,937 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_anatomy from None to 0\n",
            "2024-08-25:18:15:11,937 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,938 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_astronomy from None to 0\n",
            "2024-08-25:18:15:11,938 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,938 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_biology from None to 0\n",
            "2024-08-25:18:15:11,938 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,938 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_chemistry from None to 0\n",
            "2024-08-25:18:15:11,938 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,938 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_computer_science from None to 0\n",
            "2024-08-25:18:15:11,938 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,938 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_mathematics from None to 0\n",
            "2024-08-25:18:15:11,938 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,938 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_physics from None to 0\n",
            "2024-08-25:18:15:11,938 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,938 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_computer_security from None to 0\n",
            "2024-08-25:18:15:11,938 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,938 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0\n",
            "2024-08-25:18:15:11,938 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,938 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0\n",
            "2024-08-25:18:15:11,938 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,938 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0\n",
            "2024-08-25:18:15:11,938 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,938 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_biology from None to 0\n",
            "2024-08-25:18:15:11,938 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,938 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0\n",
            "2024-08-25:18:15:11,938 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,938 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0\n",
            "2024-08-25:18:15:11,938 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,938 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0\n",
            "2024-08-25:18:15:11,938 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,939 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_physics from None to 0\n",
            "2024-08-25:18:15:11,939 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,939 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0\n",
            "2024-08-25:18:15:11,939 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,939 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_machine_learning from None to 0\n",
            "2024-08-25:18:15:11,939 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,939 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_business_ethics from None to 0\n",
            "2024-08-25:18:15:11,939 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,939 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0\n",
            "2024-08-25:18:15:11,939 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,939 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_college_medicine from None to 0\n",
            "2024-08-25:18:15:11,939 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,939 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_global_facts from None to 0\n",
            "2024-08-25:18:15:11,939 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,939 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_aging from None to 0\n",
            "2024-08-25:18:15:11,939 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,939 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_management from None to 0\n",
            "2024-08-25:18:15:11,939 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,939 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_marketing from None to 0\n",
            "2024-08-25:18:15:11,939 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,939 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_medical_genetics from None to 0\n",
            "2024-08-25:18:15:11,939 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,939 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_miscellaneous from None to 0\n",
            "2024-08-25:18:15:11,939 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,939 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_nutrition from None to 0\n",
            "2024-08-25:18:15:11,939 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,939 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_accounting from None to 0\n",
            "2024-08-25:18:15:11,939 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,939 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_medicine from None to 0\n",
            "2024-08-25:18:15:11,940 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,940 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_virology from None to 0\n",
            "2024-08-25:18:15:11,940 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,940 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_econometrics from None to 0\n",
            "2024-08-25:18:15:11,940 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,940 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_geography from None to 0\n",
            "2024-08-25:18:15:11,940 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,940 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0\n",
            "2024-08-25:18:15:11,940 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,940 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0\n",
            "2024-08-25:18:15:11,940 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,940 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0\n",
            "2024-08-25:18:15:11,940 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,940 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0\n",
            "2024-08-25:18:15:11,940 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,940 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_human_sexuality from None to 0\n",
            "2024-08-25:18:15:11,940 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,940 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_psychology from None to 0\n",
            "2024-08-25:18:15:11,940 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,940 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_public_relations from None to 0\n",
            "2024-08-25:18:15:11,940 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,940 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_security_studies from None to 0\n",
            "2024-08-25:18:15:11,940 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,940 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_sociology from None to 0\n",
            "2024-08-25:18:15:11,940 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,940 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0\n",
            "2024-08-25:18:15:11,940 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,940 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_formal_logic from None to 0\n",
            "2024-08-25:18:15:11,941 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,941 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0\n",
            "2024-08-25:18:15:11,941 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,941 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0\n",
            "2024-08-25:18:15:11,941 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,941 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0\n",
            "2024-08-25:18:15:11,941 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,941 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_international_law from None to 0\n",
            "2024-08-25:18:15:11,941 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,941 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_jurisprudence from None to 0\n",
            "2024-08-25:18:15:11,941 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,941 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0\n",
            "2024-08-25:18:15:11,941 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,941 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_disputes from None to 0\n",
            "2024-08-25:18:15:11,941 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,941 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0\n",
            "2024-08-25:18:15:11,941 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,941 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_philosophy from None to 0\n",
            "2024-08-25:18:15:11,941 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,941 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_prehistory from None to 0\n",
            "2024-08-25:18:15:11,941 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,941 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_professional_law from None to 0\n",
            "2024-08-25:18:15:11,941 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,941 WARNING  [evaluator.py:265] Overwriting default num_fewshot of mmlu_world_religions from None to 0\n",
            "2024-08-25:18:15:11,941 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,941 WARNING  [evaluator.py:265] Overwriting default num_fewshot of leaderboard_mmlu_pro from 5 to 0\n",
            "2024-08-25:18:15:11,941 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,941 WARNING  [evaluator.py:265] Overwriting default num_fewshot of arc_challenge from None to 0\n",
            "2024-08-25:18:15:11,942 INFO     [evaluator.py:277] Setting fewshot random generator seed to 1234\n",
            "2024-08-25:18:15:11,942 WARNING  [huggingface.py:469] model.chat_template was called with the chat_template set to False or None. Therefore no chat template will be applied. Make sure this is an intended behavior.\n",
            "2024-08-25:18:15:11,950 INFO     [task.py:423] Building contexts for mmlu_abstract_algebra on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 567.46it/s]\n",
            "2024-08-25:18:15:12,133 INFO     [task.py:423] Building contexts for mmlu_anatomy on rank 0...\n",
            "100%|████████████████████████████████████████| 135/135 [00:00<00:00, 563.75it/s]\n",
            "2024-08-25:18:15:12,380 INFO     [task.py:423] Building contexts for mmlu_astronomy on rank 0...\n",
            "100%|████████████████████████████████████████| 152/152 [00:00<00:00, 549.80it/s]\n",
            "2024-08-25:18:15:12,664 INFO     [task.py:423] Building contexts for mmlu_college_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 144/144 [00:00<00:00, 561.78it/s]\n",
            "2024-08-25:18:15:12,928 INFO     [task.py:423] Building contexts for mmlu_college_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 554.90it/s]\n",
            "2024-08-25:18:15:13,116 INFO     [task.py:423] Building contexts for mmlu_college_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 546.65it/s]\n",
            "2024-08-25:18:15:13,305 INFO     [task.py:423] Building contexts for mmlu_college_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 554.73it/s]\n",
            "2024-08-25:18:15:13,490 INFO     [task.py:423] Building contexts for mmlu_college_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 102/102 [00:00<00:00, 571.54it/s]\n",
            "2024-08-25:18:15:13,674 INFO     [task.py:423] Building contexts for mmlu_computer_security on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 570.01it/s]\n",
            "2024-08-25:18:15:13,854 INFO     [task.py:423] Building contexts for mmlu_conceptual_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 235/235 [00:00<00:00, 569.29it/s]\n",
            "2024-08-25:18:15:14,279 INFO     [task.py:423] Building contexts for mmlu_electrical_engineering on rank 0...\n",
            "100%|████████████████████████████████████████| 145/145 [00:00<00:00, 570.25it/s]\n",
            "2024-08-25:18:15:14,540 INFO     [task.py:423] Building contexts for mmlu_elementary_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 378/378 [00:00<00:00, 574.83it/s]\n",
            "2024-08-25:18:15:15,216 INFO     [task.py:423] Building contexts for mmlu_high_school_biology on rank 0...\n",
            "100%|████████████████████████████████████████| 310/310 [00:00<00:00, 611.00it/s]\n",
            "2024-08-25:18:15:15,739 INFO     [task.py:423] Building contexts for mmlu_high_school_chemistry on rank 0...\n",
            "100%|████████████████████████████████████████| 203/203 [00:00<00:00, 710.80it/s]\n",
            "2024-08-25:18:15:16,033 INFO     [task.py:423] Building contexts for mmlu_high_school_computer_science on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 707.25it/s]\n",
            "2024-08-25:18:15:16,179 INFO     [task.py:423] Building contexts for mmlu_high_school_mathematics on rank 0...\n",
            "100%|████████████████████████████████████████| 270/270 [00:00<00:00, 693.54it/s]\n",
            "2024-08-25:18:15:16,579 INFO     [task.py:423] Building contexts for mmlu_high_school_physics on rank 0...\n",
            "100%|████████████████████████████████████████| 151/151 [00:00<00:00, 694.40it/s]\n",
            "2024-08-25:18:15:16,802 INFO     [task.py:423] Building contexts for mmlu_high_school_statistics on rank 0...\n",
            "100%|████████████████████████████████████████| 216/216 [00:00<00:00, 704.41it/s]\n",
            "2024-08-25:18:15:17,118 INFO     [task.py:423] Building contexts for mmlu_machine_learning on rank 0...\n",
            "100%|████████████████████████████████████████| 112/112 [00:00<00:00, 692.62it/s]\n",
            "2024-08-25:18:15:17,284 INFO     [task.py:423] Building contexts for mmlu_business_ethics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 697.56it/s]\n",
            "2024-08-25:18:15:17,432 INFO     [task.py:423] Building contexts for mmlu_clinical_knowledge on rank 0...\n",
            "100%|████████████████████████████████████████| 265/265 [00:00<00:00, 709.68it/s]\n",
            "2024-08-25:18:15:17,816 INFO     [task.py:423] Building contexts for mmlu_college_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 173/173 [00:00<00:00, 702.99it/s]\n",
            "2024-08-25:18:15:18,070 INFO     [task.py:423] Building contexts for mmlu_global_facts on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 708.95it/s]\n",
            "2024-08-25:18:15:18,215 INFO     [task.py:423] Building contexts for mmlu_human_aging on rank 0...\n",
            "100%|████████████████████████████████████████| 223/223 [00:00<00:00, 704.26it/s]\n",
            "2024-08-25:18:15:18,541 INFO     [task.py:423] Building contexts for mmlu_management on rank 0...\n",
            "100%|████████████████████████████████████████| 103/103 [00:00<00:00, 708.68it/s]\n",
            "2024-08-25:18:15:18,691 INFO     [task.py:423] Building contexts for mmlu_marketing on rank 0...\n",
            "100%|████████████████████████████████████████| 234/234 [00:00<00:00, 705.07it/s]\n",
            "2024-08-25:18:15:19,032 INFO     [task.py:423] Building contexts for mmlu_medical_genetics on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 700.30it/s]\n",
            "2024-08-25:18:15:19,179 INFO     [task.py:423] Building contexts for mmlu_miscellaneous on rank 0...\n",
            "100%|████████████████████████████████████████| 783/783 [00:01<00:00, 615.41it/s]\n",
            "2024-08-25:18:15:20,481 INFO     [task.py:423] Building contexts for mmlu_nutrition on rank 0...\n",
            "100%|████████████████████████████████████████| 306/306 [00:00<00:00, 713.61it/s]\n",
            "2024-08-25:18:15:20,923 INFO     [task.py:423] Building contexts for mmlu_professional_accounting on rank 0...\n",
            "100%|████████████████████████████████████████| 282/282 [00:00<00:00, 710.88it/s]\n",
            "2024-08-25:18:15:21,332 INFO     [task.py:423] Building contexts for mmlu_professional_medicine on rank 0...\n",
            "100%|████████████████████████████████████████| 272/272 [00:00<00:00, 703.29it/s]\n",
            "2024-08-25:18:15:21,730 INFO     [task.py:423] Building contexts for mmlu_virology on rank 0...\n",
            "100%|████████████████████████████████████████| 166/166 [00:00<00:00, 714.81it/s]\n",
            "2024-08-25:18:15:21,969 INFO     [task.py:423] Building contexts for mmlu_econometrics on rank 0...\n",
            "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 704.05it/s]\n",
            "2024-08-25:18:15:22,136 INFO     [task.py:423] Building contexts for mmlu_high_school_geography on rank 0...\n",
            "100%|████████████████████████████████████████| 198/198 [00:00<00:00, 716.43it/s]\n",
            "2024-08-25:18:15:22,420 INFO     [task.py:423] Building contexts for mmlu_high_school_government_and_politics on rank 0...\n",
            "100%|████████████████████████████████████████| 193/193 [00:00<00:00, 678.79it/s]\n",
            "2024-08-25:18:15:22,714 INFO     [task.py:423] Building contexts for mmlu_high_school_macroeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 390/390 [00:00<00:00, 707.08it/s]\n",
            "2024-08-25:18:15:23,281 INFO     [task.py:423] Building contexts for mmlu_high_school_microeconomics on rank 0...\n",
            "100%|████████████████████████████████████████| 238/238 [00:00<00:00, 711.12it/s]\n",
            "2024-08-25:18:15:23,625 INFO     [task.py:423] Building contexts for mmlu_high_school_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 545/545 [00:00<00:00, 708.12it/s]\n",
            "2024-08-25:18:15:24,417 INFO     [task.py:423] Building contexts for mmlu_human_sexuality on rank 0...\n",
            "100%|████████████████████████████████████████| 131/131 [00:00<00:00, 709.10it/s]\n",
            "2024-08-25:18:15:24,607 INFO     [task.py:423] Building contexts for mmlu_professional_psychology on rank 0...\n",
            "100%|████████████████████████████████████████| 612/612 [00:00<00:00, 709.44it/s]\n",
            "2024-08-25:18:15:25,494 INFO     [task.py:423] Building contexts for mmlu_public_relations on rank 0...\n",
            "100%|████████████████████████████████████████| 110/110 [00:00<00:00, 667.69it/s]\n",
            "2024-08-25:18:15:25,663 INFO     [task.py:423] Building contexts for mmlu_security_studies on rank 0...\n",
            "100%|████████████████████████████████████████| 245/245 [00:00<00:00, 654.91it/s]\n",
            "2024-08-25:18:15:26,051 INFO     [task.py:423] Building contexts for mmlu_sociology on rank 0...\n",
            "100%|████████████████████████████████████████| 201/201 [00:00<00:00, 704.33it/s]\n",
            "2024-08-25:18:15:26,345 INFO     [task.py:423] Building contexts for mmlu_us_foreign_policy on rank 0...\n",
            "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 710.83it/s]\n",
            "2024-08-25:18:15:26,490 INFO     [task.py:423] Building contexts for mmlu_formal_logic on rank 0...\n",
            "100%|████████████████████████████████████████| 126/126 [00:00<00:00, 691.08it/s]\n",
            "2024-08-25:18:15:26,678 INFO     [task.py:423] Building contexts for mmlu_high_school_european_history on rank 0...\n",
            "100%|████████████████████████████████████████| 165/165 [00:00<00:00, 552.81it/s]\n",
            "2024-08-25:18:15:26,986 INFO     [task.py:423] Building contexts for mmlu_high_school_us_history on rank 0...\n",
            "100%|████████████████████████████████████████| 204/204 [00:00<00:00, 571.44it/s]\n",
            "2024-08-25:18:15:27,354 INFO     [task.py:423] Building contexts for mmlu_high_school_world_history on rank 0...\n",
            "100%|████████████████████████████████████████| 237/237 [00:00<00:00, 572.84it/s]\n",
            "2024-08-25:18:15:27,780 INFO     [task.py:423] Building contexts for mmlu_international_law on rank 0...\n",
            "100%|████████████████████████████████████████| 121/121 [00:00<00:00, 575.78it/s]\n",
            "2024-08-25:18:15:27,996 INFO     [task.py:423] Building contexts for mmlu_jurisprudence on rank 0...\n",
            "100%|████████████████████████████████████████| 108/108 [00:00<00:00, 575.52it/s]\n",
            "2024-08-25:18:15:28,190 INFO     [task.py:423] Building contexts for mmlu_logical_fallacies on rank 0...\n",
            "100%|████████████████████████████████████████| 163/163 [00:00<00:00, 576.22it/s]\n",
            "2024-08-25:18:15:28,481 INFO     [task.py:423] Building contexts for mmlu_moral_disputes on rank 0...\n",
            "100%|████████████████████████████████████████| 346/346 [00:00<00:00, 581.27it/s]\n",
            "2024-08-25:18:15:29,093 INFO     [task.py:423] Building contexts for mmlu_moral_scenarios on rank 0...\n",
            "100%|████████████████████████████████████████| 895/895 [00:01<00:00, 518.15it/s]\n",
            "2024-08-25:18:15:30,861 INFO     [task.py:423] Building contexts for mmlu_philosophy on rank 0...\n",
            "100%|████████████████████████████████████████| 311/311 [00:00<00:00, 707.71it/s]\n",
            "2024-08-25:18:15:31,314 INFO     [task.py:423] Building contexts for mmlu_prehistory on rank 0...\n",
            "100%|████████████████████████████████████████| 324/324 [00:00<00:00, 713.37it/s]\n",
            "2024-08-25:18:15:31,781 INFO     [task.py:423] Building contexts for mmlu_professional_law on rank 0...\n",
            "100%|██████████████████████████████████████| 1534/1534 [00:02<00:00, 709.11it/s]\n",
            "2024-08-25:18:15:34,006 INFO     [task.py:423] Building contexts for mmlu_world_religions on rank 0...\n",
            "100%|████████████████████████████████████████| 171/171 [00:00<00:00, 713.67it/s]\n",
            "2024-08-25:18:15:34,252 INFO     [task.py:423] Building contexts for leaderboard_mmlu_pro on rank 0...\n",
            "100%|██████████████████████████████████| 12032/12032 [00:00<00:00, 16223.91it/s]\n",
            "2024-08-25:18:15:35,800 INFO     [task.py:423] Building contexts for arc_challenge on rank 0...\n",
            "100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1397.67it/s]\n",
            "2024-08-25:18:15:36,699 INFO     [evaluator.py:463] Running loglikelihood requests\n",
            "Running loglikelihood requests:   0%|                | 0/174850 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n",
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
            "Running loglikelihood requests: 100%|██| 174850/174850 [25:45<00:00, 113.15it/s]\n",
            "2024-08-25:18:43:16,499 WARNING  [huggingface.py:1427] Failed to get model SHA for ./AutoRound/Llama-3.1-Minitron-4B-Width-Base-AutoRound-GPTQ-asym-4bit at revision main. Error: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './AutoRound/Llama-3.1-Minitron-4B-Width-Base-AutoRound-GPTQ-asym-4bit'. Use `repo_type` argument if needed.\n",
            "fatal: not a git repository (or any parent up to mount point /)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "2024-08-25:18:43:17,589 INFO     [evaluation_tracker.py:206] Saving results aggregated\n",
            "hf (pretrained=./AutoRound/Llama-3.1-Minitron-4B-Width-Base-AutoRound-GPTQ-asym-4bit), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 4\n",
            "|                 Tasks                 |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n",
            "|---------------------------------------|------:|------|-----:|--------|---|-----:|---|-----:|\n",
            "|arc_challenge                          |    1.0|none  |     0|acc     |↑  |0.4283|±  |0.0145|\n",
            "|                                       |       |none  |     0|acc_norm|↑  |0.4770|±  |0.0146|\n",
            "|leaderboard_mmlu_pro                   |    0.1|none  |     0|acc     |↑  |0.2563|±  |0.0040|\n",
            "|mmlu                                   |    2.0|none  |      |acc     |↑  |0.5809|±  |0.0039|\n",
            "| - humanities                          |    2.0|none  |      |acc     |↑  |0.5362|±  |0.0068|\n",
            "|  - formal_logic                       |    1.0|none  |     0|acc     |↑  |0.3810|±  |0.0434|\n",
            "|  - high_school_european_history       |    1.0|none  |     0|acc     |↑  |0.7515|±  |0.0337|\n",
            "|  - high_school_us_history             |    1.0|none  |     0|acc     |↑  |0.7794|±  |0.0291|\n",
            "|  - high_school_world_history          |    1.0|none  |     0|acc     |↑  |0.7848|±  |0.0268|\n",
            "|  - international_law                  |    1.0|none  |     0|acc     |↑  |0.7438|±  |0.0398|\n",
            "|  - jurisprudence                      |    1.0|none  |     0|acc     |↑  |0.6944|±  |0.0445|\n",
            "|  - logical_fallacies                  |    1.0|none  |     0|acc     |↑  |0.7607|±  |0.0335|\n",
            "|  - moral_disputes                     |    1.0|none  |     0|acc     |↑  |0.6387|±  |0.0259|\n",
            "|  - moral_scenarios                    |    1.0|none  |     0|acc     |↑  |0.2547|±  |0.0146|\n",
            "|  - philosophy                         |    1.0|none  |     0|acc     |↑  |0.6495|±  |0.0271|\n",
            "|  - prehistory                         |    1.0|none  |     0|acc     |↑  |0.6883|±  |0.0258|\n",
            "|  - professional_law                   |    1.0|none  |     0|acc     |↑  |0.4654|±  |0.0127|\n",
            "|  - world_religions                    |    1.0|none  |     0|acc     |↑  |0.7544|±  |0.0330|\n",
            "| - other                               |    2.0|none  |      |acc     |↑  |0.6402|±  |0.0083|\n",
            "|  - business_ethics                    |    1.0|none  |     0|acc     |↑  |0.6400|±  |0.0482|\n",
            "|  - clinical_knowledge                 |    1.0|none  |     0|acc     |↑  |0.6151|±  |0.0299|\n",
            "|  - college_medicine                   |    1.0|none  |     0|acc     |↑  |0.6185|±  |0.0370|\n",
            "|  - global_facts                       |    1.0|none  |     0|acc     |↑  |0.3200|±  |0.0469|\n",
            "|  - human_aging                        |    1.0|none  |     0|acc     |↑  |0.6054|±  |0.0328|\n",
            "|  - management                         |    1.0|none  |     0|acc     |↑  |0.6990|±  |0.0454|\n",
            "|  - marketing                          |    1.0|none  |     0|acc     |↑  |0.8333|±  |0.0244|\n",
            "|  - medical_genetics                   |    1.0|none  |     0|acc     |↑  |0.7200|±  |0.0451|\n",
            "|  - miscellaneous                      |    1.0|none  |     0|acc     |↑  |0.7739|±  |0.0150|\n",
            "|  - nutrition                          |    1.0|none  |     0|acc     |↑  |0.6307|±  |0.0276|\n",
            "|  - professional_accounting            |    1.0|none  |     0|acc     |↑  |0.4291|±  |0.0295|\n",
            "|  - professional_medicine              |    1.0|none  |     0|acc     |↑  |0.5515|±  |0.0302|\n",
            "|  - virology                           |    1.0|none  |     0|acc     |↑  |0.4759|±  |0.0389|\n",
            "| - social sciences                     |    2.0|none  |      |acc     |↑  |0.6711|±  |0.0082|\n",
            "|  - econometrics                       |    1.0|none  |     0|acc     |↑  |0.3158|±  |0.0437|\n",
            "|  - high_school_geography              |    1.0|none  |     0|acc     |↑  |0.7626|±  |0.0303|\n",
            "|  - high_school_government_and_politics|    1.0|none  |     0|acc     |↑  |0.8446|±  |0.0261|\n",
            "|  - high_school_macroeconomics         |    1.0|none  |     0|acc     |↑  |0.5744|±  |0.0251|\n",
            "|  - high_school_microeconomics         |    1.0|none  |     0|acc     |↑  |0.6050|±  |0.0318|\n",
            "|  - high_school_psychology             |    1.0|none  |     0|acc     |↑  |0.7780|±  |0.0178|\n",
            "|  - human_sexuality                    |    1.0|none  |     0|acc     |↑  |0.6641|±  |0.0414|\n",
            "|  - professional_psychology            |    1.0|none  |     0|acc     |↑  |0.5915|±  |0.0199|\n",
            "|  - public_relations                   |    1.0|none  |     0|acc     |↑  |0.6364|±  |0.0461|\n",
            "|  - security_studies                   |    1.0|none  |     0|acc     |↑  |0.6898|±  |0.0296|\n",
            "|  - sociology                          |    1.0|none  |     0|acc     |↑  |0.7711|±  |0.0297|\n",
            "|  - us_foreign_policy                  |    1.0|none  |     0|acc     |↑  |0.8000|±  |0.0402|\n",
            "| - stem                                |    2.0|none  |      |acc     |↑  |0.5011|±  |0.0086|\n",
            "|  - abstract_algebra                   |    1.0|none  |     0|acc     |↑  |0.2800|±  |0.0451|\n",
            "|  - anatomy                            |    1.0|none  |     0|acc     |↑  |0.5481|±  |0.0430|\n",
            "|  - astronomy                          |    1.0|none  |     0|acc     |↑  |0.6447|±  |0.0389|\n",
            "|  - college_biology                    |    1.0|none  |     0|acc     |↑  |0.6875|±  |0.0388|\n",
            "|  - college_chemistry                  |    1.0|none  |     0|acc     |↑  |0.4200|±  |0.0496|\n",
            "|  - college_computer_science           |    1.0|none  |     0|acc     |↑  |0.4500|±  |0.0500|\n",
            "|  - college_mathematics                |    1.0|none  |     0|acc     |↑  |0.3100|±  |0.0465|\n",
            "|  - college_physics                    |    1.0|none  |     0|acc     |↑  |0.4020|±  |0.0488|\n",
            "|  - computer_security                  |    1.0|none  |     0|acc     |↑  |0.7500|±  |0.0435|\n",
            "|  - conceptual_physics                 |    1.0|none  |     0|acc     |↑  |0.5021|±  |0.0327|\n",
            "|  - electrical_engineering             |    1.0|none  |     0|acc     |↑  |0.4897|±  |0.0417|\n",
            "|  - elementary_mathematics             |    1.0|none  |     0|acc     |↑  |0.4259|±  |0.0255|\n",
            "|  - high_school_biology                |    1.0|none  |     0|acc     |↑  |0.7323|±  |0.0252|\n",
            "|  - high_school_chemistry              |    1.0|none  |     0|acc     |↑  |0.5271|±  |0.0351|\n",
            "|  - high_school_computer_science       |    1.0|none  |     0|acc     |↑  |0.6300|±  |0.0485|\n",
            "|  - high_school_mathematics            |    1.0|none  |     0|acc     |↑  |0.3370|±  |0.0288|\n",
            "|  - high_school_physics                |    1.0|none  |     0|acc     |↑  |0.3907|±  |0.0398|\n",
            "|  - high_school_statistics             |    1.0|none  |     0|acc     |↑  |0.4444|±  |0.0339|\n",
            "|  - machine_learning                   |    1.0|none  |     0|acc     |↑  |0.4821|±  |0.0474|\n",
            "\n",
            "|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|\n",
            "|------------------|------:|------|------|------|---|-----:|---|-----:|\n",
            "|mmlu              |      2|none  |      |acc   |↑  |0.5809|±  |0.0039|\n",
            "| - humanities     |      2|none  |      |acc   |↑  |0.5362|±  |0.0068|\n",
            "| - other          |      2|none  |      |acc   |↑  |0.6402|±  |0.0083|\n",
            "| - social sciences|      2|none  |      |acc   |↑  |0.6711|±  |0.0082|\n",
            "| - stem           |      2|none  |      |acc   |↑  |0.5011|±  |0.0086|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!lm_eval --model hf --model_args pretrained=./AutoRound/Llama-3.1-Minitron-4B-Width-Base-AutoRound-GPTQ-asym-4bit --tasks mmlu,arc_challenge,leaderboard_mmlu_pro --device cuda:0 --num_fewshot 0 --batch_size 4 --output_path ./eval/"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08b0fee0606e49f39c4f8d4746ec0812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbc79140a7dc4e8f9e231a3d8758afc1",
              "IPY_MODEL_c5b289881b614b19b83219fedf39e370",
              "IPY_MODEL_fabe96a6e6a9455484426ff92fd284e8"
            ],
            "layout": "IPY_MODEL_257822dc16ad427db4f2ae848240c903"
          }
        },
        "cbc79140a7dc4e8f9e231a3d8758afc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b02c7a30c95542dcb85abfb1be4e2068",
            "placeholder": "​",
            "style": "IPY_MODEL_71cbbf2e4e1b4169b33f2a7f19026b93",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c5b289881b614b19b83219fedf39e370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f586bc30d720478da774a8fbb1df82af",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b567d8d3f52445d1a970499b6cb74466",
            "value": 5
          }
        },
        "fabe96a6e6a9455484426ff92fd284e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_464846cfa4424fdeb3e12ba810688f13",
            "placeholder": "​",
            "style": "IPY_MODEL_437b89e93984486cb3c3787364c4bd30",
            "value": " 5/5 [00:15&lt;00:00,  3.05s/it]"
          }
        },
        "257822dc16ad427db4f2ae848240c903": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b02c7a30c95542dcb85abfb1be4e2068": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71cbbf2e4e1b4169b33f2a7f19026b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f586bc30d720478da774a8fbb1df82af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b567d8d3f52445d1a970499b6cb74466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "464846cfa4424fdeb3e12ba810688f13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "437b89e93984486cb3c3787364c4bd30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}