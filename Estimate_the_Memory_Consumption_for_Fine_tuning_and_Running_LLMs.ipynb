{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e46415545aa54564acf142ffb885ab27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e775de25834433198f0c196f24c6850",
              "IPY_MODEL_7852151eba8a417e90d75eafc9d3acd7",
              "IPY_MODEL_3c5a65d5d2ac46c69737fc3afbf376a3"
            ],
            "layout": "IPY_MODEL_95aa80ef0989401d88854785fad1a579"
          }
        },
        "7e775de25834433198f0c196f24c6850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a4e14032e2247a3b23fdef1fe8d36d7",
            "placeholder": "​",
            "style": "IPY_MODEL_6171981fd242491b95f76bce66457965",
            "value": "config.json: 100%"
          }
        },
        "7852151eba8a417e90d75eafc9d3acd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c225382f27d4403f881fecb12cad33a4",
            "max": 654,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de04f932ed7e435382155b5ba5373183",
            "value": 654
          }
        },
        "3c5a65d5d2ac46c69737fc3afbf376a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba428f8c100a47ad9a5f7deb357d1438",
            "placeholder": "​",
            "style": "IPY_MODEL_9ed5682d331e4c678c7d5e8ad1343284",
            "value": " 654/654 [00:00&lt;00:00, 13.3kB/s]"
          }
        },
        "95aa80ef0989401d88854785fad1a579": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a4e14032e2247a3b23fdef1fe8d36d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6171981fd242491b95f76bce66457965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c225382f27d4403f881fecb12cad33a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de04f932ed7e435382155b5ba5373183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba428f8c100a47ad9a5f7deb357d1438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ed5682d331e4c678c7d5e8ad1343284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tuhinmallick/AI-for-Fashion/blob/main/Estimate_the_Memory_Consumption_for_Fine_tuning_and_Running_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook estimates the memory consumption of transformer models for fine-tuning and inference.\n",
        "\n",
        "This is only an approximation of the total memory consumed by the model with a basic inference/fine-tuned framework without any particular optimization.\n",
        "\n",
        "To get the estimation, run all the cells.\n",
        "\n",
        "First, if you want to estimate the memory consumption of recent models, make sure you are using the last version of Hugging Face transformers.\n",
        "\n",
        "In the following interactive cell, enter the name of the model. It can be the name of the repository on the Hugging Face Hub or a local path.\n",
        "This cell retrieves the architecture of the model.\n"
      ],
      "metadata": {
        "id": "Zny8982jpQ9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoConfig\n",
        "\n",
        "model_name = \"meta-llama/Meta-Llama-3-8B\" # @param {type:\"string\"}\n",
        "\n",
        "model_config = AutoConfig.from_pretrained(model_name)\n",
        "\n",
        "hidden_layers = model_config.num_hidden_layers\n",
        "hidden_size =  model_config.hidden_size\n",
        "attention_heads = model_config.num_attention_heads\n",
        "\n",
        "print(\"Model: \"+str(model_name))\n",
        "print(\"Hidden layers (L): \"+str(hidden_layers))\n",
        "print(\"Hidden size (h): \"+str(hidden_size))\n",
        "print(\"Attention heads (a): \"+str(attention_heads))\n"
      ],
      "metadata": {
        "id": "PAaucRvmmf0F",
        "outputId": "f51cdce3-140a-41a3-8b96-3f6c2810216c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "e46415545aa54564acf142ffb885ab27",
            "7e775de25834433198f0c196f24c6850",
            "7852151eba8a417e90d75eafc9d3acd7",
            "3c5a65d5d2ac46c69737fc3afbf376a3",
            "95aa80ef0989401d88854785fad1a579",
            "7a4e14032e2247a3b23fdef1fe8d36d7",
            "6171981fd242491b95f76bce66457965",
            "c225382f27d4403f881fecb12cad33a4",
            "de04f932ed7e435382155b5ba5373183",
            "ba428f8c100a47ad9a5f7deb357d1438",
            "9ed5682d331e4c678c7d5e8ad1343284"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e46415545aa54564acf142ffb885ab27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: meta-llama/Meta-Llama-3-8B\n",
            "Hidden layers (L): 32\n",
            "Hidden size (h): 4096\n",
            "Attention heads (a): 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following interactive cell enter:\n",
        "- nb_billion_parameter: the number of parameters in the model, in billions. For instance, for Llama 3 8B enter 8.03 since the model has 8.03 billion parameters.\n",
        "- bitwidth_model: The number of bits per parameters. For instance 16, if you load the model with float16 or bfloat16.\n",
        "- bitwidth_optimizer: The number of bits per optimizer's parameter. This notebook assumes the use of the AdamW optimizer. If you use the standard implementation, set it to 32. If you use AdamW-8bit, set it to 8.\n",
        "- seqlen: The maximum sequence length in your batches.\n",
        "- batch_size: The number of instances in one batch."
      ],
      "metadata": {
        "id": "rWkpPCD0GLuo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMAwju0nKh3r",
        "outputId": "cc2aad54-c16b-4c36-924f-365287dc2a92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters in the model (n): 8.03B\n",
            "Bitwidth of the model's parameters (p): 16-bit\n",
            "Bitwidth of the optimizer's parameters (o): 8-bit\n",
            "Sequence length (s): 1024\n",
            "Batch size (b): 1\n"
          ]
        }
      ],
      "source": [
        "#Number of parameters in the model (in billions)\n",
        "nb_billion_parameters = 8.03 # @param {type:\"number\"}\n",
        "print(\"Number of parameters in the model (n): \"+str(nb_billion_parameters)+\"B\")\n",
        "\n",
        "#Precision of the parameters in the model\n",
        "bitwidth_model = 16 # @param {type:\"integer\"}\n",
        "print(\"Bitwidth of the model's parameters (p): \"+str(bitwidth_model)+\"-bit\")\n",
        "\n",
        "#Precision of the parameters in the optimizer\n",
        "bitwidth_optimizer = 8 # @param {type:\"integer\"}\n",
        "print(\"Bitwidth of the optimizer's parameters (o): \"+str(bitwidth_optimizer)+\"-bit\")\n",
        "\n",
        "#The maximum number of tokens in a sequence\n",
        "seqlen = 1024 # @param {type:\"integer\"}\n",
        "print(\"Sequence length (s): \"+str(seqlen))\n",
        "\n",
        "#The batch size\n",
        "batch_size = 1 # @param {type:\"integer\"}\n",
        "print(\"Batch size (b): \"+str(batch_size))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following cell to get the estimation given the information provided in the previous cells."
      ],
      "metadata": {
        "id": "9MOm8LVQHm_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_consumption():\n",
        "  #34 sbh + 5as²b\n",
        "  return round((34*seqlen*batch_size*hidden_size + 5*attention_heads*seqlen*seqlen*batch_size)*2/(1000**3),2)\n",
        "def estimate_consumption_inference():\n",
        "  #32 sbh + 5as²b\n",
        "  return round((32*seqlen*batch_size*hidden_size + 4*attention_heads*seqlen*seqlen*batch_size)*2/(1000**3),2)\n",
        "\n",
        "def estimate_optimizer_size():\n",
        "  return round(((nb_billion_parameters*bitwidth_model+3*nb_billion_parameters*bitwidth_optimizer)/8*(1000**3))/(1000**3),2)\n",
        "\n",
        "def estimate_model_size():\n",
        "  return round(nb_billion_parameters*bitwidth_model/8*(1000**3)/(1000**3),2)\n",
        "\n",
        "activation_consumption = estimate_consumption()\n",
        "activation_consumption_i = estimate_consumption_inference()\n",
        "model_consumption = estimate_model_size()\n",
        "optimizer_consumption = estimate_optimizer_size()\n",
        "\n",
        "print(\"Memory consumption of the model: \"+str(model_consumption)+\" GB\\n\")\n",
        "\n",
        "print(\"Memory consumption of the optimizer: \"+str(optimizer_consumption)+\" GB\")\n",
        "print(\"Memory consumption of activations for fine-tuning: \"+str(activation_consumption*hidden_layers)+\" GB\")\n",
        "print(\"Total memory consumption for fine-tuning: \"+str(model_consumption+optimizer_consumption+activation_consumption*hidden_layers)+\" GB\\n\")\n",
        "\n",
        "print(\"Memory consumption of activations for inference: \"+str(activation_consumption_i)+\" GB\")\n",
        "print(\"Total memory consumption for inference: \"+str(model_consumption+activation_consumption_i)+\" GB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgSFQfZcOEKx",
        "outputId": "e35b612a-36f3-45e1-9cc1-9f3974027be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory consumption of the model: 14.96 GB\n",
            "\n",
            "Memory consumption of the optimizer: 37.39 GB\n",
            "Memory consumption of activations for fine-tuning: 18.56 GB\n",
            "Total memory consumption for fine-tuning: 70.91 GB\n",
            "\n",
            "Memory consumption of activations for inference: 0.5 GB\n",
            "Total memory consumption for inference: 15.46 GB\n"
          ]
        }
      ]
    }
  ]
}